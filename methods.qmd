# Methods {#sec-methods style="text-align:justify;"}

::: callout-important
## Page under construction {style="text-align:justify;"}
:::

This chapter presents the methodology employed to carry out this study. The first section outlines the construction of the database used for the research. The second section describes the logic behind the choice of the temporal boundaries, the creation of chronologies and an attempt to respond to the problem of chronological fuzziness of samples.

## Database {style="text-align:justify;"}

::: callout-important
## Section in progress {style="text-align:justify;"}
:::

### What is a database?

Databases are increasingly being used in archaeology to archive and collect data digitally. There are mainly two types of databases---relational and non-relational. A **relational database** is more appropriate for well-defined data structures which can be linked through a mutual attribute. It is built and maintained with Structured Query Language (SQL), which allows the user to interrogate the database through queries (@gattiglia2018). A SQL database consists of several tables containing information in columns (variables) and rows (entries). Each row is defined by an unique key. Examples of relational database management systems include---MySQL, PostgreSQL, MariaDB, Microsoft SQL Server and Oracle Database. A **non-relational database** (NoSQL) is advantageous in the case of unstructured data, as data is archived as a single document rather than in a table. This structure allows much more flexibility, although NoSQL databases can be harder to use by non-specialists. Among the NoSQL database management systems, MongoDB is the most widely used.

### Databases in archaeology

Databases are used in archaeology primarily for two reasons---data management and data sharing. Most excavations are now working with databases, where the information concerning each stratigraphic unit and finds is recorded. Databases can also be linked and interact with Geographical Information Systems (GIS), that allow researchers to work with a spatial component. In many cases, this data remains private, even after the publication of the excavation results, although increasingly more teams are also making their data available to the public. The growing popularity of open data has also created the need for standardisation. Since the 1970s, researchers started working on *thesauri* (@figuera2018), dictionaries and guides for the correct archival of archaeological information (e.g. pottery classes, context types, chronologies, etc.). A shared system of naming practices is essential for sharing, integrating and analysing data. Recently, more standardised databases and repositories are being created and openly published:

-   [Archaeological Data Service](https://archaeologydataservice.ac.uk) (ADS). A non-profit organisation, based at the University of York. The website provides a large repository of downloadable archaeological data (mostly from the British isles) (@richards2021).

-   [ARIADNEplus](https://ariadne-infrastructure.eu), a Horizon 2020 project funded by the European Commission aiming to build an integrated european archaeological data structure. Over 2 million datasets are part of this project, with the original data still managed by the original creators (@niccolucci2020).

Most of the archaeological databases are based on SQL, as the visual relationships between different data structures are easier to understand.

### Creating an Environmental Archaeology database {style="text-align:justify"}

An integrated database with environmental archaeology data is still missing in Italy. A first step towards botanical data digitalisation has been the [BRAIN project](https://brainplants.successoterra.net) (Botanical Records of Archaeobotany Italian Network), a census of the Italian excavations that reported archaeobotanical data (@mercuri2015). The website, although not providing raw data, has been useful to the bibliographical research for this project. For what concerns faunal remains, a database is missing, although a pilot project was started at the University of Siena by @boscato2007. The database was created using FileMaker Pro and was likely never published.

For the scope of this project, it was thus necessary to create a database that contained raw environmental data. The creation of a database for this research responded to the need of a systematic approach in storing environmental data in a common format and in a way that is convenient for querying, rather than merely archiving the information. The goal is to have data readily available for exploratory data analysis, in an automated process that does not require to adapt the query and manually wrangle data each time a new sample is added to the collection. This project uses MariaDB, a fast and stable fork of MySQL.

-   Insert here database structure

The data was stored in the database after a thorough bibliographical research of the excavated sites (with a chronology pertaining to the 1^st^ millennium CE) where environmental analyses have been undertaken. As in most of the cases the material was retrieved from physical publications, not digitised, the process of data entry was manual and could not be automatised. A list of the publication types where data was retrieved from can be visualised in @fig-publication-type-counts.

```{r}
#| echo: false

library(ggplot2)

pub_type_count <- data.frame(
  Type=c("Book", "Book section", "Conference paper", 
         "Email", "Journal", "Webpage", 
         "Report", "PhD Thesis", "MA Thesis"),
  Count=c(4,117,32,1,81,1,2,2,2)
)

```

```{r}
#| echo: false
#| label: fig-publication-type-counts
#| fig-cap: "Count of the publication types in the database." 
#| fig-width: 5
#| fig-height: 4


ggplot(pub_type_count, aes(x = Count, y = Type)) +
  geom_bar(stat = "identity", width = .8, fill="steelblue") + 
  geom_text(aes(label=Count), hjust=-0.6, size=3.5)+
  theme_minimal()

```

## Periodization {style="text-align:justify;"}

Some of the statistics performed on the dataset have been based on sample periodization, from the Roman age to the Medieval age. The chronologies have been defined as follows:

-   **\[R\] Roman**: from the 1^st^ century BCE to the 2^nd^ century CE.

-   **\[LR\] Late Roman**: from the 3^rd^ to the 5^th^ century CE.

-   **\[EMA\] Early Middle Ages**: from the 6^th^ to the 10^th^ century CE.

-   **\[Ma\] Middle Ages:** from the 11^th^ century CE onwards.

In the database, the tables `faunal_chronologies` and `plants_chronologies` connect each bioarchaeological sample to another table with the identification numbers for the periods (e.g. Sample 1 = ID 1). If a sample has a chronology ranging between two periods, two separate entries will be recorded on the database (e.g. Sample 1 -- 2^nd^ to 3^rd^ c. CE = Periods: Roman, Late Roman) with the result of the sample being repeated in both periods.

![Periodization](images/Periodization.png){fig-align="center"}

### Chronological fuzziness {style="text-align:justify;"}

One of the methodological issues affecting this project is that of chronological fuzziness. Dating plant and animal remains using radiocarbon is very rare, at least in the samples recorded in the database. Most of these samples are dated using ceramics, and chronologies can range between one century or several. Taking this into account, I weighted each sample as follows: $$ W=\frac{1}{(C_{end}-C_{start}+1)} $$ Where:

-   $C\_{end}$ is the terminus ante quem.

-   $C\_{start}$ is the terminus post quem.

-   1 has been summed to the denominator to avoid 0 values.

The imported tables already contain a column of weights, as this operation has been performed on the database prior the export. A diachronic table of means for both datasets has been generated using the functions:

-   `zooarch_tables` (custom)
-   `Bot_mean_table` (custom)
-   `Bot_mean_fun` (custom)
-   `weighted.median` (from the package `spatstat`)

The weight can be used for weighted means and medians, with samples with larger chronologies (hence less precise/fuzzy) weighting less. This method provides each sample with a weight proportional to the length of its chronology so that lower weight values have a smaller impact on the computations.

## Archaeobotany {style="text-align:justify;"}

Introduce the topic and methodological issues

BIASES: Talk about the biases and dataset problems here or do it in the Materials chapter?

### Ubiquity {style="text-align:justify;"}

Ubiquity, or presence analysis, is a popular approach in archaeobotanical quantitative analysis. The method is straightforward-the number of sites/contexts where a plant is present is divided by the total number of sites/contexts under examination. If, for instance, an olive pit is present in 3 sites out of 10, the ubiquity for the olive will be 30%. The formula for the calculation is at follows:

$$
U_x = (\frac{N_p}{N_{tot}}) \cdot 100
$$ where $N_p$ is the number of presences, and $N_{tot}$ is the total number of contexts. The result can be multiplied by 100 to obtain a score in %.

This approach has both advantages and drawbacks. Presence analysis minimizes the impact of outliers (overrepresented plant species) on calculations (@wright2010, 51-52), but the relative importance of a plant in a particular context is lost. It is also important to keep in mind that taxa richness is influenced by factors including sample size, deposition and preservation modes, and sampling strategies (e.g. sieving methodologies) (@pearsall2015, 161-2).

-   Write about sample size problems and include a graph

-   Write about deposition and preservation

-   Write about sampling strategies

-   Write about the problems of this dataset that led to the choice of ubiquity as parameter

Ubiquity is the best option to immediately read the Italian peninsular botanical dataset. The variability in the seeds/fruits samples is too high, with different species being outliers in different sites. A likely reason for this is probably the poor sampling quality, usually occurring after an agglomerate of seeds is found during excavation. Normally, agglomerates are found in specific storage places or processing areas (e.g. wine/olive processing quarters), skewing the distribution of the curve. Ubiquity overcomes this issue, as it provides a score based on the percentage of presences of a plant species in the samples considered.

In addition to the general calculation of the diachronic ubiquity in the entire peninsula, it is also important to look for regional differences in the archaeobotanical dataset. To do so, I created an `R` function to subset data related to Northern, Central and Southern Italian regions. For a clearer reading of the plot, I divided the plants into--`Cereals`, `Pulses` and `Fruits/Nuts`. The results are in @sec-archaeobotany.

## Species richness, diversity, evenness of samples {style="text-align:justify;"}

::: callout-note
## Notes on terminology:

**Species richness** is the number of species found in a community or ecosystem. **Species diversity** is a measurement of species richness combined with **evenness**, meaning it takes into account not only how many species are present but also how evenly distributed the numbers of each species are.
:::

### Richness and diversity in the Italian macroregions

Lorem ipsum

### Cereals regionality: testing the results

Describe the PERMANOVA etc

### Network Analysis of cereals in EMA sites

Lorem ipsum

## Zooarchaeology
