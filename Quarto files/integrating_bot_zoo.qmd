---
always_allow_html: true
---

# Integrating the evidence

::: callout-important
## Page under construction - Clean page! {style="text-align:justify;"}
This page contained scripts for random forests, which have been abandoned. The page has to be cleaned now. 
:::

```{r}
#| echo: false
#| output: false

source('functions_zoo.R')

```

## Environmental data for site type classification {style="text-align:justify;"}

Random forest algorithms are a popular method for classification in machine learning, and they have been applied to a wide range of problems. In this dissertation, they can be used to classify archaeological sites from the first millennium CE based on their botanical and faunal datasets. By removing categories that create bias due to insufficient data, the accuracy of the models can be improved.

In this study, I investigated whether the botanical and faunal datasets from archaeological sites from the first millennium CE could be used to accurately classify the type of site. To do this, I built random forest models for both datasets and evaluated their performance on a test set.

Before building the models, I preprocessed the datasets by removing categories that were likely to introduce bias or lead to misclassification. In the botanical dataset, I removed the `Religious` and `Religious, monastery` categories. In the faunal dataset, I removed the `Necropolis` category due to its low number of entries and tendency to be misclassified as `Urban`. I also removed the `Rural site, mansio`, and `Shipwreck` categories from the faunal dataset due to their low number of entries. Finally, the `Castrum` and `Castle` categories were merged in both datasets.

After preprocessing the datasets, I split them into train and test sets, and used the train set to build the random forest models. I then used the models to predict the class labels of the instances in the test set, and compared these predicted labels to the true labels to evaluate the performance of the models.

The results of the study showed that both the archaeobotanical and zooarchaeological variables can be good predictors for site type. The archaeobotanical model had a predictive accuracy of 67%, and the zooarchaeological model had an accuracy of 76%. In both models, the classes that were most accurately classified by the random forests were Castles and Castra, and Urban and Rural sites. It is interesting to note that the model sometimes classifies rural villas as "Urban" and sometimes as "Rural", accurately predicting their class label only about 50% of the time.

Overall, this study demonstrates that random forest algorithms can be effectively used to classify archaeological sites from the first millennium CE based on their botanical and faunal datasets. By carefully preprocessing the datasets and selecting appropriate categories, the accuracy of the models can be improved, leading to more accurate predictions of site type.

```{r}
#| code-fold: true
#| output: false
#| code-summary: "Libraries"
#| code-overflow: wrap
# Required libraries
library(vegan)
library(tidyverse)
library(randomForest)
library(caret)
```

```{r}
#| echo: false
# Load the data frames containing the predictors
df1_zoo <- read.csv("/Users/robertoragno/Desktop/University/Bari/PhD - Quarto/Database export/Zooarch_Condensed.csv", header=TRUE, sep=";")
df2_bot <- read.csv("/Users/robertoragno/Desktop/University/Bari/PhD - Quarto/Database export/plants.csv", header=TRUE, sep=";")
```

```{r}
#| code-fold: true
#| output: false
#| code-summary: "Data manipulation"
#| code-overflow: wrap

############################################################################
##
## Reformat the data so that:
## 1. The absolute counts become frequencies for the faunal dataset and
##    presence/absence (0,1) in the botanical dataset.
##    - Using the decostand() function in the vegan package
## 2. The columns subsetted in the ZOO dataset are: 
##    - Type 'numerical': Pigs, Cattle, Caprine, Edible.W..Mammals, etc.
##    - Type 'factor': Type
## 3. The column Type has too many categories. Some are merged using the 
##    str_replace() function in the stringr library.
## 4. Interpreted correctly by randomForest:
##    - The columns Type has to be converted from
##      char to factor.
## 7. NAs are converted to 0s.
##
############################################################################

############################################################################
## ZOO Data handling
############################################################################

# 1. Convert numerical columns to frequencies
df1_zoo[c(15:23)] <- decostand(df1_zoo[c(15:23)], method="total", na.rm = TRUE)

# 2. Subsetting the dataframe keeping only the columns 'Type' and the %
df1_zoo <- df1_zoo[c(4,15:23)]

# 3. Convert NAs to 0s.
df1_zoo[is.na(df1_zoo)]<- 0

# 4. Removing problematic categories 
# The categories to remove have been chosen after using the summary() function to
# look at potential sources of bias, and testing them with the random forest

df1_zoo.clean <- filter(df1_zoo, (Type!="Necropolis") & (Type!="Religious, monastery") & (Type!="Rural site, mansio") & (Type!="Shipwreck"))

# 5. Merging the categories 'Castle' and 'Castrum'. There is probably a more efficient
#    way, but this is simple and straightforward.
df1_zoo.clean$Type <- str_replace(df1_zoo.clean$Type, "Castle", "Fortified")
df1_zoo.clean$Type <- str_replace(df1_zoo.clean$Type, "Castrum", "Fortified")

# 6. Converting the 'Type' column to factor, so it can be interpreted correctly
#    by the randomforest() function
df1_zoo.clean$Type <- as.factor(df1_zoo.clean$Type)

# Remove duplicates caused by sites that have multiple chronologies 
# (= duplicate entry).
df1_zoo.clean <- df1_zoo.clean[!duplicated(df1_zoo.clean), ]

zoo_new_rows <- df1_zoo.clean %>% sample_n(size = 2000, replace = TRUE)
df_expanded_zoo <- rbind(df1_zoo.clean, zoo_new_rows)


############################################################################
## BOT Data handling
############################################################################

# 1. Convert species absolute counts to Presence/Absence (NULL,1)
df2_bot.pa <- decostand(df2_bot[15:53], method = "pa")

# 2. Null values become 0s
df2_bot.pa[is.na(df2_bot.pa)]<- 0

# 3. A for loop that transforms every presence/absence column in a logical column
#    A logical column will have TRUE/FALSE values. 
for (i in 1:ncol(df2_bot.pa)) {
  df2_bot.pa[,i] <- as.logical(df2_bot.pa[,i])
}

# 4. The 'Type' column is added to the dataframe
df2_bot.pa$Type <- df2_bot$type_name

# 5. Removing problematic categories
# The categories to remove have been chosen after using the summary() function to
# look at potential sources of bias, and testing them with the random forest
df2_bot.clean <- filter(df2_bot.pa, (Type!="Religious") & (Type!="Religious, monastery"))

# 6. Merging the categories 'Castle' and 'Castrum'. There is probably a more efficient
#    way, but this is simple and straightforward.
df2_bot.clean$Type <- str_replace(df2_bot.clean$Type, "Castle", "Fortified")
df2_bot.clean$Type <- str_replace(df2_bot.clean$Type, "Castrum", "Fortified")

# 7. Converting the 'Type' column to factor, so it can be interpreted correctly
#    by the randomforest() function
df2_bot.clean$Type <- as.factor(df2_bot.clean$Type)

# Remove duplicates caused by sites that have multiple chronologies 
# (= duplicate entry).
df2_bot.clean <- df2_bot.clean[!duplicated(df2_bot.clean), ]

# 8. SMOTE
# The data is still unbalanced, as you can see by typing:
#table(df2_bot.clean$Type)
#library(RSBID)

#df2_bot.smote <- df2_bot.clean

#for (i in 1:39) {
#  df2_bot.smote[,i] <- as.integer(as.logical(df2_bot.smote[,i]))
#}

#df2_bot.smote <- smote(Type ~ ., data=df2_bot.smote, perc.over = 6, perc.under = 2, k=10) # Castrum
#df2_bot.smote <- smote(Type ~ ., data=df2_bot.smote, perc.over = 2, k=10) # Necropolis

#df2_bot.smote <- SMOTE(data=df2_bot.smote, 40, 5)
#df2_bot.sample <- sample(df2_bot.smote, 1000, replace=TRUE)

table(df2_bot.clean$Type)

df2_bot.weights <- 1/table(df2_bot.clean$Type)
df1_zoo.weights <- 1/table(df1_zoo.clean$Type)

bot_new_rows <- df2_bot.clean %>% sample_n(size = 2000, replace = TRUE)
df_expanded <- rbind(df2_bot.clean, bot_new_rows)

#table((df2_bot.smote$data)$class)

```

```{r}
#| code-fold: true
#| output: false
#| code-summary: "Test Random forest"
#| code-overflow: wrap
#| eval: false
#| echo: false

############################################################################
## RANDOM FORESTS
############################################################################

# Firstly, set.seed() to get reproducible results.
set.seed(42)

# The random forests below are a test that does not use a split dataset

model_bot <- randomForest(Type ~ ., 
                          data = df2_bot.clean,
                          ntree=1000,
                          strata=df2_bot.clean$Type,
                          replace=TRUE,
                          classwt=df2_bot.weights
                          )

model_zoo <- randomForest(Type ~ ., 
                          data = df1_zoo.clean,
                          ntree=1000,
                          mtry=3
                          )


```

```{r}
#| code-fold: true
#| output: false
#| code-summary: "Random forest: Archaeobotany"
#| code-overflow: wrap
#| eval: false
#| echo: false

############################################################################
##
## BOT Random forest on train dataset + prediction
##
## RandomForest returns several types of information stored in 'model'
##  a. The OOB error rate for the forest with ntree trees. 
##     In this case ntree=500 by default
##  b. The confusion matrix for the forest with ntree trees.
##     The confusion matrix is laid out like this:
##          
##                     Rural                      Urban
##         --------------------------------------------------------------
## Rural   | Number of rural sites      | Number of rural sites         |
##         | correctly called "rural"   | incorectly called "Urban"     |
##         | by the forest.             | by the forest                 |
##         --------------------------------------------------------------
## Urban   | Number of urban sites      | Number of urban sites         |
##         | incorrectly called         | correctly called "urban"      |
##         | "rural" by the forest      | by the forest                 |
##         --------------------------------------------------------------
##
##
############################################################################

bot_train_ind <- sample(1:nrow(df2_bot.clean), size = 0.8 * nrow(df2_bot.clean)) # 80% of data for training
bot_train <- df2_bot.clean[bot_train_ind, ]
bot_test <- df2_bot.clean[-bot_train_ind, ]

model_train_bot <- randomForest(Type ~ ., data = bot_train, ntree=5000, importance=T)

# Use the model to predict class labels for the test set
predictions_bot <- predict(model_train_bot, newdata = bot_test)
predictions_bot <- factor(predictions_bot)
bot_test$Type <- factor(bot_test$Type)

# Use the confusionMatrix() function to generate a confusion matrix with the test dataset
bot_confusion_matrix <- confusionMatrix(predictions_bot, bot_test$Type)

# Convert to dataframe the confusion matrix (so we can visualise it)
bot_cm.df <- as.data.frame(decostand(bot_confusion_matrix$table, margin=1, method="total"))
bot_cm.df$Freq <- round(bot_cm.df$Freq, 2)

bot_test_cm.plot <- ggplot(data = bot_cm.df, aes(x=Prediction, y=Reference, fill=Freq)) +
 geom_tile(color = "white")+
  geom_text(aes(label = Freq), color = "black", size = 4) +
 scale_fill_gradient2(low = "white", high = "#A6D1E6", limit = c(0,1), space = "Lab") +
  theme_minimal()+ 
  theme(legend.position = "none")+
 theme(axis.text.x = element_text(angle = 45, vjust = 1, 
    size = 10, hjust = 1))+
 coord_fixed()

# Let's do the same for the training dataset
bot_train_cm <- model_train_bot$confusion[,-6] #Without class error col
bot_train_cm <- decostand(bot_train_cm, margin=1, method="total")
bot_train_cm <- round(bot_train_cm, 2)
library(reshape2)
bot_train_cm <- melt(bot_train_cm, value.name = "Freq", varnames = c("Reference", "Prediction"))

#Let's plot the train confusion matrix (normalized)
bot_train_cm.plot <- ggplot(data = bot_train_cm, 
                            aes(x=Prediction, y=Reference, fill=Freq)) +
  geom_tile(color = "white")+
  geom_text(aes(label = Freq), color = "black", size = 4) +
  scale_fill_gradient2(low = "white", high = "#A6D1E6", limit = c(0,1), space = "Lab") +
  theme_minimal()+ 
  theme(legend.position = "none")+
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
    size = 10, hjust = 1))+
  coord_fixed()
```

### Archaeobotany

Below, the formula used to call the randomforest() function from the randomForest R package on the train set. The call also shows the OOB (Out-Of-Bag) error rate and the confusion matrix.

```{r}
#| echo: false
#| eval: false
model_train_bot
```

The confusion matrix can also be calculated for the final prediction that uses both the training and test set. Using this confusion matrix, it is possible to show the model's accuracy and F1 score for each class of site.

```{r}
#| echo: false
#| eval: false
#| layout-ncol: 2
#| label: fig-rf-conf-matrices-archaeobot-pa
#| fig-cap: "Standardized (each value divided by row total) confusion matrices for the training and testing archaeobotanical datasets."
#| fig-subcap:
#|   - "Training dataset"
#|   - "Testing dataset"

bot_train_cm.plot
bot_test_cm.plot

```

**Accuracy**

```{r}
#| echo: false
#| eval: false
#Accuracy
print(as.numeric(bot_confusion_matrix$overall[1]))
```

**F1 Scores**

```{r}
#| echo: false
#| eval: false

# Print the F1 score
print(bot_confusion_matrix$byClass[,7])
```

The most problematic class is `Rural site, villa` which leads to an incorrect classification of the site as `Urban` in the testing dataset, whereas it is correctly classified in only half of the training dataset (consisting of 80% of the entire dataset). @fig-rf-conf-matrices-archaeobot-pa shows the confusion matrices for both the testing and training datasets, standardised to allow inter-class comparability. In the training dataset, the best performing class is `Urban`, which has a class error of 0.10, followed by necropoleis and fortified sites.

### Zooarchaeology

```{r}
#| code-fold: true
#| output: false
#| code-summary: "Random forest: Zooarchaeology"
#| code-overflow: wrap
#| eval: false
#| echo: false

############################################################################
##
## ZOO Random forest on train dataset + prediction
##
############################################################################
zoo_train_ind <- sample(1:nrow(df1_zoo.clean), size = 0.8 * nrow(df1_zoo.clean)) # 80% of data for training
zoo_train <- df1_zoo.clean[zoo_train_ind, ]
zoo_test <- df1_zoo.clean[-zoo_train_ind, ]

model_train_zoo <- randomForest(Type ~ ., data = zoo_train, ntree=1000, importance=T)

# Let's plot the confusion matrix of the training dataset
zoo_train_cm <- model_train_zoo$confusion[,-7] #Without class error col
zoo_train_cm <- decostand(zoo_train_cm, margin=1, method="total")
zoo_train_cm <- round(zoo_train_cm, 2)
zoo_train_cm <- melt(zoo_train_cm, value.name = "Freq", varnames = c("Reference", "Prediction"))

#Let's plot the train confusion matrix (normalized)
zoo_train_cm.plot <- ggplot(data = zoo_train_cm, 
                            aes(x=Prediction, y=Reference, fill=Freq)) +
  geom_tile(color = "white")+
  geom_text(aes(label = Freq), color = "black", size = 4) +
  scale_fill_gradient2(low = "white", high = "#A6D1E6", limit = c(0,1)) +
  theme_minimal()+ 
  theme(legend.position = "none")+
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
    size = 10, hjust = 1))+
  coord_fixed()

## TEST SET 
# Use the model to predict class labels for the test set
predictions_zoo <- predict(model_train_zoo, newdata = zoo_test)
predictions_zoo <- factor(predictions_zoo)
zoo_test$Type <- factor(zoo_test$Type)

# Use the confusionMatrix() function to generate a confusion matrix
zoo_confusion_matrix <- confusionMatrix(predictions_zoo, zoo_test$Type)

# Convert to dataframe the confusion matrix (so we can visualise it)
zoo_cm.df <- as.data.frame(decostand(zoo_confusion_matrix$table, margin=1, method="total"))
zoo_cm.df$Freq <- round(zoo_cm.df$Freq, 2)

zoo_test_cm.plot <- ggplot(zoo_cm.df, aes(x=Prediction, y=Reference)) +
 geom_tile(aes(fill=Freq)) +
 geom_text(aes(label = Freq), color = "black", size = 4) +
 scale_fill_gradient(low = "#FFFFFF", high = "#A6D1E6") +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
    size = 10, hjust = 1), legend.position = "right")+
 coord_fixed()

```

Below, the formula used to call the randomforest() function from the randomForest R package on the train set. The call also shows the OOB (Out-Of-Bag) error rate and the confusion matrix.

```{r}
#| echo: false
#| eval: false
model_train_zoo
```

The confusion matrix can also be calculated for the final prediction that uses both the training and test set. Using this confusion matrix, it is possible to show the model's accuracy and F1 score for each class of site.

```{r}
#| echo: false
#| eval: false
#| layout-ncol: 2
#| label: fig-rf-conf-matrices-zooarch-pa
#| fig-cap: "Standardized (each value divided by row total) confusion matrices for the training and testing zooarchaeological datasets."
#| fig-subcap:
#|   - "Training dataset"
#|   - "Testing dataset"

zoo_train_cm.plot
zoo_test_cm.plot
```

**Accuracy**

```{r}
#| echo: false
#| eval: false
# Accuracy
print(as.numeric(zoo_confusion_matrix$overall[1]))
```

**F1 Scores**

```{r}
#| echo: false
#| eval: false

# Print the F1 score
print(zoo_confusion_matrix$byClass[,7])
```

The class `Rural site, villa` has a low F1 score, being at times classified as urban. 


## Feature importance using environmental data {style="text-align:justify;"}

### Zooarchaeology

```{r}
#| eval: false
#| echo: false
# Import again the dataframe

df1_zoo <- read.csv("/Users/robertoragno/Desktop/University/Bari/PhD - Quarto/Database export/Zooarch_Condensed.csv", header=TRUE, sep=";")

str(df1_zoo)
#df1_zoo <- df1_zoo[!duplicated(df1_zoo), ]

# 1. Convert numerical columns to frequencies
df1_zoo[c(15:23)] <- decostand(df1_zoo[c(15:23)], method="total", na.rm = TRUE)

# 2. Subsetting the dataframe keeping only the columns 'Type' and the %
df1_zoo <- df1_zoo[c(4:6,9,15:23)]

# 3. Convert NAs to 0s.
df1_zoo[is.na(df1_zoo)]<- 0

# 4. Removing problematic categories 
# The categories to remove have been chosen after using the summary() function to
# look at potential sources of bias, and testing them with the random forest

library(stringr)
library(tidyverse)
df1_zoo.clean <- filter(df1_zoo, (Type!="Necropolis") & (Type!="Religious, monastery") & (Type!="Rural site, mansio") & (Type!="Shipwreck"))

# 5. Merging the categories 'Castle' and 'Castrum'. There is probably a more efficient
#    way, but this is simple and straightforward.
df1_zoo.clean$Type <- str_replace(df1_zoo.clean$Type, "Castle", "Castle/Castrum")
df1_zoo.clean$Type <- str_replace(df1_zoo.clean$Type, "Castrum", "Castle/Castrum")
df1_zoo.clean$Type <- str_replace(df1_zoo.clean$Type, "Castle/Castle/Castrum", "Castle/Castrum")

# 6. Converting the categorical columns to factor, so they can be interpreted correctly
#    by the randomforest() function

df1_zoo.clean[,c(1:4)] <- lapply(df1_zoo.clean[,c(1:4)], as.factor)
#df1_zoo.clean <- df1_zoo.clean[,-c(8,10,11,12,13)]

zoo_responses <- df1_zoo.clean[,c(5:ncol(df1_zoo.clean))]
zoo_predictors <- df1_zoo.clean[,c(1:4)]

library(randomForest)
model_zoo_cat <- randomForest(x=zoo_predictors, y=zoo_responses$Caprine, data = df1_zoo.clean, ntree=1000, importance=T)



```

# Test Distance

```{r}
#| echo: false
#| eval: false


###################################
## Dissimilarity matrix 
###################################

# Import libraries
library(matrixStats) # WeightedMedian() function

# Import data
zooarch_summary <- (zooarch_tables_general(zooarch_cond)$Rel_Prop_exp_XY)
#zooarch_summary[zooarch_summary==0] <- NA

#Simplify the categories
zooarch_summary$Type <- str_replace(zooarch_summary$Type, "Urban, amphitheater", "Amphitheater")    
zooarch_summary$Type <- str_replace(zooarch_summary$Type, "Rural site, mansio", "Rural")
zooarch_summary$Type <- str_replace(zooarch_summary$Type, "Religious, monastery", "Religious")
zooarch_summary$Type <- str_replace(zooarch_summary$Type, "Castle", "Fortified")
zooarch_summary$Type <- str_replace(zooarch_summary$Type, "Castrum", "Fortified")

# Remove duplicates
zooarch_clean <- zooarch_summary[c(3, 14:22)]
zooarch_clean <- zooarch_clean[!duplicated(zooarch_clean), ]

library(vegan)

# Calculate weighted median of animals by site type
zoo_medians_type_gen <- zooarch_summary %>%
  group_by(Type) %>%
  summarize(Pigs = weightedMedian(Pigs, w=weight, na.rm = TRUE),
            Cattle = weightedMedian(Cattle, w=weight, na.rm = TRUE),
            Caprine = weightedMedian(Caprine, w=weight, na.rm = TRUE),
            Edible_Wild = weightedMedian(Edible.W..Mammals, w=weight, na.rm = TRUE)
            )

# Convert to dataframe and remove row n. 7 (Shipwreck)
zoo_medians_type_gen <- as.data.frame(zoo_medians_type_gen)
rownames(zoo_medians_type_gen) <- zoo_medians_type_gen$Type
zoo_medians_type_gen <- zoo_medians_type_gen[-7,]

# Calculate the matrix
zoo_type_dist <- vegdist(zoo_medians_type_gen[-1], na.rm=T, diag=T, method="bray")

# Melt the matrix to plot it
library(reshape2)
zoo_type_dist.mat <- as.matrix(zoo_type_dist)
zoo_type_dist.melt <- melt(zoo_type_dist.mat)

zoo_type_dist.plot <- ggplot(zoo_type_dist.melt, aes(x=Var1, y=Var2)) +
 geom_tile(aes(fill=value)) +
 geom_text(aes(label = round(value,2)), color = "black", size = 4) +
 scale_fill_gradient(low = "#FFFFFF", high = "#A6D1E6") +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
    size = 10, hjust = 1), 
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    legend.position = "right"
    )+
  labs(
  title= "ZOO - Dissimilarity among site types",
  caption = "Values closer to 0 indicate more similar site types.",
  subtitle="Bray-Curtis dissimilarity matrix."
  )+
 coord_fixed()

zoo_type_dist.plot

adonis2(
zooarch_clean[-1] ~ Type,
data=zooarch_clean
)

```



# To do:
- Does viticulture decrease in the 2nd-3rd c. in favor of grain production + animal rearing?
