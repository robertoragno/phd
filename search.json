[
  {
    "objectID": "methods.html",
    "href": "methods.html",
    "title": "4  Methods",
    "section": "",
    "text": "Page under construction"
  },
  {
    "objectID": "methods.html#introduction",
    "href": "methods.html#introduction",
    "title": "4  Methods",
    "section": "4.1 Introduction",
    "text": "4.1 Introduction\nThis chapter presents the methodology employed to carry out this study. The first section discusses statistical computing programming languages such as R and Python. The second section introduces databases and their employment in archaeology, then outlines the construction of the database used for this research. GitHub as a hosting service for this research is discussed in section three. The fourth section describes the logic behind the choice of the temporal boundaries, the creation of chronologies and presents a possible solution to mitigate the problem of chronological fuzziness of samples."
  },
  {
    "objectID": "methods.html#statistical-computing",
    "href": "methods.html#statistical-computing",
    "title": "4  Methods",
    "section": "4.2 Statistical computing",
    "text": "4.2 Statistical computing\nStatistical computing, often referred to as computational statistics, is a branch of statistics that uses computational approaches to solving statistical problems. Traditionally, the term statistical computing places more emphasis on numerical methods, while computational statistics refer to topics such as resampling methods, exploratory data analysis, neural networks, etc. (Rizzo (2019)). Specifically, computational statistics deals with methods “unthinkable before the computer age” (Lauro (1996)). In Archaeology, mainly two programming languages are used today for exploring large sets of data: R and Python. Both programming languages can be used for statistical modeling, although R was designed explicitly for statistical computing and Python as an object-oriented language for more general purposes. Python is one of the most used and fastest-growing programming languages in the world, and its package number is extremely high compared to R. While R benefits from a strong academic community, Python relies on developers to add new packages almost continuously. R was used for the majority of this project due to its familiarity, while Python was used for certain algorithms that were easier to implement.\n\n\n\nLogos of R and Python\n\n\n\n4.2.1 The R programming language\nR, as described on the R-Project FAQs is a “system for statistical computation and graphics. It consists of a language plus a run-time environment with graphics, a debugger, access to certain system functions, and the ability to run programs stored in script files”. Increasingly popular for data scientists, R is based on S and provides its own IDE (the R GUI), although RStudio1 is the most popular IDE for computing the R language. For this project, RStudio was the standard IDE.\n\n4.2.1.1 R Packages\nIn addition to base R, several packages enhance its performances and offer more tools to users. The packages are distributed by the official CRAN repository, which counts more than 18,452 packages2.\n\n4.2.1.1.1 tidyverse\nThe tidyverse ecosystem (Wickham et al. (2019)) is a core set of packages for R, maintained by Hadley Wickham for importing, tidying, transforming and visualising data which includes packages such as—ggplot2, dplyr, tidyr, stringr, tibble, forcats, purr, readr.\n\n\n4.2.1.1.2 ggplot2\nggplot2 is the most common data visualisation package for R, included in the tidyverse environment. The package substitutes the R base graphics and allows visualisation of single and multiple components (Wickham (2016)).\n\n\n4.2.1.1.3 knitr\nThe knitr engine enables the integration of R with HTML, Markdown and LaTeX. The package allows reproducible research (Xie (2021)) and was used for generating dynamic reports and documentation for this thesis.\n\n\n4.2.1.1.4 vegan\nThe vegan package (Oksanen et al. (2022)) is designed for ordination methods, diversity analysis and multivariate analysis in ecology.\n\n\n\n\n4.2.2 The Python programming language\nPython is a popular high-level general-purpose programming language that supports object-oriented, procedural and functional programming. Several IDE support Python, including JupyterLab (open source), RStudio, PyCharm and Visual Studio Code. In recent years, many statistical packages have been developed to compete with R in the data science field. This project uses Python in addition to R as its environment offers well-designed and intuitive packages for some of the data-reduction methods used on the datasets.\n\n4.2.2.1 Python packages\nPython’s motto “batteries included” refers to its comprehensive standard library. However, over 390,000 packages are contained in the PyPi repository providing users with many options for coding. In particular, this project uses some data science libraries (set of packages) and packages listed below.\n\n4.2.2.1.1 Pandas\nPandas is the most used package for data handling, manipulation and analysis (Reback et al. (2022)).\n\n\n4.2.2.1.2 Matplotlib\nMatplotlib is Python’s standard data visualisation library (Hunter (2007)).\n\n\n4.2.2.1.3 Seaborn\nBased on Matplotlib, Seaborn is a data visualisation library that allows users to create more complex graphs (Waskom (2021)).\n\n\n4.2.2.1.4 Scikit-learn\nScikit-learn is the most comprehensive Python library for machine learning, including methods for classification, clustering, data reduction and regression (Pedregosa et al. (2011)).\n\n\n4.2.2.1.5 NumPy\nThe NumPy library is the main tool for array programming and it includes several functions for numerical analysis (Harris et al. (2020)).\n\n\n4.2.2.1.6 SciPy\nThe SciPy library provides tools for scientific computing (data integration, interpolation, optimization, linear algebra, etc.) and it works with NumPy multidimensional arrays (Virtanen et al. (2020))."
  },
  {
    "objectID": "methods.html#github-hosting-the-project",
    "href": "methods.html#github-hosting-the-project",
    "title": "4  Methods",
    "section": "4.3 GitHub: hosting the project",
    "text": "4.3 GitHub: hosting the project\n\n\n\n\n\n\nSection under construction\n\n\n\nThis section will include a general intro to GitHub and why I chose to host data there."
  },
  {
    "objectID": "methods.html#database",
    "href": "methods.html#database",
    "title": "4  Methods",
    "section": "4.4 Database",
    "text": "4.4 Database\n\n4.4.1 What is a database?\nDatabases are increasingly being used in archaeology to archive and collect data digitally. There are mainly two types of databases—relational and non-relational. A relational database is more appropriate for well-defined data structures which can be linked through a mutual attribute. It is built and maintained with Structured Query Language (SQL), which allows the user to interrogate the database through queries (Gattiglia (2018)). A SQL database consists of several tables containing information in columns (variables) and rows (entries). Each row is defined by an unique key. Examples of relational database management systems include—MySQL, PostgreSQL, MariaDB, Microsoft SQL Server and Oracle Database. A non-relational database (NoSQL) is advantageous in the case of unstructured data, as data is archived as a single document rather than in a table. This structure allows much more flexibility, although NoSQL databases can be harder to use by non-specialists. Among the NoSQL database management systems, MongoDB is the most widely used.\n\n\n4.4.2 Databases in archaeology\nDatabases are used in archaeology primarily for two reasons—data management and data sharing. Most excavations are now working with databases, where the information concerning each stratigraphic unit and finds is recorded. Databases can also be linked and interact with Geographical Information Systems (GIS), that allow researchers to work with a spatial component. In many cases, this data remains private, even after the publication of the excavation results, although increasingly more teams are also making their data available to the public. The growing popularity of open data has also created the need for standardisation. Since the 1970s, researchers started working on thesauri (Figuera (2018)), dictionaries and guides for the correct archival of archaeological information (e.g. pottery classes, context types, chronologies, etc.). A shared system of naming practices is essential for sharing, integrating and analysing data. Recently, more standardised databases and repositories are being created and openly published:\n\nArchaeological Data Service (ADS). A non-profit organisation, based at the University of York. The website provides a large repository of downloadable archaeological data (mostly from the British isles) (Richards (2021)).\nARIADNEplus, a Horizon 2020 project funded by the European Commission aiming to build an integrated european archaeological data structure. Over 2 million datasets are part of this project, with the original data still managed by the original creators (Niccolucci (2020)).\n\nMost of the archaeological databases are based on SQL, as the visual relationships between different data structures are easier to understand.\n\n\n4.4.3 Creating an Environmental Archaeology database\nAn integrated database with environmental archaeology data is still missing in Italy. A first step towards botanical data digitalisation has been the BRAIN project (Botanical Records of Archaeobotany Italian Network), a census of the Italian excavations that reported archaeobotanical data (Mercuri et al. (2015)). The website, although not providing raw data, has been useful to the bibliographical research for this project. For what concerns faunal remains, a database is missing, although a pilot project was started at the University of Siena by Boscato et al. (2007). The database was created using FileMaker Pro and was likely never published.\nFor the scope of this project, it was thus necessary to create a database that contained raw environmental data. The creation of a database for this research responded to the need of a systematic approach in storing environmental data in a common format and in a way that is convenient for querying, rather than merely archiving the information. The goal is to have data readily available for exploratory data analysis, in an automated process that does not require to adapt the query and manually wrangle data each time a new sample is added to the collection. This project uses MariaDB, a fast and stable fork of MySQL.\nThe database was structured with the creation of 21 tables. The table site_list is the core table, from which most of the other tables in the schema depend. The entries in the table are based on the chronology of a single sample. The chronology is defined both by the macroperiod3 and by the centuries, with two columns: startcentury and endcentury. If a context has been sampled more than once, there will be as many entries as many chronologies. If a context has been sampled both for seeds and bones, the sample IDs will be recorded on the same entry (if the chronologies match).\n\n\n\nContext\nSample #ID\n\n\n\n\nImola, villa Clelia, 6th c.\n15\n\n\nImola, villa Clelia, 10th-11th c.\n16\n\n\n\nSince the table is context based, each site has been provided with an unique ID, so that if the site has been sampled in different areas the database can be still queried using the site ID4. In addition to the reference to the samples table, the table site_list also contains references to child tables with information about: site type, geography, altitude, coordinates, and region. The samples are organized in three tables, depending on the type of remain that has to be recorded in the database:\n\nplant_remains\npollen_remains\nfaunal_remains\n\nEach entry in the samples tables contains information about chronology, sampling type and notes, reference to the publication, reference to the main site, and the raw data. The tables faunal_chrono_weights and plants_chrono_weights contain the automated calculation of the samples weights (refer to Section 4.5.1). The Figure 4.1 shows the schema with the complete list of tables in the database.\n\n\n\nFigure 4.1: Schema of the database, with the table site_list at the core.\n\n\nThe data was stored in the database after a thorough bibliographical research of the excavated sites (with a chronology pertaining to the 1st millennium CE) where environmental analyses have been undertaken. As in most of the cases the material was retrieved from physical publications, not digitised, the process of data entry was manual and could not be automatised. A list of the publication types where data was retrieved from can be visualised in Figure 4.2.\n\n\n\n\n\n\n\n\nFigure 4.2: Count of the publication types in the database."
  },
  {
    "objectID": "methods.html#sec-periodization",
    "href": "methods.html#sec-periodization",
    "title": "4  Methods",
    "section": "4.5 Periodization",
    "text": "4.5 Periodization\nSome of the statistics performed on the dataset have been based on sample periodization, from the Roman age to the Medieval age. The chronologies have been defined as follows:\n\n[R] Roman: from the 1st century BCE to the 2nd century CE.\n[LR] Late Roman: from the 3rd to the 5th century CE.\n[EMA] Early Middle Ages: from the 6th to the 10th century CE.\n[Ma] Middle Ages: from the 11th century CE onwards.\n\nIn the database, the tables faunal_chronologies and plants_chronologies connect each bioarchaeological sample to another table with the identification numbers for the periods (e.g. Sample 1 = ID 1). If a sample has a chronology ranging between two periods, two separate entries will be recorded on the database (e.g. Sample 1 – 2nd to 3rd c. CE = Periods: Roman, Late Roman) with the result of the sample being repeated in both periods.\n\n\n\nPeriodization schema.\n\n\n\n4.5.1 Chronological fuzziness\nOne of the methodological issues affecting this project is that of chronological fuzziness. Dating plant and animal remains using radiocarbon is very rare, at least in the samples recorded in the database. Most of these samples are dated using ceramics, and chronologies can range between one century or several. Taking this into account, I weighted each sample as follows: \\[ W=\\frac{1}{(C_{end}-C_{start}+1)} \\] Where:\n\n\\(C\\_{end}\\) is the terminus ante quem.\n\\(C\\_{start}\\) is the terminus post quem.\n1 has been summed to the denominator to avoid 0 values.\n\nThe imported tables already contain a column of weights, as this operation has been performed on the database prior the export. A diachronic table of means for both datasets has been generated using the functions:\n\nzooarch_tables (custom)\nBot_mean_table (custom)\nBot_mean_fun (custom)\nweighted.median (from the package spatstat)\n\nThe weight can be used for weighted means and medians, with samples with larger chronologies (hence less precise/fuzzy) weighting less. This method provides each sample with a weight proportional to the length of its chronology so that lower weight values have a smaller impact on the computations."
  },
  {
    "objectID": "methods.html#sec-met-multivariate-statistics",
    "href": "methods.html#sec-met-multivariate-statistics",
    "title": "4  Methods",
    "section": "4.6 Multivariate statistics",
    "text": "4.6 Multivariate statistics\n\n\n\n\n\n\nSection in progress\n\n\n\n\n\n\nThis research uses multivariate analysis to explore possible relationships within the sets of environmental data under investigation. Univariate analyses can be easily plotted and visualized with bar charts, histograms and density curves. A scatterplot (or scattergram) shows the relationship between two variables by plotting their values on the axes of a diagram using Cartesian coordinates. This relationship can also be mathematically measured by calculating a distance between two points in the graph. However, the relationship between more than two variables is much harder to read on a scatterplot, as it would require as many axes as the number of variables. If our analysis is exploratory, we might not know yet where to look for correlations. A possible solution is analysing each combination of two variables in the dataset and measure their correlation. This would require too much computation time if the dataset had a large number of variables, that is to say if we are dealing with big data. In addition, we would only gather information about the relationship between two variables, when there might be another factor influencing a trend or phenomenon. Multivariate statistics has a wide range of applications, including grouping and multidimensional scaling, as well as in machine learning and predictive analysis (Fletcher and Lock (2005)). In this research, multivariate methods have been applied both to the botanical and faunal datasets, mainly with the objective of (i) testing hypotheses between multiple variables and (ii) reducing the dimensionality of data to—assess which variables are the main drivers of change in the datasets and examine relationships between these variables.\n\n4.6.1 Statistical hypothesis testing\nExplain what is hypothesis testing\n\n4.6.1.1 PERMANOVA\nPermutational multivariate analysis of variance (PERMANOVA) is a non-parametric multivariate statistical test used to compare group of objects. By using measure space, the null hypothesis that the centroids and dispersion of groups are identical is tested. The null hypothesis is rejected if either the centroid or the spread of the objects differs between the groups. A prior calculation of the distance between any two objects included in the experiment is used to determine whether the test is valid or not. (Anderson (2017)).\n\n\n\n4.6.2 Dimensionality reduction and ordination\nDimensionality reduction techniques transform high-dimension datasets into a low-dimension ordination space, with the intention of maintaining the geometry and data structure as close as possible to the original dataset. The dimension of a dataset is given by the number of variables (i.e. the columns in the table). As anticipated in Section 4.6, as each variable is graphically represented by an axis, it would be virtually impossible to represent more than three axes in a graph. Ordination allows to reduce data dimensionality to usually one to three (at most) dimensions. Moreover, focusing on a reduced number of dimensions reduces the amount of “noise” that can mislead the interpretation (Gauch (1982)). The points generated through ordination techniques (the objects in our dataset) can eventually be plotted in a scatterplot. In most of the ordination methods, points plotting closer together in graph are more similar, whereas points far apart from each other are more dissimilar (Shennan (1997, p. 197)). For instance, one could perform an ordination on a group of burials in a cemetery where each point represents a single burial assemblage. After the ordination it is also possible to group the new reduced set of variables, to observe differences between groups and facilitate the interpretation. In the previous example, a group might be represented by burials of the same ethnic group, status, etc.\nMany of the ordination techniques described in this chapter developed in fields outside archaeology, and are thus borrowed from disciplines as community ecology. Ecologists regularly apply ordination methods for the study of environmental gradients, so that the term “gradient analysis” is often used interchangeably with “ordination”. An environmental gradient refers to variations in site characteristics (e.g. time, elevation, temperature, vegetation, etc.), which in turn can affect biotic factors (e.g. species abundance, diversity, etc.) (Grebner et al. (2013)). The purpose of ordination is then to identify the cause of ecological processes in the dataset. Generally, it is possible to apply ordination on datasets in which the variables have a cause-and-effect (e.g. climate vs. plant species) or mutual influences on each other. There are two main types of ordination, or gradient analysis, techniques (see Table 4.1): direct (constrained) or indirect (unconstrained). The objective of indirect (unconstrained) gradient analysis is to identify patterns between samples of ‘dependent variables’ (e.g. which sites are more similar according to their species composition). Conversely, direct gradient (or constrained) analysis includes more information (or tables) in a single analysis—the dependent variables are now constrained to be a function of other sets of ‘independent variables’ (usually environmental proxies). In short, a constrained analysis uses both datasets to find the best possible mathematical relationship between the dependent and independent variables. In this sense, direct gradient analysis can be considered as an extension of unconstrained analysis (Syms (2008)). The choice between using constrained or unconstrained methods for ordination strictly depends on the research questions and on the researcher’s dataset.\n\n\nTable 4.1: Ordination methods used in gradient analysis. Table after Cuffney et al. (2014, p. 149)\n\n\n\n\n\n\n\nResponse model\nIndirect gradient analysis\nDirect gradient analysis\n\n\n\n\nLinear\nPrincipal component analysis (PCA)\nRedundancy analysis (RDA)\n\n\nUnimodal\nCorrespondence analysis (CA)\nDetrended CA (DCA)\nCanonical correspondence analysis (CCA)\nDetrended CCA\n\n\nMonotonic\nnon-metric multidimensional scaling (nMDS)\n\n\n\n\n\n\n4.6.2.1 PCA\n\n\n\n\n\n\nEigenvalues and eigenvectors\n\n\n\nBoth PCA and CA are methods based on eigenanalysis. The analysis of eigenvalues and eigenvectors will not be described in detail in this chapter, and the meaning of the terms will be only briefly explained in the text. However, some information must be given for the eigenanalysis-based ordination methods:\n\nThe methods are performed on a square symmetric matrix (for instance a correlation matrix);\nThe order of the variables is not important for the result;\nAxes are ranked according to their eigenvalues (i.e. the first axis has the largest eigenvalue, the second the second-largest, etc.)\nEigenvalues have mathematical meaning that is important for the interpretation of our data.\n\n\n\nPrincipal component analysis (PCA) is an useful tool to identify possible patterns or sub-groups in data. The input variables in the dataset must be numerical (or at least dichotomous). If used for machine learning, PCA is in fact an unsupervised method, meaning that the data points will be unlabelled after the transformation. As for other dimensionality reduction methods, the algorithm tries to preserve the global structure of data by finding a space in which dimensions can be reduced without losing much information. In other words, PCA optimizes the loss of variance. The first step in PCA is creating a correlation matrix or covariance matrix, to extract the eigenvalues and eigenvectors. The decision between correlation or covariance matrix depends on our data and on our research questions. Correlation matrices are helpful if our variables have different units (e.g. lenght, volume, etc.). Covariance matrices can be used if the variables have the same unit and comparable variances. The latter is an important factor to consider before choosing covariance matrices, as the biggest variances will overshadow the others (Carlson (2017, p. 267)). For PCA, the eigenvalues are the variances of the principal components (so that the first component has the largest eigenvalue) and the eigenvectors are the principal component loadings (the score for each variable in the new dimensional space). After extracting the eigenvalues and eigenvectors, the user must decide how many components he will use. The components (defined as the sum in % of the eigenvalues) are the axes in our new dimensional space. Most of the times, the first two components are enough to explain the variance in our dataset. For instance, if the first two axes explain 80% and 12% of the variance, it is acceptable to use a 2D graph—the graphical representation of the two axes will explain 92% of the variance. It is possible to choose the appropriate number of components by using a scree plot, which shows the amount of variance for each component. Scree plots are an important of PCA, because they allow us to see how many components have a significant variance (eigenvalue). A significant variance must be greater than 1. If more than 2 or 3 components have a variance greater than 1, PCA might not be the best method for reducing our set of data. The example in Figure 4.3 shows that PCA in this case is an appropriate method, as only the first two components have variances greater than 1. Therefore we can discard the other components as they are of little significance.\n\n\n\nFigure 4.3: Example of a scree plot showing that only the first two components have a variance greater than 1. Figure after Carlson (2017, p. 271)\n\n\nMost of the statistical packages offer an automatic rotation of the axes for an easier interpretation of the results, which is more important if the data has been standardised prior to the calculations.\n\n4.6.2.1.1 Interpreting a PCA\nPCA are often visualised through biplots, which shows at the same time the scores of the observations (rows) and the loadings of the variables (columns). Generally, the x-axis of the plot represents the first component, and the y-axis the second component. Making sense of the plotted observations is straightforward—points that are closer together are more similar and they can create clusters. It is important to remember that first component of the PCA lays on the x-axis, so differences in clusters on the first component (i.e. the horizontal distance) is actually larger than differences in clusters on the second component (i.e. the vertical distance). Interpreting the variable loadings can be more difficult. The variables are represented by arrows, implying that the variable increases in the direction of the arrow and decreases in the opposite direction. The direction of the arrow is given by the loadings of the first component—if the loadings are negative the arrows will point to the left. If the signs of the loadings are flipped the result will be the same but the arrows will point towards opposite directions. The arrows show how strongly each variable influences a principal component, with longer arrows being the best described in the dimension. The angle between the arrows also indicate extra information useful for the interpretation:\n\nIf two arrows form a small angle, the two variables are positively correlated.\nIf two arrows form a large diverging angle, the two variables are negatively correlated.\nIf two arrows form an angle close to 90°, there might be no correlation at all.\n\nFigure 4.4 shows an example of a PCA biplot. All the arrows (variables) point to the same direction, but we can interpret their correlations using the angles as described above. For example, B1 and B2 are not correlated, as they form an angle of 90°. On the contrary, the variables B and L are positively correlated, as they form a very small angle.\n\n\n\nFigure 4.4: PCA Biplot, after Carlson (2017, p. 274)\n\n\n\n\n\n4.6.2.2 CA\nCorrespondence analysis (CA) is a dimensionality reduction technique that can be applied to contingency tables. Contingency tables (or crosstabs) are two-way tables used to display frequency data formed by two categorical variables. As for PCA, it is an indirect gradient analysis5. Instead of maximizing the variance, CA maximizes the degree of correspondence between rows and columns (i.e. observations and variables). CA is appropriate for exploring non-negative data (e.g. relative abundance, counts, presence/absence) in a contingency table, and examining the relationships between cells in a row, in a column, and their interrelationship (Baxter (2015, p. 101)). Moreover, CA is suited for categorical or qualitative data.\nOn a practical level, CA can be used to compare assemblages from different sites, to answer questions such as “Which sites do certain finds correspond to?” or “Which sites are more similar according to their assemblages?”. This technique is extremely useful for archaeologists, even though its reception by the archaeological community has been slow.\neigenvalues are different from pca eigenvalues\nSensitive to outliers and rare species\nIn R, common implementations of this algorithm are included in the packages MASS, FactoMineR and vegan. Correspondence analysis has been used several times in this research using the function cca() from the vegan package, which was applied to the presence/absence archaeobotanical dataset (**add where else**6). The function cca() performs a canonical correspondence analysis (CCA), but it can also be used for correspondence analysis.\n\n4.6.2.2.1 Interpreting a CA\nCA can also visualised through biplots as for PCA.\n\n\n\n4.6.2.3 nMDS\nMultidimensional scaling (MDS) is a technique to visualise the level of similarity of individual observations (e.g. sites/cases) in a dataset. MDS works with matrices containing Euclidean distances between each pair of observations. Conversely, non-metric multidimensional scaling (nMDS) is a rank-based approach that finds both:\n\nA non-parametric monotonic relationship between the items in the dissimilarity matrix and the Euclidean distances.\nThe location of items in the low-dimensional space.\n\nThe goal of nMDS is to represent the pairwise dissimilarity between items in the matrix as closely as possible. For this reason, it is considered as a good technique for multivariate data visualisation. nMDS can be used on quantitative, qualitative and mixed data. For this project, it has been applied to a subset of the early medieval archaeobotanical dataset that included presence/absence values of cereals. The full breakdown of the process is reported in Section 5.4.2. The R function metaMDS from the package vegan allows users to select the distance metric most appropriate to their data (e.g. Bray-Curtis, Jaccard, etc.). As nMDS is an iterative approach, meaning that the the computations are run until the best solution is found, it can be quite computationally demanding for larger datasets. Although the nMDS algorithm tries to minimize the ordination stress, it is a good practice to compute the ordination stress value to judge the reliability of the solution found (goodness-of-fit). Ordination stress indicates how much distorted are the fitted data when compared to the original observed samples. Stress values can also be visualised with the function stressplot() (vegan package), which produces a Shepard stressplot (Figure 4.5).\n\n\n\nFigure 4.5: A Shepard plot, from R Studio Pubs.\n\n\nThe Shepard plot displays the ordination distance against the observed distance. Ideally, the higher the points should fall on a monotonic line, where an increased observed distance is related to an increased ordination distance. Moreover, the higher the number of dimensions, the lower the stress value. If interested in choosing the appropriate number of dimensions, it is possible to use a scree plot which shows the number of dimensions against the stress level. Generally, it is possible to interpret stress values following these guidelines (Dexter et al. (2018)):\n\n\nTable 4.2: Ordination stress for the interpretation of nMDS\n\n\nInterpretation\nStress level\n\n\n\n\nExcellent\n< 0.05\n\n\nGood\n< 0.1\n\n\nUsable (but caution is required)\n> 0.2\n\n\nRandom\n> 0.3\n\n\n\n\nIf the solution has produced a good stress level for the number of dimensions required, it is possible to plot the nMDS and interpret the results. Points that plot closer together are more similar, while points that are distant one to each other are more different. The nMDS plot can also be useful in recognizing groups (points grouping together and plotting further from other points). An example is provided in Figure 4.6.\n\n\n\nFigure 4.6: A nMDS plot with clusters, from R Studio Pubs.\n\n\n\n\n4.6.2.4 NCA\nThe Neighborhood Component Analysis is a supervised machine learning algorithm for metric learning, developed by Goldberger et al. (2005) at the University of Toronto. The documentation for the Python implementation (package sklearn.neighbors) reports that:\n\nIt learns a linear transformation in a supervised fashion to improve the classification accuracy of a stochastic nearest neighbours rule in the transformed space.\n\nThe algorithm optimizes the overall classification accuracy of multivariate data, and it works in a similar way to the \\(k\\)-Nearest Neighbours (\\(k\\)-NN). NCA is mostly used for distance metric learning, although it can be used as a linear dimensionality reduction technique. Both \\(k\\)-NN and NCA can be applied to non-normal distributions, as they are non-parametric methods (Cardarelli (2022)).\nIn this project, NCA has been applied to the same subset used for the nMDS (which included presence/absence values of cereals), with the scope of dimensionality reduction. The dataset has been reduced to one dimension to show a greater degree of separation between Northern and Southern Italy in the early Middle Ages. The entire process of data preparation and processing is described in Section 5.4.3."
  },
  {
    "objectID": "methods.html#archaeobotany",
    "href": "methods.html#archaeobotany",
    "title": "4  Methods",
    "section": "4.7 Archaeobotany",
    "text": "4.7 Archaeobotany\n\n\n\n\n\n\nSection in progress\n\n\n\nIntroduce the topic\n\n\n\n4.7.1 Methodological issues\n\n\n\n\n\n\nSection in progress\n\n\n\nIssues: problems with the data and general problems in sampling\nBIASES: Talk about the biases and dataset problems here or do it in the Materials chapter?\n\n\nThe data collection process did not present major problems in taxa comparability, since the names of plant were matching. In some cases, it was only possible for the archaeobotanist to specify the name of the species (e.g. Avena sp.), or it was not possible to properly identify the taxa. In the latter case, I reported all the names that can possibly identify the seed (e.g. Triticum aestivum/durum). Quantifications on the archaeobotanical dataset were affected by several biases. The samples in the database have been collected using different variations of visual strategies. Visual sampling occurs when archaeologists can visually see or expect macroremains in the feature they are excavating. Common features from which samples are usually collected include—pits, hearths, filled anforae, etc. But “how can one argue that the contents of a pit reflect activities involving food specific to that context, if one has not examined samples from floor deposits into which the pit was dug, or the deposits overlying it?” (Pearsall (2015) [p.75]). Lennstrom and Hastorf (1995) lament “feature biases” in many archaeological excavations, as paleobotanists are often called after archaeologists have already recovered materials from specific site features. The authors call for a general misconception in the goal of archaeobotany—to collect as many macroremains as possible. This strategy is, in fact, not very informative about the relationships between plant remains and stratigraphic units, and the general deposition patterns in the site. For instance, Jones et al. (1986) were able to reconstruct the functions of structures and the methods of crop storage at Assiros, northern Greece, through a thorough extensive sampling. Pearsall (2015, p. 74) reccommends a “blanket sampling” strategy, which consists in collecting samples for flotation from each stratigraphical unit. The advantages of blanket sampling are manifold:\n\nIf in theory sampling from strategical features (e.g. hearths) maximizes the chances of recovering more macrobotanical remains, in practice this is not always the case. For instance, if a hearth was used on a regular basis, it could possibly have been cleaned of ashes frequently, and the excavator might have more luck sampling around it.\nIncluding the collection of samples from each layer in the excavation leads an uniform and standardised procedure, reducing the variation across samples.\nBlanket sampling allows an easier reconstruction of deposition patterns and of stratigraphic units relations as stated above. For instance, one can analyse differences in macroremains densities across samples.\n\nWhile archaeobotanists have advocated for more specific sampling strategies for over 40 years, none of the Italian excavations in this dataset applied blanket sampling, and sampling from features is still the most common practice.\n\n\n4.7.2 Quantifications\n\n4.7.2.1 Ubiquity\nUbiquity, or presence analysis, is a popular approach in archaeobotanical quantitative analysis. The method is straightforward—the number of sites/contexts where a plant is present is divided by the total number of sites/contexts under examination. If, for instance, an olive pit is present in 3 sites out of 10, the ubiquity for the olive will be 30%. The formula for the calculation is at follows:\n\\[\nU_x = (\\frac{N_p}{N_{tot}}) \\cdot 100\n\\] where \\(N_p\\) is the number of presences, and \\(N_{tot}\\) is the total number of contexts. The result can be multiplied by 100 to obtain a score in %.\nThis approach has both advantages and drawbacks. Presence analysis minimizes the impact of outliers (overrepresented plant species) on calculations (Wright (2010), 51-52), but the relative importance of a plant in a particular context is lost. It is also important to keep in mind that taxa richness is influenced by factors including sample size, deposition and preservation modes, and sampling strategies (e.g. sieving methodologies) (Pearsall (2015), 161-2).\n\nWrite about sample size problems and include a graph\nWrite about deposition and preservation\nWrite about sampling strategies\nWrite about the problems of this dataset that led to the choice of ubiquity as parameter\n\nUbiquity is the best option to immediately read the Italian peninsular botanical dataset. The variability in the seeds/fruits samples is too high, with different species being outliers in different sites. A likely reason for this is probably the poor sampling quality, usually occurring after an agglomerate of seeds is found during excavation. Normally, agglomerates are found in specific storage places or processing areas (e.g. wine/olive processing quarters), skewing the distribution of the curve. Ubiquity overcomes this issue, as it provides a score based on the percentage of presences of a plant species in the samples considered.\nIn addition to the general calculation of the diachronic ubiquity in the entire peninsula, it is also important to look for regional differences in the archaeobotanical dataset. To do so, I created an R function to subset data related to Northern, Central and Southern Italian regions. For a clearer reading of the plot, I divided the plants into–Cereals, Pulses and Fruits/Nuts. The results are in Chapter 5.\n\n\n\n4.7.3 Diversity\n\n\n\n\n\n\nNotes:\n\n\n\nIntroduce the concept of diversity. Why is it useful?\n\n\nSpecies richness (\\(S\\)) is the number of species found within a community or ecosystem. The boundaries of the region are defined by the researcher. While ecologists use sampling or census to obtain the richness value, archaeobotanists can only rely on sampling, counting the presence of species in the area under investigation (Moore (2013)). Species diversity is a measurement of species richness combined with species evenness, meaning it takes into account not only how many species are present but also how evenly distributed the numbers of each species are.\nThere are different ways to calculate species diversity…\nShannon-W"
  },
  {
    "objectID": "methods.html#zooarchaeology",
    "href": "methods.html#zooarchaeology",
    "title": "4  Methods",
    "section": "4.8 Zooarchaeology",
    "text": "4.8 Zooarchaeology\n\n\n\n\n\n\nSection in progress\n\n\n\n\n\n\n\n\n\n\nAnderson, M.J., 2017. Permutational Multivariate Analysis of Variance (PERMANOVA). In: Wiley StatsRef: Statistics Reference Online. John Wiley & Sons, Ltd, pp. 1–15.\n\n\nBaxter, M.J., 2015. Exploratory multivariate analysis in archaeology, Foundations of archaeology. Percheron Press, a division of Eliot Werner Publications, Inc, Clinton Corners, New York.\n\n\nBoscato, P., Fronza, V., Salvadori, F., 2007. Proposta di un database per i reperti faunistici. In: Fiore, I., Malerba, G., Chilardi, S. (Eds.), Atti Del 3 Convegno Nazionale Di Archeozoologia. Siracusa 3-5 Novembre 2000. Istituto Poligrafico e Zecca dello Stato, Roma, pp. 1–14.\n\n\nCardarelli, L., 2022. A deep variational convolutional Autoencoder for unsupervised features extraction of ceramic profiles. A case study from central Italy. Journal of Archaeological Science 144, 105640.\n\n\nCarlson, D.L., 2017. Quantitative methods in archaeology using R, Cambridge University Press. ed, Cambridge Manuals in Archaeology. Cambridge.\n\n\nCuffney, T.F., Kennen, J.G., Waite, I.R., 2014. Aquatic Ecosystems as Indicators of Status and Trends in Water Quality. In: Comprehensive Water Quality and Purification. Elsevier, pp. 122–156.\n\n\nDexter, E., Rollwagen-Bollens, G., Bollens, S.M., 2018. The trouble with stress: A flexible method for the evaluation of nonmetric multidimensional scaling: The Trouble with Stress. Limnology and Oceanography: Methods 16, 434–443.\n\n\nFiguera, M., 2018. Database management e dati archeologici: standardizzazione e applicazione della logica fuzzy alla gestione delle fonti e delle attribuzioni tipologiche. Archeologia e Calcolatori 29, 143–160.\n\n\nFletcher, M., Lock, G.R., 2005. Digging numbers: Elementary statistics for archaeologists, 2nd ed. ed, Monograph (Oxford University School of Archaeology). Oxford University Committee for Archaeology, Oxford : Oakville, CT.\n\n\nGattiglia, G., 2018. Databases in Archaeology. In: López Varela, S.L. (Ed.), The Encyclopedia of Archaeological Sciences. John Wiley & Sons, Inc., Hoboken, NJ, USA, pp. 1–4.\n\n\nGauch, H.G., 1982. Multivariate Analysis in Community Ecology, First. ed. Cambridge University Press.\n\n\nGoldberger, J., Hinton, G.E., Roweis, S., Salakhutdinov, R.R., 2005. Neighbourhood components analysis. In: Saul, L.K., Weiss, Y., Bottou, L. (Eds.), Advances in Neural Information Processing Systems. Bradford Books, Vancouver, pp. 513–520.\n\n\nGrebner, D.L., Bettinger, P., Siry, J.P., 2013. Forest Dynamics. In: Introduction to Forestry and Natural Resources. Elsevier, pp. 243–254.\n\n\nHarris, C.R., Millman, K.J., van der Walt, S.J., Gommers, R., Virtanen, P., Cournapeau, D., Wieser, E., Taylor, J., Berg, S., Smith, N.J., Kern, R., Picus, M., Hoyer, S., van Kerkwijk, M.H., Brett, M., Haldane, A., del Río, J.F., Wiebe, M., Peterson, P., Gérard-Marchant, P., Sheppard, K., Reddy, T., Weckesser, W., Abbasi, H., Gohlke, C., Oliphant, T.E., 2020. Array programming with NumPy. Nature 585, 357–362.\n\n\nHunter, J.D., 2007. Matplotlib: A 2D graphics environment. Computing in science & engineering 9, 90–95.\n\n\nJones, G., Wardle, K., Halstead, P., Wardle, D., 1986. Crop Storage at Assiros. Scientific American 254, 96–103.\n\n\nLauro, C., 1996. Computational statistics or statistical computing, is that the question? Computational Statistics & Data Analysis, Classification 23, 191–193.\n\n\nLennstrom, H.A., Hastorf, C.A., 1995. Interpretation in context: Sampling and analysis in paleoethnobotany. American Antiquity 60, 701–721.\n\n\nMercuri, A.M., Allevato, E., Arobba, D., Bandini Mazzanti, M., Bosi, G., Caramiello, R., Castiglioni, E., Carra, M.L., Celant, A., Costantini, L., Di Pasquale, G., Fiorentino, G., Florenzano, A., Guido, M., Marchesini, M., Mariotti Lippi, M., Marvelli, S., Miola, A., Montanari, C., Nisbet, R., Peña-Chocarro, L., Perego, R., Ravazzi, C., Rottoli, M., Sadori, L., Ucchesu, M., Rinaldi, R., 2015. Pollen and macroremains from Holocene archaeological sites: A dataset for the understanding of the bio-cultural diversity of the Italian landscape. Review of Palaeobotany and Palynology 218, 250–266.\n\n\nMoore, J.C., 2013. Diversity, taxonomic versus functional. In: Encyclopedia of Biodiversity. Elsevier, pp. 648–656.\n\n\nNiccolucci, F., 2020. ARIADNEplus: L’avventura continua. DigItalia 2, 88–95.\n\n\nOksanen, J., Simpson, G.L., Blanchet, F.G., Kindt, R., Legendre, P., Minchin, P.R., O’Hara, R.B., Solymos, P., Stevens, M.H.H., Szoecs, E., Wagner, H., Barbour, M., Bedward, M., Bolker, B., Borcard, D., Carvalho, G., Chirico, M., Caceres, M.D., Durand, S., Evangelista, H.B.A., FitzJohn, R., Friendly, M., Furneaux, B., Hannigan, G., Hill, M.O., Lahti, L., McGlinn, D., Ouellette, M.-H., Cunha, E.R., Smith, T., Stier, A., Braak, C.J.F.T., Weedon, J., 2022. Vegan: Community ecology package.\n\n\nPearsall, D.M., 2015. Paleoethnobotany: A handbook of procedures, Third edition. ed. Left Coast Press Inc, Walnut Creek, California.\n\n\nPedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., Duchesnay, É., 2011. Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research 12, 2825–2830.\n\n\nReback, J., jbrockmendel, McKinney, W., Bossche, J.V. den, Roeschke, M., Augspurger, T., Hawkins, S., Cloud, P., gfyoung, Sinhrks, Hoefler, P., Klein, A., Petersen, T., Tratner, J., She, C., Ayd, W., Naveh, S., Darbyshire, J.H.M., Shadrach, R., Garcia, M., Schendel, J., Hayden, A., Saxton, D., Gorelli, M.E., Li, F., Wörtwein, T., Zeitlin, M., Jancauskas, V., McMaster, A., Li, T., 2022. Pandas-dev/pandas: Pandas 1.4.3.\n\n\nRichards, J.D., 2021. Archiving Archaeological Data in the United Kingdom. Internet Archaeology 58.\n\n\nRizzo, M.L., 2019. Statistical Computing with R, Second. ed. Chapman and Hall/CRC, New York.\n\n\nShennan, S., 1997. Quantifying archaeology, 2nd ed. ed. Edinburgh University Press, Edinburgh.\n\n\nSyms, C., 2008. Ordination. In: Encyclopedia of Ecology. Elsevier, pp. 2572–2581.\n\n\nVirtanen, P., Gommers, R., Oliphant, T.E., Haberland, M., Reddy, T., Cournapeau, D., Burovski, E., Peterson, P., Weckesser, W., Bright, J., 2020. SciPy 1.0: Fundamental algorithms for scientific computing in Python. Nature methods 17, 261–272.\n\n\nWaskom, M.L., 2021. Seaborn: Statistical data visualization. Journal of Open Source Software 6, 3021.\n\n\nWickham, H., 2016. Programming with Ggplot2. In: Wickham, H. (Ed.), Ggplot2: Elegant Graphics for Data Analysis, Use R! Springer International Publishing, Cham, pp. 241–253.\n\n\nWickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L.D., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T.L., Miller, E., Bache, S.M., Müller, K., Ooms, J., Robinson, D., Seidel, D.P., Spinu, V., Takahashi, K., Vaughan, D., Wilke, C., Woo, K., Yutani, H., 2019. Welcome to the tidyverse 4, 1686.\n\n\nWright, P.J., 2010. Methodological Issues in Paleoethnobotany: A consideration of Issues, Methods, and Cases. In: VanDerwarker, A.M., Peres, T.M. (Eds.), Integrating Zooarchaeology and Paleoethnobotany: A Consideration of Issues, Methods, and Cases. Springer New York, New York, NY, pp. 37–64.\n\n\nXie, Y., 2021. Knitr: A general-purpose package for dynamic report generation in r."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Page under construction"
  },
  {
    "objectID": "literature_review.html",
    "href": "literature_review.html",
    "title": "2  Literature Review",
    "section": "",
    "text": "Page under construction"
  },
  {
    "objectID": "literature_review.html#introduction",
    "href": "literature_review.html#introduction",
    "title": "2  Literature Review",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction"
  },
  {
    "objectID": "literature_review.html#continuity-vs-rupture",
    "href": "literature_review.html#continuity-vs-rupture",
    "title": "2  Literature Review",
    "section": "2.2 Continuity vs rupture",
    "text": "2.2 Continuity vs rupture"
  },
  {
    "objectID": "literature_review.html#environmental-archaeology",
    "href": "literature_review.html#environmental-archaeology",
    "title": "2  Literature Review",
    "section": "2.3 Environmental archaeology",
    "text": "2.3 Environmental archaeology\nMaybe move the processual arch. part somewhere here or create a general ‘science in arch’ section\n\n2.3.1 Archaeobotany\nName origin: Archaeobotany, paleobotany, paleoethnobotany…\n\n\n2.3.2 Zooarchaeology\nClassical intro with name zooarchaeology vs archaeozoology"
  },
  {
    "objectID": "literature_review.html#landscape-studies",
    "href": "literature_review.html#landscape-studies",
    "title": "2  Literature Review",
    "section": "2.4 Landscape studies",
    "text": "2.4 Landscape studies"
  },
  {
    "objectID": "literature_review.html#diet-studies",
    "href": "literature_review.html#diet-studies",
    "title": "2  Literature Review",
    "section": "2.5 Diet studies",
    "text": "2.5 Diet studies"
  },
  {
    "objectID": "literature_review.html#big-data-in-archaeology",
    "href": "literature_review.html#big-data-in-archaeology",
    "title": "2  Literature Review",
    "section": "2.6 Big data in archaeology",
    "text": "2.6 Big data in archaeology"
  },
  {
    "objectID": "literature_review.html#statistical-analysis-in-archaeology",
    "href": "literature_review.html#statistical-analysis-in-archaeology",
    "title": "2  Literature Review",
    "section": "2.7 Statistical analysis in archaeology",
    "text": "2.7 Statistical analysis in archaeology\nGeneral introduction (Shennan?)\nIn archaeology, multivariate statistics has been applied since the mid-60s, when the spread of computers and statistical packages made these methods more easily applicable. The growing popularity of computational archaeology in this period also owes a great debt to the New Archaeology movement (or Processual archaeology). New Archaeology emphasized the application of rigorous scientific analysis at the expense of the cultural historical approach which focused on artifacts cataloging based on ethnic grouping (Binford and Binford (1968)).\nInclude Baxter and Drennan"
  },
  {
    "objectID": "literature_review.html#conclusions",
    "href": "literature_review.html#conclusions",
    "title": "2  Literature Review",
    "section": "2.8 Conclusions",
    "text": "2.8 Conclusions\n\n\n\n\nBinford, S.R., Binford, L., 1968. New Perspectives in Archaeology. Aldline Press, Chicago."
  },
  {
    "objectID": "materials.html",
    "href": "materials.html",
    "title": "3  Materials",
    "section": "",
    "text": "Page under construction\n\n\n\nThis page will probably be merged with “Methods”"
  },
  {
    "objectID": "materials.html#introduction",
    "href": "materials.html#introduction",
    "title": "3  Materials",
    "section": "3.1 Introduction",
    "text": "3.1 Introduction\n\n\n\n\n\n\nSection in progress"
  },
  {
    "objectID": "materials.html#archaeobotany",
    "href": "materials.html#archaeobotany",
    "title": "3  Materials",
    "section": "3.2 Archaeobotany",
    "text": "3.2 Archaeobotany\n\n\n\n\n\n\nSection in progress\n\n\n\n\n\n\nShould the maps be here?\n\n3.2.1 Carpology\n\n3.2.1.1 Database storing procedures\n\n\n\n3.2.2 Palinology\n\n3.2.2.1 Database storing procedures"
  },
  {
    "objectID": "materials.html#zooarchaeology",
    "href": "materials.html#zooarchaeology",
    "title": "3  Materials",
    "section": "3.3 Zooarchaeology",
    "text": "3.3 Zooarchaeology\n\n\n\n\n\n\nSection in progress\n\n\n\n\n\n\nShould the maps be here?\n\n3.3.1 Database storing procedures"
  },
  {
    "objectID": "archaeobotany.html",
    "href": "archaeobotany.html",
    "title": "5  Archaeobotany",
    "section": "",
    "text": "In this chapter, I will present the macrobotanical data from 170 case studies used to carry on this research (Chapter 3), along with the quantifications performed on the absolute counts. The data will be first presented temporally, and a discussion of the diachronic trends will follow at the end of the chapter."
  },
  {
    "objectID": "archaeobotany.html#case-studies",
    "href": "archaeobotany.html#case-studies",
    "title": "5  Archaeobotany",
    "section": "5.1 Case studies",
    "text": "5.1 Case studies\nThe following map shows the sites under investigation, divided by chronology. Please select the desired chronology (or chronologies) from the legend on the right.\n\n\n\n\n\n\n\n\n\n\n\nFigure 5.1: Legend: R = Roman, LR = Late Roman, EMA = Early Middle Ages, Ma = 11th c. onwards"
  },
  {
    "objectID": "archaeobotany.html#ubiquity",
    "href": "archaeobotany.html#ubiquity",
    "title": "5  Archaeobotany",
    "section": "5.2 Ubiquity",
    "text": "5.2 Ubiquity\nIn Chapter 4 ubiquity has been described as the best way to present the archaeobotanical remains from the Italian peninsula, given the numerous biases in the samples. The heatmap below (Figure 5.2) provides a good overview of the temporal trends of presence of cereals, legumes, fruits and nuts in the entire area under examination.\n\n\n\n\n\nShow the code\n# Load the libraries\n# Note: these libraries are used for the data visualizations in this page.\nlibrary(RColorBrewer)\nlibrary(reshape2)\nlibrary(ggplot2)\nlibrary(hrbrthemes)\nlibrary(plotly)\nlibrary(patchwork)\n\n## UBIQUITY\n\n## Creating a dataframe that contains the ubiquity of each century under examination. \nUbiquity_table <- data.frame(\n  \"I BCE\" = archaeobotany_tables(plants_export, -1)$Ubiquity_exp,  \n  \"I CE\" = archaeobotany_tables(plants_export, 1)$Ubiquity_exp,\n  \"II CE\" = archaeobotany_tables(plants_export, 2)$Ubiquity_exp,\n  \"III CE\" = archaeobotany_tables(plants_export, 3)$Ubiquity_exp,\n  \"IV CE\" = archaeobotany_tables(plants_export, 4)$Ubiquity_exp,\n  \"V CE\" = archaeobotany_tables(plants_export, 5)$Ubiquity_exp,\n  \"VI CE\" = archaeobotany_tables(plants_export, 6)$Ubiquity_exp,\n  \"VII CE\" = archaeobotany_tables(plants_export, 7)$Ubiquity_exp,\n  \"VIII CE\" = archaeobotany_tables(plants_export, 8)$Ubiquity_exp,\n  \"IX CE\" = archaeobotany_tables(plants_export, 9)$Ubiquity_exp,\n  \"X CE\" = archaeobotany_tables(plants_export, 10)$Ubiquity_exp,\n  \"XI CE\" = archaeobotany_tables(plants_export, 11)$Ubiquity_exp\n  )\n\n# Transform the ubiquity table into a matrix\nUbiquity_mat <- as.matrix(Ubiquity_table) \n\n# Rename the centuries\ncolnames(Ubiquity_mat) <- c(\"1st c. BCE\", \"1st c. CE\", \"2nd c. CE\",\n                            \"3rd c. CE\", \"4th c. CE\", \"5th c. CE\",\n                            \"6th c. CE\", \"7th c. CE\", \"8th c. CE\",\n                            \"9th c. CE\", \"10th c. CE\", \"11th c. CE\") \n\n# The data has to be molten to use it with ggplot2\n# (package: reshape2)\nUbiquity_melt <- melt(Ubiquity_mat)\n\n# Let's now rename the columns \ncolnames(Ubiquity_melt) <- c(\"Taxon\", \"Century\", \"Ubiquity\")\n\n# Add a column for the text tooltip\nUbiquity_melt <- Ubiquity_melt %>%\n  mutate(text = paste0(\"Taxon: \", Taxon, \"\\n\", \"Century: \", Century, \"\\n\", \"Value: \",round(Ubiquity,2)))\n\n# Create the heatmap with ggplot2\nUbiquity_HM <- ggplot(Ubiquity_melt, aes(Century, Taxon, fill=Ubiquity, text=text)) + \n  geom_tile(colour=\"white\") +\n  scale_alpha(range=c(0,1)) +\n  scale_x_discrete(\"\", expand = c(0, 0)) + \n  scale_y_discrete(\"\", expand = c(0, 0)) + \n  theme_grey(base_size = 9) + \n  theme(legend.position = \"right\",\n        axis.ticks = element_blank(), \n        axis.text.x = element_text(angle = 90, hjust = 0)\n        ) +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+\n  labs(\n    title=\"Ubiquity\",\n    subtitle=\"Diachronical heatmap of recorded plant species\"\n  ) +\n  scale_fill_gradient(low = \"white\", high = \"black\")\n\n\n\n\n\n\n\nFigure 5.2: Diachronical heatmap of recorded plant species\n\n\n\n\n5.2.1 Macroregional differences\nThe heatmap displayed in Figure 5.2 presents diachronical ubiquity values of the entire peninsula. However, it is also possible to look at the macroregional differences in plants ubiquities. The R function Ubiquity_macroreg_chrono() (Section 1.3) was created to subset data related to (current) Northern, Central and Southern Italian regions. Subsetting the dataset required a larger chronological division to obtain enough sites for a statistical interpretation of the results. The ubiquity values are presented using the variable Chronology rather than the individual centuries. For a clearer reading of the plot, the taxa have been divided into–Cereals, Pulses and Fruits/Nuts. Some taxa have been omitted from the plot.\nSource code:\n\n\nShow the code: data preparation\n# Ubiquity by Italian Macro regions: Northern, Central and Southern Italy\n\n# Load the libraries\nlibrary(vegan)\nlibrary(matrixStats)\nlibrary(patchwork)\n\n# Creating a dataframe with the ubiquities of all macroregions and chronologies\nbot_macroreg <- rbind(\n  Ubiquity_R_NI <- Ubiquity_macroreg_chrono(Archaeobot_Condensed,\"Northern Italy\", \"R\"),\n  Ubiquity_R_CI <- Ubiquity_macroreg_chrono(Archaeobot_Condensed,\"Central Italy\", \"R\"),\n  Ubiquity_R_SI <- Ubiquity_macroreg_chrono(Archaeobot_Condensed,\"Southern Italy\", \"R\"),\n  Ubiquity_LR_NI <- Ubiquity_macroreg_chrono(Archaeobot_Condensed,\"Northern Italy\", \"LR\"),\n  Ubiquity_LR_CI <- Ubiquity_macroreg_chrono(Archaeobot_Condensed,\"Central Italy\", \"LR\"),\n  Ubiquity_LR_SI <- Ubiquity_macroreg_chrono(Archaeobot_Condensed,\"Southern Italy\", \"LR\"),\n  Ubiquity_EMA_NI <- Ubiquity_macroreg_chrono(Archaeobot_Condensed,\"Northern Italy\", \"EMA\"),\n  Ubiquity_EMA_CI <- Ubiquity_macroreg_chrono(Archaeobot_Condensed,\"Central Italy\", \"EMA\"),\n  Ubiquity_EMA_SI <- Ubiquity_macroreg_chrono(Archaeobot_Condensed,\"Southern Italy\", \"EMA\"),\n  Ubiquity_Ma_NI <- Ubiquity_macroreg_chrono(Archaeobot_Condensed,\"Northern Italy\", \"Ma\"),\n  Ubiquity_Ma_CI <- Ubiquity_macroreg_chrono(Archaeobot_Condensed,\"Central Italy\", \"Ma\"),\n  Ubiquity_Ma_SI <- Ubiquity_macroreg_chrono(Archaeobot_Condensed,\"Southern Italy\", \"Ma\")\n)\n\n# Re-arranging the cereals/macroregions for visualisation on the Y axis\nlevel_macroreg_order <- c(\"Southern Italy\", \"Central Italy\", \"Northern Italy\")\n\nlevel_cereals_order <- c(\"Common.Wheat\", \"Barley\", \"Rye\", \n                         \"Einkorn\", \"Emmer\", \"Proso.millet\", \n                         \"Foxtail.millet\", \"Oats\", \"Sorghum\")\n\n# Cereals\ncer_ubiquity_macroreg.R <- filter(bot_macroreg, Chronology==\"R\" & Plant.Type==\"Cereals\")\ncer_ubiquity_macroreg.R <- filter(cer_ubiquity_macroreg.R, Macroregion!=\"Central Italy\")\ncer_ubiquity_macroreg.LR <- filter(bot_macroreg, Chronology==\"LR\" & Plant.Type==\"Cereals\")\ncer_ubiquity_macroreg.EMA <- filter(bot_macroreg, Chronology==\"EMA\" & Plant.Type==\"Cereals\")\ncer_ubiquity_macroreg.Ma <- filter(bot_macroreg, (Chronology==\"Ma\" & Plant.Type==\"Cereals\"))\ncer_ubiquity_macroreg.Ma <- filter(cer_ubiquity_macroreg.Ma, Macroregion!=\"Southern Italy\")\n\n#Pulses\npuls_ubiquity_macroreg.R <- filter(bot_macroreg, Chronology==\"R\" & Plant.Type==\"Pulses\")\npuls_ubiquity_macroreg.R <- filter(puls_ubiquity_macroreg.R, Macroregion!=\"Central Italy\")\npuls_ubiquity_macroreg.R <- filter(puls_ubiquity_macroreg.R, Plant!=\"Chickpea\")\npuls_ubiquity_macroreg.LR <- filter(bot_macroreg, Chronology==\"LR\" & Plant.Type==\"Pulses\")\npuls_ubiquity_macroreg.LR <- filter(puls_ubiquity_macroreg.LR, \n                                    Macroregion!=\"Southern Italy\")\npuls_ubiquity_macroreg.LR <- filter(puls_ubiquity_macroreg.LR, Plant!=\"Chickpea\")\npuls_ubiquity_macroreg.EMA <- filter(bot_macroreg, Chronology==\"EMA\" & Plant.Type==\"Pulses\")\npuls_ubiquity_macroreg.Ma <- filter(bot_macroreg, Chronology==\"Ma\"  & Plant.Type==\"Pulses\")\npuls_ubiquity_macroreg.Ma <- filter(puls_ubiquity_macroreg.Ma, \n                                    Macroregion!=\"Southern Italy\")\n\n#Fruits (+ Subset)\nfnuts_ubiquity_macroreg.R <- filter(bot_macroreg, Chronology==\"R\" & Plant.Type==\"Fruits/Nuts\")\nfnuts_ubiquity_macroreg.R <- subset(fnuts_ubiquity_macroreg.R, (Plant == \"Wild.Cherry\" | Plant == \"Walnut\" | Plant == \"Peach\" | Plant == \"Olive\" |Plant == \"Grape\" | Plant ==\"Fig\" | Plant ==\"Apple\"))\nfnuts_ubiquity_macroreg.R <- filter(fnuts_ubiquity_macroreg.R, Macroregion!=\"Central Italy\")\nfnuts_ubiquity_macroreg.LR <- filter(bot_macroreg, Chronology==\"LR\" & Plant.Type==\"Fruits/Nuts\")\nfnuts_ubiquity_macroreg.LR <- subset(fnuts_ubiquity_macroreg.LR, (Plant == \"Wild.Cherry\" | Plant == \"Walnut\" | Plant == \"Peach\" | Plant == \"Olive\" |Plant == \"Grape\" | Plant ==\"Fig\" | Plant ==\"Apple\"))\nfnuts_ubiquity_macroreg.EMA <- filter(bot_macroreg, Chronology==\"EMA\" & Plant.Type==\"Fruits/Nuts\")\nfnuts_ubiquity_macroreg.EMA <- subset(fnuts_ubiquity_macroreg.EMA, (Plant == \"Wild.Cherry\" | Plant == \"Walnut\" | Plant == \"Peach\" | Plant == \"Olive\" |Plant == \"Grape\" | Plant ==\"Fig\" | Plant ==\"Apple\"))\nfnuts_ubiquity_macroreg.Ma <- filter(bot_macroreg, Chronology==\"Ma\"  & Plant.Type==\"Fruits/Nuts\")\nfnuts_ubiquity_macroreg.Ma <- subset(fnuts_ubiquity_macroreg.Ma, (Plant == \"Wild.Cherry\" | Plant == \"Walnut\" | Plant == \"Peach\" | Plant == \"Olive\" |Plant == \"Grape\" | Plant ==\"Fig\" | Plant ==\"Apple\"))\nfnuts_ubiquity_macroreg.Ma <- filter(fnuts_ubiquity_macroreg.Ma, Macroregion!=\"Southern Italy\")\n\n\n\n\nShow the code: plots\n# Cereals plots ubiquity\ncer_ubiquity_macroreg_R.HM <- ggplot(cer_ubiquity_macroreg.R, aes(\n  factor(Macroregion, levels=(level_macroreg_order)),\n  factor(Plant, levels=rev(level_cereals_order)),\n  fill=(Ubiquity)\n)) + \n  geom_tile(colour=\"white\") +\n  geom_text(aes(label = Ubiquity), colour=\"white\", size=3)+ \n  scale_alpha(range=c(0,1)) +\n  scale_x_discrete(\"\", expand = c(0, 0)) + \n  scale_y_discrete(\"\", expand = c(0, 0)) + \n  theme_grey(base_size = 9) + \n  theme(legend.position = \"none\",\n        axis.ticks = element_blank()\n  ) +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+\n  labs(\n    title=\"Roman\"\n  ) +  scale_fill_gradient(low = \"white\", high = \"black\")\n\n\ncer_ubiquity_macroreg_LR.HM <- ggplot(cer_ubiquity_macroreg.LR, aes(\n  factor(Macroregion, levels=(level_macroreg_order)),\n  factor(Plant, levels=rev(level_cereals_order)),\n  fill=(Ubiquity)\n)) + \n  geom_tile(colour=\"white\") +\n  geom_text(aes(label = Ubiquity), colour=\"white\", size=3)+ \n  scale_alpha(range=c(0,1)) +\n  scale_x_discrete(\"\", expand = c(0, 0)) + \n  scale_y_discrete(\"\", expand = c(0, 0)) + \n  theme_grey(base_size = 9) + \n  theme(legend.position = \"none\",\n        axis.ticks = element_blank()\n  ) +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+\n  labs(\n    title=\"Late Roman\"\n  ) +  scale_fill_gradient(low = \"white\", high = \"black\")\n\ncer_ubiquity_macroreg_EMA.HM <- ggplot(cer_ubiquity_macroreg.EMA, aes(\n  factor(Macroregion, levels=(level_macroreg_order)),\n  factor(Plant, levels=rev(level_cereals_order)),\n  fill=(Ubiquity)\n)) + \n  geom_tile(colour=\"white\") +\n  geom_text(aes(label = Ubiquity), colour=\"white\", size=3)+ \n  scale_alpha(range=c(0,1)) +\n  scale_x_discrete(\"\", expand = c(0, 0)) + \n  scale_y_discrete(\"\", expand = c(0, 0)) + \n  theme_grey(base_size = 9) + \n  theme(legend.position = \"none\",\n        axis.ticks = element_blank()\n  ) +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+\n  labs(\n    title=\"Early Medieval\"\n  ) +  scale_fill_gradient(low = \"white\", high = \"black\")\n\ncer_ubiquity_macroreg_Ma.HM <- ggplot(cer_ubiquity_macroreg.Ma, aes(\n  factor(Macroregion, levels=(level_macroreg_order)),\n  factor(Plant, levels=rev(level_cereals_order)),\n  fill=(Ubiquity)\n)) + \n  geom_tile(colour=\"white\") +\n  geom_text(aes(label = Ubiquity), colour=\"white\", size=3)+ \n  scale_alpha(range=c(0,1)) +\n  scale_x_discrete(\"\", expand = c(0, 0)) + \n  scale_y_discrete(\"\", expand = c(0, 0)) + \n  theme_grey(base_size = 9) + \n  theme(legend.position = \"none\",\n        axis.ticks = element_blank()\n  ) +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+\n  labs(\n    title=\"Medieval\"\n  ) +  scale_fill_gradient(low = \"white\", high = \"black\")\n\n\nCereals_Ubiquity_MacroReg_Patchwork <- (cer_ubiquity_macroreg_R.HM|cer_ubiquity_macroreg_LR.HM)/(cer_ubiquity_macroreg_EMA.HM|cer_ubiquity_macroreg_Ma.HM)\nCereals_Ubiquity_MacroReg_Patchwork + plot_annotation(\n  title = 'Cereals',\n  subtitle = 'Ubiquity (%), plotted by macroregion and chronology.',\n  caption='Note: Data was too scarce for Roman Central Italy and Medieval Southern Italy.'\n  )\n\n\nShow the code: plots\n# Pulses plots ubiquity\npuls_ubiquity_macroreg_R.HM <- ggplot(puls_ubiquity_macroreg.R, aes(\n  factor(Macroregion, levels=(level_macroreg_order)),\n  Plant,\n  fill=(Ubiquity)\n)) + \n  geom_tile(colour=\"white\") +\n  geom_text(aes(label = Ubiquity), colour=\"#cfcfcf\", size=3)+ \n  scale_alpha(range=c(0,1)) +\n  scale_x_discrete(\"\", expand = c(0, 0)) + \n  scale_y_discrete(\"\", expand = c(0, 0)) + \n  theme_grey(base_size = 9) + \n  theme(legend.position = \"none\",\n        axis.ticks = element_blank()\n  ) +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+\n  labs(\n    title=\"Roman\"\n  ) +  scale_fill_gradient(low = \"white\", high = \"black\")\n\n\npuls_ubiquity_macroreg_LR.HM <- ggplot(puls_ubiquity_macroreg.LR, aes(\n  factor(Macroregion, levels=(level_macroreg_order)),\n  Plant,\n  fill=(Ubiquity)\n)) + \n  geom_tile(colour=\"white\") +\n  geom_text(aes(label = Ubiquity), colour=\"#ffffff\", size=3)+ \n  scale_alpha(range=c(0,1)) +\n  scale_x_discrete(\"\", expand = c(0, 0)) + \n  scale_y_discrete(\"\", expand = c(0, 0)) + \n  theme_grey(base_size = 9) + \n  theme(legend.position = \"none\",\n        axis.ticks = element_blank()\n  ) +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+\n  labs(\n    title=\"Late Roman\"\n  ) +  scale_fill_gradient(low = \"white\", high = \"black\")\n\npuls_ubiquity_macroreg_EMA.HM <- ggplot(puls_ubiquity_macroreg.EMA, aes(\n  factor(Macroregion, levels=(level_macroreg_order)),\n  Plant,\n  fill=(Ubiquity)\n)) + \n  geom_tile(colour=\"white\") +\n  geom_text(aes(label = Ubiquity), colour=\"white\", size=3)+ \n  scale_alpha(range=c(0,1)) +\n  scale_x_discrete(\"\", expand = c(0, 0)) + \n  scale_y_discrete(\"\", expand = c(0, 0)) + \n  theme_grey(base_size = 9) + \n  theme(legend.position = \"none\",\n        axis.ticks = element_blank()\n  ) +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+\n  labs(\n    title=\"Early Medieval\"\n  ) +  scale_fill_gradient(low = \"white\", high = \"black\")\n\npuls_ubiquity_macroreg_Ma.HM <- ggplot(puls_ubiquity_macroreg.Ma, aes(\n  factor(Macroregion, levels=(level_macroreg_order)),\n  Plant,\n  fill=(Ubiquity)\n)) + \n  geom_tile(colour=\"white\") +\n  geom_text(aes(label = Ubiquity), colour=\"white\", size=3)+ \n  scale_alpha(range=c(0,1)) +\n  scale_x_discrete(\"\", expand = c(0, 0)) + \n  scale_y_discrete(\"\", expand = c(0, 0)) + \n  theme_grey(base_size = 9) + \n  theme(legend.position = \"none\",\n        axis.ticks = element_blank()\n  ) +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+\n  labs(\n    title=\"Medieval\"\n  ) +  scale_fill_gradient(low = \"white\", high = \"black\")\n\n\nPulses_Ubiquity_MacroReg_Patchwork <- (puls_ubiquity_macroreg_R.HM|puls_ubiquity_macroreg_LR.HM)/(puls_ubiquity_macroreg_EMA.HM|puls_ubiquity_macroreg_Ma.HM)\nPulses_Ubiquity_MacroReg_Patchwork + plot_annotation(\n  title = 'Pulses',\n  subtitle = 'Ubiquity (%), plotted by macroregion and chronology.',\n  caption='Note: Data was too scarce for Roman Central Italy and Late Roman/Medieval Southern Italy.'\n)\n\n\nShow the code: plots\n# Fruits nuts plots\n\nfnuts_ubiquity_macroreg_R.HM <- ggplot(fnuts_ubiquity_macroreg.R, aes(\n  factor(Macroregion, levels=(level_macroreg_order)),\n  Plant,\n  fill=(Ubiquity)\n)) + \n  geom_tile(colour=\"white\") +\n  geom_text(aes(label = Ubiquity), colour=\"white\", size=3)+ \n  scale_alpha(range=c(0,1)) +\n  scale_x_discrete(\"\", expand = c(0, 0)) + \n  scale_y_discrete(\"\", expand = c(0, 0)) + \n  theme_grey(base_size = 9) + \n  theme(legend.position = \"none\",\n        axis.ticks = element_blank()\n  ) +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+\n  labs(\n    title=\"Roman\"\n  ) +  scale_fill_gradient(low = \"white\", high = \"black\")\n\n\nfnuts_ubiquity_macroreg_LR.HM <- ggplot(fnuts_ubiquity_macroreg.LR, aes(\n  factor(Macroregion, levels=(level_macroreg_order)),\n  Plant,\n  fill=(Ubiquity)\n)) + \n  geom_tile(colour=\"white\") +\n  geom_text(aes(label = Ubiquity), colour=\"white\", size=3)+ \n  scale_alpha(range=c(0,1)) +\n  scale_x_discrete(\"\", expand = c(0, 0)) + \n  scale_y_discrete(\"\", expand = c(0, 0)) + \n  theme_grey(base_size = 9) + \n  theme(legend.position = \"none\",\n        axis.ticks = element_blank()\n  ) +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+\n  labs(\n    title=\"Late Roman\"\n  ) +  scale_fill_gradient(low = \"white\", high = \"black\")\n\nfnuts_ubiquity_macroreg_EMA.HM <- ggplot(fnuts_ubiquity_macroreg.EMA, aes(\n  factor(Macroregion, levels=(level_macroreg_order)),\n  Plant,\n  fill=(Ubiquity)\n)) + \n  geom_tile(colour=\"white\") +\n  geom_text(aes(label = Ubiquity), colour=\"white\", size=3)+ \n  scale_alpha(range=c(0,1)) +\n  scale_x_discrete(\"\", expand = c(0, 0)) + \n  scale_y_discrete(\"\", expand = c(0, 0)) + \n  theme_grey(base_size = 9) + \n  theme(legend.position = \"none\",\n        axis.ticks = element_blank()\n  ) +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+\n  labs(\n    title=\"Early Medieval\"\n  ) +  scale_fill_gradient(low = \"white\", high = \"black\")\n\nfnuts_ubiquity_macroreg_Ma.HM <- ggplot(fnuts_ubiquity_macroreg.Ma, aes(\n  factor(Macroregion, levels=(level_macroreg_order)),\n  Plant,\n  fill=(Ubiquity)\n)) + \n  geom_tile(colour=\"white\") +\n  geom_text(aes(label = Ubiquity), colour=\"white\", size=3)+ \n  scale_alpha(range=c(0,1)) +\n  scale_x_discrete(\"\", expand = c(0, 0)) + \n  scale_y_discrete(\"\", expand = c(0, 0)) + \n  theme_grey(base_size = 9) + \n  theme(legend.position = \"none\",\n        axis.ticks = element_blank()\n  ) +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+\n  labs(\n    title=\"Medieval\"\n  ) +  scale_fill_gradient(low = \"white\", high = \"black\")\n\n\nFrNuts_Ubiquity_MacroReg_Patchwork <- (fnuts_ubiquity_macroreg_R.HM|fnuts_ubiquity_macroreg_LR.HM)/(fnuts_ubiquity_macroreg_EMA.HM|fnuts_ubiquity_macroreg_Ma.HM)\nFrNuts_Ubiquity_MacroReg_Patchwork + plot_annotation(\n  title = 'Fruits/Nuts',\n  subtitle = 'Ubiquity (%), plotted by macroregion and chronology.',\n  caption='Note: Data was too scarce for Roman Central Italy and Medieval Southern Italy.'\n)\n\n\n\n5.2.1.1 Cereals\nIt is interesting to notice how in the Roman age, cereals are similarly ubiquitous in Southern and Northern Italy, although there are some exceptions (i.e. einkorn, rye, oats, proso millet) that can derive from the randomness of samples. Unfortunately, only three sites provided botanical samples for Roman Central Italy and the values have been omitted from the plot. These sites (from the Roman Peasant Project, Tuscany) only reported three kinds of cereal: common wheat, emmer, and barley. Similar ubiquity values for the two macroregions under assessment in the Roman age may suggest similar production patterns in the whole peninsula. In the Late Roman age, ubiquity data has been calculated for the three macroregions. Three crops are found on 62-75% of the Central Italian sites: common wheat, barley and emmer. Other cereals are present, but less ubiquitously. These three cultivations seem to be diffused in the south as well. Conversely, in Northern Italy common wheat and barley were important cultivations but competed with other cereals including millet, sorghum, and rye (now doubled in presence). The Early Medieval age seems to mark a shift in agricultural practices—cereals ubiquities vary more markedly in the three macroregions. In Southern Italy, common wheat and barley were still the predominant cereals. This is true for Central and Northern Italy, however in these regions other cereals are also widely present in a large number of sites. The samples from the Medieval age are fewer in number since the upper boundary of this project’s chronology is the 11th c. Despite the short chronology, it is possible to make some considerations. Medieval Centraly Italy relied heavily on common wheat, barley and emmer, with other cereals increasingly important. Barley is the most ubiquitous cereal in Northern Italy in this period, followed by common wheat, millets and sorghum.\n\n\n\n\n\nFigure 5.3: Diachronical heatmap of cereals in the Italian macroregions\n\n\n\n\n\n\n5.2.1.2 Pulses\nIn the Roman Age, pulses are an important part of the diet and are cultivated both in Northern and Southern Italy. In the latter, vetch/broad beans are present in 22-32% of the samples, and lentils are present in 38% of the sites. In the Late Roman Age, broad beans are equally important in Central and Northern Italy, and peas are present in 50% of the Central Italian sites. In the Early Medieval Age, pulses are present in many Central Italian sites, especially blue/red peas, broad beans and other Fabaceae. Lentils and broad beans are also cultivated in almost half of the Northern Italian sites. The importance of pulses in Central Italy is confirmed by the 11th c. samples, where every specie is present in over 66% of the sites and Fabaceae and blue/red peas are found in every sample. Conversely, in Northern Italy broad bean is found in 66% of the sites.\n\n\n\n\n\nFigure 5.4: Diachronical heatmap of pulses in the Italian macroregions\n\n\n\n\n\n\n5.2.1.3 Fruits and nuts\nOlive and grape are two essential cultivations in the Italian peninsula. Olive pits, as can be expected, are more ubiquitous in Southern Italy, where in Roman times are present in >87% of the sites and in over 58% of the sites in the following chronologies1. Conversely, the grape is important in Central and Northern Italy in the Late Roman, Early Medieval and Medieval ages.\n\n\n\n\n\nFigure 5.5: Diachronical heatmap of fruits/nuts in the Italian macroregions"
  },
  {
    "objectID": "archaeobotany.html#richness-and-diversity",
    "href": "archaeobotany.html#richness-and-diversity",
    "title": "5  Archaeobotany",
    "section": "5.3 Richness and diversity",
    "text": "5.3 Richness and diversity\n\n\n\n\n\n\nSection in progress\n\n\n\n\n\n\n\n5.3.1 Richness and diversity in the Italian macroregions\n\n\nShow the code: data preparation\n# Species richness based on geographical features\n# RELATIVE PROPORTIONS OF ARCHAEOBOT_VIZ QUERY EXPORT FROM THE DB\n# (Condensed, without totals)\n\n# Remove NAs\nDf_Cond_Plants[is.na(Df_Cond_Plants)] <-0 \n\n# Generate a dataframe with the relative proportions and round the results\nDf_Cond_Plants_Rel <- decostand(Df_Cond_Plants[11:50], method = \"total\")\nDf_Cond_Plants_Rel <- round(Df_Cond_Plants_Rel, digits=2)\n\n# Add more info to the dataframe\nDf_Cond_Plants_Rel_Richness_Diversity <- data.frame(\n                                 \"Geo\" = Df_Cond_Plants$Geo,\n                                 \"Chronology\" = Df_Cond_Plants$Chronology, \n                                 \"Type\"= Df_Cond_Plants$Type, \n                                 \"Specnumber\" = specnumber(Df_Cond_Plants_Rel),\n                                 \"Shannon Div\" = diversity(Df_Cond_Plants_Rel),\n                                 Df_Cond_Plants_Rel\n)\n\nDf_Cond_Plants_Rel_withMacroregion <- data.frame(\"Geo\" = Df_Cond_Plants$Geo,\n                                                 \"Chronology\" = Df_Cond_Plants$Chronology,\n                                                 \"Type\"= Df_Cond_Plants$Type, \n                                                 \"Macroregion\" = Df_Cond_Plants$name_macroreg,\n                                                 \"Specnumber\" = specnumber(Df_Cond_Plants_Rel[1:10]), #Only cereals\n                                                 \"Shannon Div\" = diversity(Df_Cond_Plants_Rel[1:10]),\n                                                 Df_Cond_Plants_Rel[1:10]\n)\n\n# Let's plot the diversity by macroregion\n\n# Creating the dataframes for R and EMA age \n# I know it's called \"Plants\" but it's actually just cereals\nDf_Cond_Plants_Rel_withMacroregion.R <- filter(Df_Cond_Plants_Rel_withMacroregion, Chronology == \"R\")\nDf_Cond_Plants_Rel_withMacroregion.LR <- filter(Df_Cond_Plants_Rel_withMacroregion, Chronology == \"LR\")\nDf_Cond_Plants_Rel_withMacroregion.EMA <- filter(Df_Cond_Plants_Rel_withMacroregion, Chronology == \"EMA\")\n\n\n\n\nShow the code: plots\npal_RichnessvsGeo <- c(\"cadetblue3\", \"gold1\",  \"bisque4\", \"palegreen4\")\n\nplot_RichnessMacroReg.R <- ggplot(Df_Cond_Plants_Rel_withMacroregion.R, aes(x = Macroregion, y = Specnumber, fill = Macroregion)) +\n  geom_violin(trim=FALSE) + \n  geom_boxplot(width=0.1, fill=\"white\")+\n  scale_fill_manual(values = pal_RichnessvsGeo) +\n  geom_jitter(alpha=0.3)+\n  scale_x_discrete(labels = c(\"Central Italy \\n (n = 3)\", \"Northern Italy \\n (n = 39)\", \"Southern Italy \\n (n=31)\")) +\n  theme(legend.position = \"none\",\n        plot.background = element_rect(\"white\"),\n        panel.background = element_rect(\"white\"),\n        panel.grid = element_line(\"grey90\"),\n        axis.line = element_line(\"gray25\"),\n        axis.text = element_text(size = 12, color = \"gray25\"),\n        axis.title = element_text(color = \"gray25\"),\n        legend.text = element_text(size = 12)) + \n  labs(x = \"Macroregion\",\n       y = \"Number of species per site\",\n       title = \"R - Cereal richness\")\n\nplot_RichnessMacroReg.EMA <- ggplot(Df_Cond_Plants_Rel_withMacroregion.EMA, aes(x = Macroregion, y = Specnumber, fill = Macroregion)) +\n  geom_violin(trim=FALSE) + \n  geom_boxplot(width=0.1, fill=\"white\")+\n  scale_fill_manual(values = pal_RichnessvsGeo) +\n  geom_jitter(alpha=0.3)+\n  scale_x_discrete(labels = c(\"Central Italy \\n (n = 10)\", \"Northern Italy \\n (n = 36)\", \"Southern Italy \\n (n=17)\")) +\n  theme(legend.position = \"none\",\n        plot.background = element_rect(\"white\"),\n        panel.background = element_rect(\"white\"),\n        panel.grid = element_line(\"grey90\"),\n        axis.line = element_line(\"gray25\"),\n        axis.text = element_text(size = 12, color = \"gray25\"),\n        axis.title = element_text(color = \"gray25\"),\n        legend.text = element_text(size = 12)) + \n  labs(x = \"Macroregion\",\n       y = \"Number of species per site\",\n       title = \"EMA - Cereal richness\")\n\n\nCereals share similar presence values in Roman Northern and Southern Italian sites (Figure 5.6). Central Italy reports higher values, although this is based only on three sites and hence it is not reliable. During the Early Middle Ages, Central Italy again is the richest in cereals, closely followed by Northern Italy. Interestingly, Southern Italy still reports values very close to the Roman age. A full list of the Southern Italian EMA sites is reported in Table 5.1.\n\n\n\n\n\n\n\n(a) Roman age.\n\n\n\n\n\n\n\n(b) Early Medieval age.\n\n\n\n\nFigure 5.6: Violin plots of cereal richness in the Italian macroregions. The grey dots (jitters) indicate the value for the single site, while the white boxplot shows the median and the quartile values.\n\n\n\n\nTable 5.1: List of Southern Italian sites with chronology EMA\n\n\n\n\n\n\n\n\n\n\nID\nSite\nRegion\nGeography\nType\nCulture/Influence\n\n\n\n\n98\nS. Maria in Cività, D85\nMolise\nHilltop\nUrban\nLombard\n\n\n107\nS. Giovanni di Ruoti, Phase 3A\nBasilicata\nMountain\nMonastery\nLombard\n\n\n107\nS. Giovanni di Ruoti, Phase 3B\nBasilicata\nMountain\nMonastery\nLombard\n\n\n198\nSalapia, area botteghe, US 2475\nPuglia\nCoast/Lagoon\nUrban\nLombard\n\n\n198\nSalapia, area botteghe, US 2437\nPuglia\nCoast/Lagoon\nUrban\nLombard\n\n\n199\nSalapia, area conceria, US 2054\nPuglia\nCoast/Lagoon\nUrban\nLombard\n\n\n199\nSalapia, area conceria, US 2211-2217\nPuglia\nCoast/Lagoon\nUrban\nLombard\n\n\n199\nSalapia, area conceria, 8th-9th c.\nPuglia\nCoast/Lagoon\nUrban\nLombard\n\n\n196\nFaragola, wastepit 61\nPuglia\nPlain\nRural, villa\nLombard\n\n\n196\nFaragola, wastepit 66\nPuglia\nPlain\nRural, villa\nLombard\n\n\n234\nColle Castellano, Phase 3-4\nMolise\nHill\nUrban\nLombard\n\n\n177\nSan Vincenzo al Volturno, kitchen area\nMolise\nHill\nMonastery\nLombard\n\n\n101\nSupersano, loc. Scorpo\nPuglia\nPlain\nRural\nByzantine\n\n\n250\nApigliano, 9th-10th c., pits\nPuglia\nPlain\nRural\nByzantine\n\n\n250\nApigliano, 10th-11th c., pits\nPuglia\nPlain\nRural\nByzantine\n\n\n196\nFaragola, granary A7\nPuglia\nPlain\nRural, villa\nLombard\n\n\n196\nFaragola, granary A8\nPuglia\nPlain\nRural, villa\nLombard"
  },
  {
    "objectID": "archaeobotany.html#cereals-regionality",
    "href": "archaeobotany.html#cereals-regionality",
    "title": "5  Archaeobotany",
    "section": "5.4 Cereals regionality",
    "text": "5.4 Cereals regionality\n\n5.4.1 PERMANOVA\n\n\n\n\n\n\nNotes on terminology: PERMANOVA\n\n\n\nPermutational multivariate analysis of variance (PERMANOVA) is a non-parametric multivariate statistical test used to compare group of objects. By using measure space, the null hypothesis that the centroids and dispersion of groups are identical is tested. The null hypothesis is rejected if either the centroid or the spread of the objects differs between the groups. A prior calculation of the distance between any two objects included in the experiment is used to determine whether the test is valid or not2 (Anderson (2017)). In this context, the null hypothesis is that there is no regional difference in the cereals dataset, with cereals being evenly distributed across macroregions and chronologies.\n\n\nThe suggestion of an Early Medieval shift in cereal farming stated in Section 5.2.1 and Section 5.3.1 needs statistical support. Considering that data is not unimodal and that we are dealing with presence/absence analysis, the best choice is to use a non-parametric test as PERMANOVA on the early medieval botanical dataset. Prior to performing the test, it was necessary to pre-process data by:\n\nSelecting all the cereals columns of the plant remains table, keeping some categorical variables: Macroregion, Chronology, Geography and Type.\nRemoving the empty rows (caused by the fact that some sites have seeds/fruits, but not cereals).\nTransforming the raw counts into presence/absence, using the function decostand() (method=pa) in the R package vegan (Oksanen et al. (2020)).\n\n\n\nShow the code: Pre-processing\n# Testing the results: Regionality in the dataset? \nlibrary(vegan)\n\nset.seed(29)\n\n\n# Pre processing: remove empty rows\n\n# Note: The input table is the CONDENSED table without totals\n\n# Selecting all the cereals columns of the plant remains table, keeping some categorical variables \ncer_macroreg_ubiquity_transp.tot <- Df_Cond_Plants[c(4,5,6,7,11:19)]\n\n# Selecting all rows with data (since we selected only with cereals, and some sites only had fruits/pulses we might have empty rows)\ncer_macroreg_ubiquity_transp.tot <- cer_macroreg_ubiquity_transp.tot[rowSums(cer_macroreg_ubiquity_transp.tot[5:13])>0,]\n\n# Assigning a column name \"Macroregion\"\ncolnames(cer_macroreg_ubiquity_transp.tot)[1] = \"Macroregion\"\n\n# Selecting the Chronology of interest (EMA) and excluding Central Italy\ncer_macroreg_ubiquity_transp.tot<- filter(cer_macroreg_ubiquity_transp.tot, Macroregion!=\"Central Italy\" & Chronology==\"EMA\")\n\n# dividing categorical and numerical columns\ncer_macroreg_ubiquity_transp.categ <- cer_macroreg_ubiquity_transp.tot[1:4]\ncer_macroreg_ubiquity_transp.data <- cer_macroreg_ubiquity_transp.tot[5:13]\n\n# Converting the numerical columns into a presence/absence matrix (using method=pa)\ncer_macroreg_ubiquity_transp.dist <- decostand(cer_macroreg_ubiquity_transp.data, method=\"pa\", na.rm=TRUE)\n\n\nAfter the pre-processing, it was possible to run the PERMANOVA using the function adonis2() in the package vegan. The function creates a distance matrix and computes an analysis of variance on the matrix. The method chosen to calculate the distance matrix is the jaccard distance. The Jaccard distance (Kosub (2019)), based on the Jaccard similarity index, is a value of dissimilarity between sample sets. When compared to other dissimilarity indices, it is more appropriate for presence/absence analyses as it is not based on Euclidean distance.\nResults of adonis2().\n\n\nShow the code: adonis2()\ncer_macroreg_ubiquity_transp.div <- adonis2(\n  cer_macroreg_ubiquity_transp.dist ~ Macroregion, \n  data = cer_macroreg_ubiquity_transp.categ,\n  permutations = 10000, method=\"jaccard\"\n  )\n\n\n\n\nPermutation test for adonis under reduced model\nTerms added sequentially (first to last)\nPermutation: free\nNumber of permutations: 10000\n\nadonis2(formula = cer_macroreg_ubiquity_transp.dist ~ Macroregion, data = cer_macroreg_ubiquity_transp.categ, permutations = 10000, method = \"jaccard\")\n            Df SumOfSqs      R2      F    Pr(>F)    \nMacroregion  1   1.3024 0.13495 7.3322 9.999e-05 ***\nResidual    47   8.3487 0.86505                     \nTotal       48   9.6512 1.00000                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe results of the PERMANOVA indicate that the variable Macroregion is highly significant, meaning that we can be 99.9% confident that it is a discriminant in the early medieval dataset.\nAfter running the PERMANOVA, it is necessary to check the homogeneity of variances, to confirm the results (especially when dealing with small groups of data). The function betadisper() from the package vegan provides the distances of group samples from centroids. If the variation is even, the null hypothesis of no difference in dispersion between groups is accepted. To test the variation, it is possible to use the analysis of variance (ANOVA).\n\n\nShow the code: Betadisper()\n# We do not need to calculate the distance separately, but it will be useful later for the betadisper() function\n\n# Distance dissimilarity matrix with the Jaccard method\ncer_macroreg_ubiquity_transp.dist2 <- vegdist(cer_macroreg_ubiquity_transp.dist, method=\"jaccard\", na.rm=TRUE)\n\n# Betadisper: distances of group samples from centroids\ncer_macroreg_ubiquity_transp.betadisper <- betadisper(cer_macroreg_ubiquity_transp.dist2, cer_macroreg_ubiquity_transp.categ$Macroregion)\n\n\nResults of anova() on the betadisper.\n\n\nShow the code: ANOVA on betadisper()\n# We will see that the ANOVA's p-value is not significant meaning that group dispersions are homogenous \n#(\"Null hypothesis of no difference in dispersion between groups\"; https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/betadisper).\n\nanova(cer_macroreg_ubiquity_transp.betadisper) # This should not be significant!\n\n\nAnalysis of Variance Table\n\nResponse: Distances\n          Df  Sum Sq   Mean Sq F value Pr(>F)\nGroups     1 0.00211 0.0021112  0.0715 0.7903\nResiduals 47 1.38696 0.0295098               \n\n\n\n\n\n\n\n\n\n(a) Groups dispersions plot with confidence ellipses.\n\n\n\n\n\n\n\n(b) Boxplot showing equal distances from centroid.\n\n\n\n\nFigure 5.7: Results of the betadisper() (groups dispersions) on the distance matrix calculated with the Jaccard method.\n\n\nThe betadisper() graphs (Figure 5.7) show similar distances from the centroids for the categories Northern Italy and Southern Italy. In addition, the ANOVA on the betadisper() shows that the separation is not significant (p-value over the significance treshold), meaning that the groups dispersions are homogeneous. We can now be more confident of the PERMANOVA results and accept the difference between the two groups of sites under investigation. In other words, the Southern and Northern Italian group of sites are different during the Early Middle Ages.\nRunning the same tests on the Roman sites failed to separate the two groups of sites, confirming that there was not a major difference in the types of cereals cultivated during the Roman age between Northern and Southern Italy.\n\n\n5.4.2 nMDS\n\n\n5.4.3 NCA\n\n\n\n\n\n\nNotes on terminology: Wasserstein metric\n\n\n\nThe Wasserstein distance (or earth’s mover distance) is a measure of distance between two probability distributions on a metric space.\n\n\nIn addition to statistically testing the separation between the Northern and Southern Italian early medieval cereals dataset (Section 5.4.1), it is possible to measure the distance between groups of sites both in the Roman and early Middle ages. For this task, a machine learning algorithm for metric learning has been chosen: the Neighborhood Component Analysis, from the Python package NeighborhoodComponentAnalysis (in sklearn.neighbors). A more in-depth explanation of the algorithm can be read in Section 4.6.2.4. To work with balanced group of samples, the group sizes have been arbitrarily set to 20 random samples, allowing replacement (meaning that a sample can randomly be picked twice). The Python function sample() (from the random library) was used to select random samples. To avoid fallacy in computations, the macroregion Central Italy and the chronologies LR (Late Roman) and Ma (11th c. onwards) have been excluded from this test—the uneven distribution of the group of samples required a cautious approach. The NCA has been run with a reduction to only one dimension, using KDE plots to visualize the results. Setting the dimension to one allows easier calculations of distance. In Figure 5.8 (a), it is possible to see the NCA performed on the Roman cereals presence/absence dataset. As already pointed out, the PERMANOVA did not produce significant results for this dataset and the Wasserstein distance (calculated with the wasserstein_distance() function in the scipy library) is indeed shorter for the Roman dataset. For both chronologies there is an overlap in the curves, which is more considerable in the Roman age (indicating that the group of samples are more similar). The overlap for the EMA groups (Figure 5.8, b) is probably due to the fact that the presence of the noble grains is not by itself a ‘marker’ of Southern Italian sites—these grains are also very common in the North. The difference is that in the South noble grains are not cultivated in conjunction with other grains. The graph for the EMA chronology shows a clearer separation of the macroregional groups, with some minor overlaps. Moreover, the graph also displays variability in the Northern Italian dataset. The variability can also be assessed from the outliers in the boxplots in Figure 5.9.\nSource code:\n\n\nShow the code: Libraries\n# Load Python libraries\n#!pip install pandas\nimport pandas as pd\nimport os\n\n#!pip install scikit-hubness\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.neighbors import (KNeighborsClassifier,\n                                 NeighborhoodComponentsAnalysis)\n\nfrom scipy.stats import wasserstein_distance\n\nimport seaborn as sns\n\n# Set seed\nrandom.seed(10)\n\n\n\n\n\n\n\nShow the code: Selecting random samples, with replacement\n#R\ndf_R_SI = df_R[df_R[\"Macroregion\"]==\"Southern Italy\"].sample(20, random_state=7, replace=\"TRUE\")\ndf_R_NI = df_R[df_R[\"Macroregion\"]==\"Northern Italy\"].sample(20, random_state=7, replace=\"TRUE\")\n# Create a dataset with northern and southern Italy\ndf_R_merge = pd.concat([df_R_SI, df_R_NI], ignore_index=True)\n\ndata_R_byPlantGroup = df_R_merge.drop(['Chronology','Type', 'Macroregion', 'Weight'], axis=1)\nlabels_R_byPlantGroup = df_R_merge.iloc[:,2] # nrow, 0 for Chronology - nrow, 1 for Type - nrow,2 for Macroregion\n\n#EMA\ndf_EMA_SI = df_EMA[df_EMA[\"Macroregion\"]==\"Southern Italy\"].sample(20, random_state=7, replace=\"TRUE\")\ndf_EMA_NI = df_EMA[df_EMA[\"Macroregion\"]==\"Northern Italy\"].sample(20, random_state=7, replace=\"TRUE\")\ndf_EMA_merge = pd.concat([df_EMA_SI, df_EMA_NI], ignore_index=True)\n \ndata_EMA_byPlantGroup = df_EMA_merge.drop(['Chronology','Type', 'Macroregion', 'Weight'], axis=1)\nlabels_EMA_byPlantGroup = df_EMA_merge.iloc[:,2] # nrow, 0 for Chronology - nrow, 1 for Type - nrow,2 for Macroregion\n\n\n\n\nShow the code: Performing the NCA\n#R\nnca_for_KDE_R_PlantGroup = NeighborhoodComponentsAnalysis(n_components =1, init=\"lda\").fit(data_R_byPlantGroup, labels_R_byPlantGroup)\nreduction_for_KDE_R_PlantGroup = nca_for_KDE_R_PlantGroup.transform(data_R_byPlantGroup)\ndf_R_merge[\"value\"] = reduction_for_KDE_R_PlantGroup\n     \n#EMA\nnca_for_KDE_EMA_PlantGroup = NeighborhoodComponentsAnalysis(n_components =1, init=\"lda\").fit(data_EMA_byPlantGroup, labels_EMA_byPlantGroup)\nreduction_for_KDE_EMA_PlantGroup = nca_for_KDE_EMA_PlantGroup.transform(data_EMA_byPlantGroup)\ndf_EMA_merge[\"value\"] = reduction_for_KDE_EMA_PlantGroup\n\n\n\n\nShow the code: Wasserstein distance\n# R\ndf_R_North = df_R_merge[df_R_merge[\"Macroregion\"] == \"Northern Italy\"]\ndf_R_South = df_R_merge[df_R_merge[\"Macroregion\"] == \"Southern Italy\"]\n\nwasserstein_distance(df_R_South[\"value\"], df_R_North[\"value\"], u_weights=df_R_North[\"Weight\"], v_weights=df_R_South[\"Weight\"])\n\n#EMA\n\ndf_EMA_North = df_EMA_merge[df_EMA_merge[\"Macroregion\"] == \"Northern Italy\"]\ndf_EMA_South = df_EMA_merge[df_EMA_merge[\"Macroregion\"] == \"Southern Italy\"]\n\nwasserstein_distance(df_EMA_South[\"value\"], df_EMA_North[\"value\"], u_weights=df_EMA_North[\"Weight\"], v_weights=df_EMA_South[\"Weight\"])\n\n\nPlots\n\n\nShow the code: Plotting the NCA\nNCA_KDE_1D, ax = plt.subplots(1, 2, figsize=(10, 5), sharey=True, sharex=True)\n\nsns.kdeplot(data=df_R_merge, x=\"value\", ax=ax[0], hue=\"Macroregion\", fill=True, alpha=.1, palette=\"colorblind\", linewidth=1, legend=None).set(xlabel='NCA', title=\"(a) Roman age\")\n\nsns.kdeplot(data=df_EMA_merge, x=\"value\", ax=ax[1], hue=\"Macroregion\", fill=True, alpha=.1, palette=\"colorblind\", linewidth=1).set(xlabel='NCA', title=\"(b) early Middle ages\")\n\nNCA_KDE_1D.text(0.08, 0.03, 'Weighted Wasserstein Distance: W = 67.64 \\nPERMANOVA test: p>0.05', fontsize=10)\nNCA_KDE_1D.text(0.68, 0.03, 'Weighted Wasserstein Distance: W = 200.65\\nPERMANOVA test: p<0.001', fontsize=10)\nplt.tight_layout()\nplt.subplots_adjust(bottom=0.19)\nplt.show()\n\n\n\n\n\nFigure 5.8: One-Dimension NCA on the Presence/Absence Cereals Dataset\n\n\n\n\n\n\n\n\n\nFigure 5.9: Boxplots showing the NCA value for Northern and Southern Early Medieval Italy.\n\n\n\n\n\n\n5.4.4 Network Analysis of cereals in EMA sites\n\n\n\n\n\n\nSection in progress\n\n\n\n\n\n\n\n\n\n\nAnderson, M.J., 2017. Permutational Multivariate Analysis of Variance (PERMANOVA). In: Wiley StatsRef: Statistics Reference Online. John Wiley & Sons, Ltd, pp. 1–15.\n\n\nKosub, S., 2019. A note on the triangle inequality for the Jaccard distance. Pattern Recognition Letters 120, 36–38.\n\n\nOksanen, J., Blanchet, F.G., Friendly, M., Kindt, R., Legendre, P., McGlinn, D., Minchin, P.R., O’Hara, R.B., Simpson, G.L., Solymos, P., Stevens, M.H.H., Szoecs, E., Wagner, H., 2020. Vegan: Community ecology package."
  },
  {
    "objectID": "zooarchaeology.html",
    "href": "zooarchaeology.html",
    "title": "6  Zooarchaeology",
    "section": "",
    "text": "Page under construction"
  },
  {
    "objectID": "zooarchaeology.html#case-studies",
    "href": "zooarchaeology.html#case-studies",
    "title": "6  Zooarchaeology",
    "section": "6.1 Case studies",
    "text": "6.1 Case studies\nThe following map shows the sites under investigation, divided by chronology. Please select the desired chronology (or chronologies) from the legend on the right.\n\n\n\n\n\n\n\nLegend: R = Roman, LR = Late Roman, EMA = Early Middle Ages, Ma = 11th c. onwards"
  },
  {
    "objectID": "discussion.html",
    "href": "discussion.html",
    "title": "7  Discussion",
    "section": "",
    "text": "Page under construction"
  },
  {
    "objectID": "conclusions.html",
    "href": "conclusions.html",
    "title": "8  Conclusions",
    "section": "",
    "text": "Page to be added"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Anderson, M.J., 2017. Permutational\nMultivariate Analysis of Variance\n(PERMANOVA). In: Wiley StatsRef:\nStatistics Reference Online. John Wiley & Sons,\nLtd, pp. 1–15.\n\n\nBaxter, M.J., 2015. Exploratory multivariate analysis in archaeology,\nFoundations of archaeology. Percheron Press, a division of Eliot\nWerner Publications, Inc, Clinton Corners, New York.\n\n\nBinford, S.R., Binford, L., 1968. New Perspectives in\nArchaeology. Aldline Press,\nChicago.\n\n\nBoscato, P., Fronza, V., Salvadori, F., 2007. Proposta di un database\nper i reperti faunistici. In: Fiore, I., Malerba, G., Chilardi, S.\n(Eds.), Atti Del 3 Convegno Nazionale Di\nArcheozoologia. Siracusa 3-5\nNovembre 2000. Istituto Poligrafico e Zecca dello\nStato, Roma, pp. 1–14.\n\n\nCardarelli, L., 2022. A deep variational\nconvolutional Autoencoder for unsupervised features\nextraction of ceramic profiles. A case study from central\nItaly. Journal of Archaeological Science 144, 105640.\n\n\nCarlson, D.L., 2017. Quantitative methods in archaeology using\nR, Cambridge University Press. ed, Cambridge\nManuals in Archaeology.\nCambridge.\n\n\nCuffney, T.F., Kennen, J.G., Waite, I.R., 2014. Aquatic\nEcosystems as Indicators of\nStatus and Trends in Water\nQuality. In: Comprehensive Water Quality and\nPurification. Elsevier, pp. 122–156.\n\n\nDexter, E., Rollwagen-Bollens, G., Bollens, S.M., 2018. The trouble with stress:\nA flexible method for the evaluation of nonmetric\nmultidimensional scaling: The Trouble\nwith Stress. Limnology and Oceanography: Methods 16,\n434–443.\n\n\nFiguera, M., 2018. Database management e dati archeologici:\nstandardizzazione e applicazione della logica fuzzy alla gestione delle\nfonti e delle attribuzioni tipologiche. Archeologia e Calcolatori\n29, 143–160.\n\n\nFletcher, M., Lock, G.R., 2005. Digging numbers: Elementary statistics\nfor archaeologists, 2nd ed. ed, Monograph (Oxford University\nSchool of Archaeology). Oxford University\nCommittee for Archaeology, Oxford : Oakville, CT.\n\n\nGattiglia, G., 2018. Databases in\nArchaeology. In: López Varela, S.L. (Ed.), The\nEncyclopedia of Archaeological Sciences.\nJohn Wiley & Sons, Inc., Hoboken, NJ, USA,\npp. 1–4.\n\n\nGauch, H.G., 1982. Multivariate\nAnalysis in Community Ecology, First. ed.\nCambridge University Press.\n\n\nGoldberger, J., Hinton, G.E., Roweis, S., Salakhutdinov, R.R., 2005.\nNeighbourhood components analysis. In: Saul, L.K., Weiss, Y., Bottou, L.\n(Eds.), Advances in Neural Information Processing Systems.\nBradford Books, Vancouver, pp. 513–520.\n\n\nGrebner, D.L., Bettinger, P., Siry, J.P., 2013. Forest\nDynamics. In: Introduction to Forestry and\nNatural Resources. Elsevier, pp. 243–254.\n\n\nHarris, C.R., Millman, K.J., van der Walt, S.J., Gommers, R., Virtanen,\nP., Cournapeau, D., Wieser, E., Taylor, J., Berg, S., Smith, N.J., Kern,\nR., Picus, M., Hoyer, S., van Kerkwijk, M.H., Brett, M., Haldane, A.,\ndel Río, J.F., Wiebe, M., Peterson, P., Gérard-Marchant, P., Sheppard,\nK., Reddy, T., Weckesser, W., Abbasi, H., Gohlke, C., Oliphant, T.E.,\n2020. Array\nprogramming with NumPy. Nature 585, 357–362.\n\n\nHunter, J.D., 2007. Matplotlib: A 2D graphics environment.\nComputing in science & engineering 9, 90–95.\n\n\nJones, G., Wardle, K., Halstead, P., Wardle, D., 1986. Crop\nStorage at Assiros. Scientific American\n254, 96–103.\n\n\nKosub, S., 2019. A note on the\ntriangle inequality for the Jaccard distance. Pattern\nRecognition Letters 120, 36–38.\n\n\nLauro, C., 1996. Computational\nstatistics or statistical computing, is that the question?\nComputational Statistics & Data Analysis, Classification 23,\n191–193.\n\n\nLennstrom, H.A., Hastorf, C.A., 1995. Interpretation in context:\nSampling and analysis in paleoethnobotany. American Antiquity 60,\n701–721.\n\n\nMercuri, A.M., Allevato, E., Arobba, D., Bandini Mazzanti, M., Bosi, G.,\nCaramiello, R., Castiglioni, E., Carra, M.L., Celant, A., Costantini,\nL., Di Pasquale, G., Fiorentino, G., Florenzano, A., Guido, M.,\nMarchesini, M., Mariotti Lippi, M., Marvelli, S., Miola, A., Montanari,\nC., Nisbet, R., Peña-Chocarro, L., Perego, R., Ravazzi, C., Rottoli, M.,\nSadori, L., Ucchesu, M., Rinaldi, R., 2015. Pollen and macroremains from\nHolocene archaeological sites: A dataset for\nthe understanding of the bio-cultural diversity of the\nItalian landscape. Review of Palaeobotany and Palynology\n218, 250–266.\n\n\nMoore, J.C., 2013. Diversity,\ntaxonomic versus functional. In: Encyclopedia of Biodiversity.\nElsevier, pp. 648–656.\n\n\nNiccolucci, F., 2020. ARIADNEplus: L’avventura\ncontinua. DigItalia 2, 88–95.\n\n\nOksanen, J., Blanchet, F.G., Friendly, M., Kindt, R., Legendre, P.,\nMcGlinn, D., Minchin, P.R., O’Hara, R.B., Simpson, G.L., Solymos, P.,\nStevens, M.H.H., Szoecs, E., Wagner, H., 2020. Vegan: Community ecology\npackage.\n\n\nOksanen, J., Simpson, G.L., Blanchet, F.G., Kindt, R., Legendre, P.,\nMinchin, P.R., O’Hara, R.B., Solymos, P., Stevens, M.H.H., Szoecs, E.,\nWagner, H., Barbour, M., Bedward, M., Bolker, B., Borcard, D., Carvalho,\nG., Chirico, M., Caceres, M.D., Durand, S., Evangelista, H.B.A.,\nFitzJohn, R., Friendly, M., Furneaux, B., Hannigan, G., Hill, M.O.,\nLahti, L., McGlinn, D., Ouellette, M.-H., Cunha, E.R., Smith, T., Stier,\nA., Braak, C.J.F.T., Weedon, J., 2022. Vegan: Community ecology\npackage.\n\n\nPearsall, D.M., 2015. Paleoethnobotany: A handbook of procedures, Third\nedition. ed. Left Coast Press Inc, Walnut Creek,\nCalifornia.\n\n\nPedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B.,\nGrisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V.,\nVanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M.,\nDuchesnay, É., 2011. Scikit-learn: Machine Learning in\nPython. Journal of Machine Learning Research 12, 2825–2830.\n\n\nReback, J., jbrockmendel, McKinney, W., Bossche, J.V. den, Roeschke, M.,\nAugspurger, T., Hawkins, S., Cloud, P., gfyoung, Sinhrks, Hoefler, P.,\nKlein, A., Petersen, T., Tratner, J., She, C., Ayd, W., Naveh, S.,\nDarbyshire, J.H.M., Shadrach, R., Garcia, M., Schendel, J., Hayden, A.,\nSaxton, D., Gorelli, M.E., Li, F., Wörtwein, T., Zeitlin, M.,\nJancauskas, V., McMaster, A., Li, T., 2022. Pandas-dev/pandas:\nPandas 1.4.3.\n\n\nRichards, J.D., 2021. Archiving Archaeological Data in the\nUnited Kingdom. Internet Archaeology 58.\n\n\nRizzo, M.L., 2019. Statistical\nComputing with R, Second. ed.\nChapman and Hall/CRC, New York.\n\n\nShennan, S., 1997. Quantifying archaeology, 2nd ed. ed. Edinburgh\nUniversity Press, Edinburgh.\n\n\nSyms, C., 2008. Ordination.\nIn: Encyclopedia of Ecology. Elsevier, pp.\n2572–2581.\n\n\nVirtanen, P., Gommers, R., Oliphant, T.E., Haberland, M., Reddy, T.,\nCournapeau, D., Burovski, E., Peterson, P., Weckesser, W., Bright, J.,\n2020. SciPy 1.0: Fundamental algorithms for scientific\ncomputing in Python. Nature methods 17, 261–272.\n\n\nWaskom, M.L., 2021. Seaborn: Statistical data visualization. Journal of\nOpen Source Software 6, 3021.\n\n\nWickham, H., 2016. Programming with\nGgplot2. In: Wickham, H. (Ed.), Ggplot2: Elegant\nGraphics for Data Analysis, Use R!\nSpringer International Publishing, Cham, pp.\n241–253.\n\n\nWickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L.D., François,\nR., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen,\nT.L., Miller, E., Bache, S.M., Müller, K., Ooms, J., Robinson, D.,\nSeidel, D.P., Spinu, V., Takahashi, K., Vaughan, D., Wilke, C., Woo, K.,\nYutani, H., 2019. Welcome\nto the tidyverse 4, 1686.\n\n\nWright, P.J., 2010. Methodological\nIssues in Paleoethnobotany: A\nconsideration of Issues, Methods, and\nCases. In: VanDerwarker, A.M., Peres, T.M. (Eds.),\nIntegrating Zooarchaeology and\nPaleoethnobotany: A Consideration of\nIssues, Methods, and Cases.\nSpringer New York, New York, NY, pp. 37–64.\n\n\nXie, Y., 2021. Knitr: A\ngeneral-purpose package for dynamic report generation in r."
  },
  {
    "objectID": "functions.html",
    "href": "functions.html",
    "title": "Custom functions",
    "section": "",
    "text": "This section contains the list of custom functions that have been written to prepare, handle and visualize the data exported from the database."
  },
  {
    "objectID": "functions.html#archaeobotany",
    "href": "functions.html#archaeobotany",
    "title": "Custom functions",
    "section": "Archaeobotany",
    "text": "Archaeobotany\n\narchaeobotany_tables()\nThis function has two arguments:\n\na dataframe of the exported table of plants from the database (view_archaeobot.csv).\n\n\n [1] \"site_code\"               \"site_name\"              \n [3] \"type_name\"               \"region_name\"            \n [5] \"data_valid_start\"        \"data_valid_end\"         \n [7] \"weight\"                  \"sampling_notes\"         \n [9] \"extra_notes\"             \"short_ref\"              \n[11] \"culture_type\"            \"x\"                      \n[13] \"y\"                       \"Triticum.aestivum.durum\"\n[15] \"Triticum.dicoccum\"       \"Triticum.monococcum\"    \n[17] \"Avena.sp\"                \"Hordeum.vulgare\"        \n[19] \"Panicum.milliaceum\"      \"Secale.cereale\"         \n[21] \"Setaria.italica\"         \"Sorghum.bicolor\"        \n[23] \"Cerealia.ind\"            \"Leguminosae\"            \n[25] \"Lens.culinaris\"          \"Pisum.sativum\"          \n[27] \"Vicia.faba\"              \"Vicia.sativa\"           \n[29] \"Vicia.sp\"                \"Lathyrus.cicera.sativus\"\n[31] \"Cicer.aretinum\"          \"Cornus.mas\"             \n[33] \"Corylus.avellana\"        \"Ficus.carica\"           \n[35] \"Fragaria.vesca\"          \"Juglans.regia\"          \n[37] \"Castanea.sativa\"         \"Malus.domestica\"        \n[39] \"Olea.europaea.L\"         \"Prunus.cerasus\"         \n[41] \"Prunus.avium\"            \"Prunus.sp\"              \n[43] \"Prunus.persica\"          \"Prunus.domestica\"       \n[45] \"Prunus.spinosa\"          \"Rubus.fruticosus\"       \n[47] \"Pyrus.communis\"          \"Sambucus.nigra\"         \n[49] \"Cucumis.melo\"            \"Vitis.vinifera\"         \n[51] \"Linum.usatissimus\"       \"Sorbus.sp\"              \n\n\nthe century of interest.\n\nThe function archaeobotany_tables() can be used to return the ubiquity, relative proportions or a print of the table with the sites from the chosen century. The comments in the code below explain the process.\n\n\nShow the code\n##FUNCTION FOR GENERATING CENTURY BASED\n# - UBIQUITY\n# - RELATIVE PROPORTIONS\n# - A PRINT OF THE TABLE\n\narchaeobotany_tables <- function(x, century) {\n  # Load the tidyverse library if it hasn't been loaded in the page before\n  library(tidyverse)\n  \n  # Remove NAs\n  x[is.na(x)] <-0 \n  \n  # Filter the table for the chosen century\n  # package: tidyverse\n  x <- filter(x, data_valid_start <= century & data_valid_end >= century)\n  \n  # The total of each row is needed to calculate the relative proportions\n  # Note: Calculation starts from column 14 because it is the first column with numerical data. If the table exported from the database changes, this number must be adjusted.\n  Total <- rowSums(x[,14:ncol(x)])\n  \n  # Subsetting the given dataframe by creating a new dataframe with fewer columns \n  plants <- data.frame(x$site_name, x$type_name, \n                       x$data_valid_start, x$data_valid_end,\n                       x$culture_type, x[14:ncol(x)], \n                       Total\n  )\n  \n  # Calculating the relative proportions and rounding the results to 2 digits.\n  Rel_Prop <- round(((x[14:ncol(x)]/Total)*100), digits=2)\n  \n  # Ubiquity: \n  #Note: It is given by the no. of sites where the plant is present divided by the total of sites\n  # Note: Total of sites: (No. of rows - header row)\n  \n  # Creating a new dataframe from the Relative Proportions one (Rel_Prop). \n  # Note: This can be done also from the original dataframe, it is not important since it is just a calculation based on presence/absence. I chose this dataframe as it has already the columns I need.\n  Pres_Abs <- Rel_Prop\n  \n  # If the value is > 0 it means that the plant is present: this line replaces this value with a 1 (indicating presence)\n  Pres_Abs[Pres_Abs > 0] <- 1\n  \n  # In how many sites is this plant present?\n  Tot_sites_present <- colSums(Pres_Abs)\n\n  # Finally calculate ubiquity\n  # Note: The score is multiplied by 100 to obtain results in %\n  Ubiquity <- (Tot_sites_present / nrow(Pres_Abs))*100\n  \n  return(list(\n    Ubiquity_exp = Ubiquity,\n    Rel_Prop_exp = Rel_Prop,\n    Raw_Counts = plants\n    ))\n}\n\n\n\n\nRel_Prop_per_Century()\nThis function has two arguments: - a dataframe of the exported table of plants from the database (view_archaeobot.csv).\n\nthe century of interest. The function Rel_Prop_per_Century() can be used to return the relative proportions of each site from the chosen century. The comments in the code below explain the process.\n\n\n\nShow the code\n## Convert each site raw data into relative proportions\n\nRel_Prop_per_Century <- function(x, century) {\n  \n  # Remove NAs\n  x[is.na(x)] <-0\n  \n  # Filter the table for the chosen century\n  # package: tidyverse\n  library(tidyverse)\n  x <- filter(x, data_valid_start <= century & data_valid_end >= century)\n  \n  # Calculate the total of the row and divide each value by the total to get proportions\n  # round() is used to get two decimal values\n  Total_per_site <- rowSums(x[,14:ncol(x)])\n  Rel_Prop_per_site <- round(((x[14:ncol(x)]/Total_per_site)*100), digits=2)\n  \n  # Create new dataframe with the information we need\n  plants_rel_prop <- data.frame(\n    \"Site\" = x$site_name, \n    \"Type\" = x$type_name, \n    \"From.Century\" = x$data_valid_start, \n    \"To.Century\"= x$data_valid_end,\n    \"Weight\"=x$weight,\n    \"Culture\"=x$culture_type, \n    \"x\"=x$x, \n    \"y\"=x$y,\n    Rel_Prop_per_site\n  )\n  \n  return(plants_rel_prop)\n}\n\n\n\n\nUbiquity_macroreg_chrono()\nThis function has three arguments:\n\na dataframe of the exported condensed table of plants from the database (Archaeobot_Condensed.csv). It is a table of plants exported with their common English name and with a column of totals for each type of plant (Cereals, Fruit/Nuts, …).\nthe macroregion of interest: Southern Italy, Central Italy, Northern Italy.\nthe chronology of interest: R, LR, EMA, Ma.\n\n\n\nShow the code\nUbiquity_macroreg_chrono <- function(df, macroregion, chronology) {\n  \n  # Load the tidyverse library if it hasn't been loaded in the page before\n  library(tidyverse)\n  \n  # Remove NAs\n  df[is.na(df)] <- 0\n  \n  # Filter the table for the chosen chronology and macroregion\n  # package: tidyverse\n  df.chronology <- filter(df, Chronology == chronology & Macroregion == macroregion)\n  \n  #Remove useless columns: Tots, unsp.cols\n  df.chronology <- df.chronology[-c(23,24,32,33,56)] \n  \n  # Create a counts dataframe where the taxa that are present will be stored as 1\n  df.counts <- df.chronology[14:ncol(df.chronology)]\n  df.counts[df.counts>0] <- 1\n  \n  # Create a dataframe with a sum of presences\n  df.sites.present <- colSums(df.counts)\n\n  # Calculate ubiquity and round the value to 2 decimals\n  Ubiquity <- (df.sites.present / nrow(df.chronology))*100\n  Ubiquity <- round(Ubiquity, 2)\n  \n  # Add a category that explains what type of plant is it (useful for visualisation)\n  Plants_Type <- data.frame(Type=1:38)\n  Plants_Type$Type[1:9] <- \"Cereals\"\n  Plants_Type$Type[10:16] <- \"Pulses\"\n  Plants_Type$Type[17:38] <- \"Fruits/Nuts\"\n\n  # Final dataframe that the function will return\n  Ubiquity <- cbind.data.frame(\"Chronology\" = chronology, \n                               \"Macroregion\" = macroregion, \n                               \"Plant\"=names(Ubiquity), \n                               \"Plant.Type\"=Plants_Type$Type, \n                               \"Ubiquity\"= Ubiquity)\n  Ubiquity <- data.frame(Ubiquity, row.names = NULL)\n  \n  \n  return(Ubiquity)\n}"
  },
  {
    "objectID": "functions.html#zooarchaeology",
    "href": "functions.html#zooarchaeology",
    "title": "Custom functions",
    "section": "Zooarchaeology",
    "text": "Zooarchaeology"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Long-term Dynamics and Peasant Autonomy in the Italian Countryside",
    "section": "",
    "text": "AFFILIATION\nEMAIL"
  },
  {
    "objectID": "index.html#distribution-map",
    "href": "index.html#distribution-map",
    "title": "Long-term Dynamics and Peasant Autonomy in the Italian Countryside",
    "section": "Distribution map",
    "text": "Distribution map\nThe map below (Figure 1.1) shows the distribution of the samples used for this project. Hover to the point of interest and click on the marker to see what data is available.\n\n\n\n\n\n\n\n\nFigure 1.1: Legend: bot = Archaeobotanical remains, zoo = Zooarchaeological remains, poll = Pollen remains. If the codes are combined, more than one type of data is available for the same context and chronology."
  },
  {
    "objectID": "index.html#counts",
    "href": "index.html#counts",
    "title": "Long-term Dynamics and Peasant Autonomy in the Italian Countryside",
    "section": "Counts",
    "text": "Counts\n\n\n\nThe graphs below (Figure 1.2) provide counts of the (a) sample types3 and (b) site types in the database.\n\n\n\n\n\n\n\n(a) Data type.\n\n\n\n\n\n\n\n(b) Site type.\n\n\n\n\nFigure 1.2: Database status"
  }
]