<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Peasants, Agriculture, and Environment in the 1st Millennium CE Italian Countryside: A Bayesian approach - 6&nbsp; Methods</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./archaeobotany.html" rel="next">
<link href="./database.html" rel="prev">
<link href="./favicon.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./materials_archaeobotany.html">Materials and Methods</a></li><li class="breadcrumb-item"><a href="./methods.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Methods</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Peasants, Agriculture, and Environment in the 1<sup>st</sup> Millennium CE Italian Countryside: A Bayesian approach</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/robertoragno/phd" rel="" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
    <a href="https://twitter.com/ragno_roberto" rel="" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-twitter"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Abstract</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Introduction</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./literature_review.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Literature Review</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Materials and Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./materials_archaeobotany.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Archaeobotany</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./materials_zooarchaeology.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Zooarchaeology</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./database.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">The database</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./methods.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Methods</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Results</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./archaeobotany.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Archaeobotany</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./zooarchaeology.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Zooarchaeology</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Discussion and Conclusions</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./discussion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Discussion</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./conclusions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Conclusions</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Bibliography</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./sites_references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sites bibliography</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./functions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Custom functions</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-data-collection" id="toc-sec-data-collection" class="nav-link active" data-scroll-target="#sec-data-collection"><span class="header-section-number">6.1</span> Data collection</a></li>
  <li><a href="#introduction-to-statistical-computing" id="toc-introduction-to-statistical-computing" class="nav-link" data-scroll-target="#introduction-to-statistical-computing"><span class="header-section-number">6.2</span> Introduction to statistical computing</a>
  <ul class="collapse">
  <li><a href="#statistical-programming-r" id="toc-statistical-programming-r" class="nav-link" data-scroll-target="#statistical-programming-r"><span class="header-section-number">6.2.1</span> Statistical programming: <em>R</em></a></li>
  </ul></li>
  <li><a href="#issues-and-approaches-in-the-quantification-of-archaeobotanical-data" id="toc-issues-and-approaches-in-the-quantification-of-archaeobotanical-data" class="nav-link" data-scroll-target="#issues-and-approaches-in-the-quantification-of-archaeobotanical-data"><span class="header-section-number">6.3</span> Issues and approaches in the quantification of archaeobotanical data</a>
  <ul class="collapse">
  <li><a href="#ubiquity" id="toc-ubiquity" class="nav-link" data-scroll-target="#ubiquity"><span class="header-section-number">6.3.1</span> Ubiquity</a></li>
  <li><a href="#richness-and-diversity-indices" id="toc-richness-and-diversity-indices" class="nav-link" data-scroll-target="#richness-and-diversity-indices"><span class="header-section-number">6.3.2</span> Richness and diversity indices</a></li>
  <li><a href="#sec-met-multivariate-statistics" id="toc-sec-met-multivariate-statistics" class="nav-link" data-scroll-target="#sec-met-multivariate-statistics"><span class="header-section-number">6.3.3</span> Multivariate analysis</a></li>
  <li><a href="#sec-case-study-richness-cereals-macroreg" id="toc-sec-case-study-richness-cereals-macroreg" class="nav-link" data-scroll-target="#sec-case-study-richness-cereals-macroreg"><span class="header-section-number">6.3.4</span> Case study: Cereal richness across the Italian subregions</a></li>
  </ul></li>
  <li><a href="#sec-issues-zoo-quant" id="toc-sec-issues-zoo-quant" class="nav-link" data-scroll-target="#sec-issues-zoo-quant"><span class="header-section-number">6.4</span> Issues and approaches in the quantification of zooarchaeological data</a></li>
  <li><a href="#building-a-statistical-model" id="toc-building-a-statistical-model" class="nav-link" data-scroll-target="#building-a-statistical-model"><span class="header-section-number">6.5</span> Building a statistical model</a></li>
  <li><a href="#sec-bayesian-modeling" id="toc-sec-bayesian-modeling" class="nav-link" data-scroll-target="#sec-bayesian-modeling"><span class="header-section-number">6.6</span> Modeling, the Bayesian way</a>
  <ul class="collapse">
  <li><a href="#sec-building-bayesian-models" id="toc-sec-building-bayesian-models" class="nav-link" data-scroll-target="#sec-building-bayesian-models"><span class="header-section-number">6.6.1</span> Building Bayesian models</a></li>
  <li><a href="#sec-sampling-posterior-diagnostics" id="toc-sec-sampling-posterior-diagnostics" class="nav-link" data-scroll-target="#sec-sampling-posterior-diagnostics"><span class="header-section-number">6.6.2</span> Sampling from the posterior and model diagnostics</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-methods" class="quarto-section-identifier"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Methods</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>This chapter details the methodology implemented to undertake the present study. The first section concerns the data collection process, encompassing the delimitation of this research’s chronological and geographical parameters. This is followed by a concise introduction to statistical computing programming languages like R. The third section outlines the approaches and concerns of archaeobotanical quantification, addressing ubiquity, richness, and diversity indices, as well as multivariate analysis used in the case study of the cereal dataset. The subsequent section provides a brief overview of the issues in the zooarchaeological dataset, including overdispersion. The fifth section provides an overview of statistical modelling, leading into the following section which discusses Bayesian inference and modelling. Models with examples from archaeobotanical and zooarchaeological quantifications are also provided.</p>
<section id="sec-data-collection" class="level2" style="text-align: justify" data-number="6.1">
<h2 style="text-align: justify" data-number="6.1" class="anchored" data-anchor-id="sec-data-collection"><span class="header-section-number">6.1</span> Data collection</h2>
<p>This section focuses on the data collection phase, complementing the data entry process discussed in <a href="database.html"><span>Chapter&nbsp;5</span></a>. The research uses legacy or published archaeobotanical and zooarchaeological data from a variety of sources such as monographs, book chapters, journal articles, conference papers, excavation reports, websites, and dissertations. The sites bibliography (in the <a href="https://robertoragno.github.io/phd/sites_references.html">Online Supplementary Materials</a>) provides a comprehensive list of these sources, while <a href="database.html#fig-publication-type-counts">Figure&nbsp;<span>5.2</span></a> offers a graphical overview of the distribution of primary data sources. A few existing syntheses of archaeobotanical and zooarchaeological data (<em>cf.</em> <a href="literature_review.html"><span>Chapter&nbsp;2</span></a>) significantly contributed to the foundation of the database. The data was then organised and stored in a relational database, as detailed in the previous chapter.</p>
<p>The publications selected met a number of criteria. Only trusted academic publications were considered, with a requirement for precise site location information or specific geographical context. Only sources that reported raw counts of plant and animal remains were selected. While data quality varied, efforts were made to include details from older excavation reports, albeit with some limitations. Comprehensive information, including sampling strategies, stratigraphic unit (SU) numbers, preservation methods, and sampled soil volume, were incorporated where available. To ensure robust statistical analysis and meaningful results, certain exclusions were necessary. Sporadic finds and low-quantity assemblages were omitted from particular analyses (e.g., PERMANOVA and nMDS) but retained in the database for comprehensive documentation. For plant and animal taxa, clear and unambiguous taxonomic indications were required for inclusion in the database. For example, plants belonging to the <em>Triticum</em> group that could not be further identified to species level were classified as ‘Unsp. Cereals’. Similarly, animal bones that were either unidentified or identified only by size (e.g.&nbsp;large ungulates) were stored as ‘unidentified’ to avoid potential confusion with other taxa.</p>
<p>The samples selected for this research come from sites that fall within the spatial and chronological boundaries of the study. Inclusion criteria encompassed sites within mainland Italy, dating from the 1<sup>st</sup> century BCE to the 11<sup>th</sup> century CE. In order to assess the geographical differences within the peninsula, and to simplify the statistics, the region under review was ideally divided into three parts: northern, central, and southern Italy. Northern Italy lies between today’s political northern limit and the latitude of about 43°N, the centre between about 42°N and 41°N, and the south from about 40°N to the southern limit of Calabria. To facilitate this division, the boundary of today’s regions was followed (<a href="database.html#tbl-macroregions-db-join">Table&nbsp;<span>5.6</span></a>). Although the region of Abruzzo is currently considered part of southern Italy for cultural reasons, it has been included in central Italy following a geographical logic. There are important micro-ecological differences between regions, but each of these three sub-regions has coastal, plain, hilly and mountainous areas. The choice of boundaries was based on other large-scale studies of ancient Italy <span class="citation" data-cites="palmisanoLongTermDemographicTrends2021 parkinsonRadiocarbonDatedTrends2021">(<a href="references.html#ref-palmisanoLongTermDemographicTrends2021" role="doc-biblioref">Palmisano et al., 2021</a>; <a href="references.html#ref-parkinsonRadiocarbonDatedTrends2021" role="doc-biblioref">Parkinson et al., 2021</a>)</span>.</p>
<p><a href="database.html"><span>Chapter&nbsp;5</span></a>, outlines site details, including location, geographical features, site type, and culture. Whenever it was not possible to assign a site to a specific culture (e.g.&nbsp;Byzantine, Lombard, etc.), this field was filled in generically with the corresponding chronology. For this project, decisions have been made on how to classify archaeological sites for the purposes of collecting statistical data and storing it in the database. While some sites are relatively easy to identify and categorise, there can be uncertainty, for example, in classifying sites as urban or rural, as these terms can have different meanings in the context of archaeology. The problem of correctly defining a settlement is not new to archaeological theory, and there have been several attempts to define the concept of ‘site’ itself <span class="citation" data-cites="dunnellNotionSite1992 parsonsArchaeologicalSettlementPatterns1972 triggerSettlementArchaeologyIts1967 davisDefiningWhatWe2020 bowesRomanPeasantProject2020">(<a href="references.html#ref-bowesRomanPeasantProject2020" role="doc-biblioref">Bowes, 2020, p. 11</a>; <a href="references.html#ref-davisDefiningWhatWe2020" role="doc-biblioref">Davis, 2020</a>; <a href="references.html#ref-dunnellNotionSite1992" role="doc-biblioref">Dunnell, 1992</a>; <a href="references.html#ref-parsonsArchaeologicalSettlementPatterns1972" role="doc-biblioref">Parsons, 1972</a>; <a href="references.html#ref-triggerSettlementArchaeologyIts1967" role="doc-biblioref">Trigger, 1967</a>)</span>. In order to ensure accurate categorisation, it was essential to consider the specific context and characteristics of each site, as well as the definitions and criteria used to classify them. This meticulous approach allowed for a robust selection of sites falling within the spatial and chronological boundaries of the study, thus ensuring the reliability and relevance of the data collected. For example, isolated and smaller settlements that did not have the typical characteristics of the Roman <span class="citation" data-cites="grosStoriaUrbanisticaMondo2014">(<a href="references.html#ref-grosStoriaUrbanisticaMondo2014" role="doc-biblioref">Gros and Torelli, 2014</a>)</span> or medieval <span class="citation" data-cites="heersCittaNelMedioevo1995 piccinatoUrbanisticaMedievale1993">(<a href="references.html#ref-heersCittaNelMedioevo1995" role="doc-biblioref">Heers, 1995</a>; <a href="references.html#ref-piccinatoUrbanisticaMedievale1993" role="doc-biblioref">Piccinato, 1993</a>)</span> city (public buildings, etc.) were recorded as ‘rural’. In the majority of cases, the site classification adhered to the original categorization provided by the respective authors.</p>
<p>Another criterion for selecting an assemblage was chronology. Each assemblage (or collection of assemblages) had to be associated with a chronological range in centuries or years. Where reports gave only vague chronologies, such as ‘Roman’ or ‘early medieval’, the report was discarded. This approach minimises the risk of misinterpretation when analysing the data. In many cases, publications report chronologies expressed in phases; if these phases were undated, the assemblage was not included in the database. The level of detail for assemblages from the same site included in the database is contextual and chronological. If the same context (e.g.&nbsp;‘Room A’) provided several assemblages for the same chronological range, these were merged. This choice, although it may result in a loss of scale of detail, was necessary for reasons of time and resources. Most of the statistics performed on the dataset are based on a assemblage periodisation, from the Roman Age to the Medieval Age. The chronologies were defined as follows:</p>
<ul>
<li><p><strong>[R] Roman</strong>: from the 1<sup>st</sup> century BCE to the 2<sup>nd</sup> century CE.</p></li>
<li><p><strong>[LR] Late Roman</strong>: from the 3<sup>rd</sup> to the 5<sup>th</sup> century CE.</p></li>
<li><p><strong>[EMA] Early Middle Ages</strong>: from the 6<sup>th</sup> to the 10<sup>th</sup> century CE.</p></li>
<li><p><strong>[Ma] Middle Ages:</strong> from the 11<sup>th</sup> century CE onwards.</p></li>
</ul>
<p>In the database, the tables <code>faunal_chronologies</code> and <code>plants_chronologies</code> connect each bioarchaeological assemblage to another table with the identification numbers for the periods (e.g.&nbsp;Sample 1 = ID 1). If an assemblage has a chronology ranging between two periods, two separate entries will be recorded on the database (e.g.&nbsp;Sample 1 – 2<sup>nd</sup> to 3<sup>rd</sup> c.&nbsp;CE = Periods: Roman, Late Roman) with the result of the assemblage being repeated in both periods.</p>
<div id="fig-periodisation" class="quarto-figure quarto-figure-center anchored" style="text-align:center;">
<figure class="figure">
<p><img src="images/Periodization.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;6.1: Periodisation schema.</figcaption>
</figure>
</div>
<p>One of the methodological issues affecting this project is that of chronological fuzziness. Dating plant and animal remains using radiocarbon is very rare, at least in the samples recorded in the database. Most of these samples are dated using ceramics, and chronologies can range between one century or several. Rather than creating arbitrary weights that would affect the models in unexpected ways, all assemblages were considered to have the same weight and impact on the calculations. For example, if an assemblage spans three centuries, it is difficult to say whether the layer was formed in three centuries (e.g.&nbsp;a waste pit used over a long period), or whether the dating of that layer is less precise because a particular type of pottery was used over a long period.</p>
</section>
<section id="introduction-to-statistical-computing" class="level2" style="text-align:justify;" data-number="6.2">
<h2 style="text-align:justify;" data-number="6.2" class="anchored" data-anchor-id="introduction-to-statistical-computing"><span class="header-section-number">6.2</span> Introduction to statistical computing</h2>
<p>Statistical computing, often referred to as computational statistics, is a branch of statistics that uses computational approaches to solving statistical problems. Traditionally, the term ‘statistical computing’ places more emphasis on numerical methods, while ‘computational statistics’ refer to topics such as resampling methods, exploratory data analysis, neural networks, etc. <span class="citation" data-cites="rizzoStatisticalComputing2019">(<a href="references.html#ref-rizzoStatisticalComputing2019" role="doc-biblioref">Rizzo, 2019</a>)</span>. Specifically, computational statistics deals with methods “unthinkable before the computer age” <span class="citation" data-cites="lauroComputationalStatisticsStatistical1996">(<a href="references.html#ref-lauroComputationalStatisticsStatistical1996" role="doc-biblioref">Lauro, 1996</a>)</span>. In archaeology, one widely used programming language for statistical computing is R, which has the advantage of relying on its strong academic community. The community actively contributes to the development of new packages, expanding the functionality and versatility of R for statistical computing. Researchers often choose R for statistical computing in archaeology due to its comprehensive statistical capabilities, flexibility, and the ability to reproduce and share analyses. The syntax and structure of R are specifically designed to facilitate data analysis and statistical modelling, allowing researchers to perform complex analyses efficiently. Additionally, R provides powerful data visualisation tools, enabling researchers to create visually appealing and informative graphs to communicate their findings.</p>
<section id="statistical-programming-r" class="level3" style="text-align:justify;" data-number="6.2.1">
<h3 style="text-align:justify;" data-number="6.2.1" class="anchored" data-anchor-id="statistical-programming-r"><span class="header-section-number">6.2.1</span> Statistical programming: <em>R</em></h3>
<p>R, as described on the <a href="https://cran.r-project.org/doc/FAQ/R-FAQ.html#What-is-R_003f">R-Project FAQs</a> is a “system for statistical computation and graphics. It consists of a language plus a run-time environment with graphics, a debugger, access to certain system functions, and the ability to run programs stored in script files”. Increasingly popular for data scientists, R is based on S and provides its own IDE (the R GUI), although <a href="https://www.rstudio.com">RStudio</a> is the most popular IDE for computing the R language. For this project, RStudio was the standard IDE.</p>
<section id="r-packages" class="level4" data-number="6.2.1.1">
<h4 data-number="6.2.1.1" class="anchored" data-anchor-id="r-packages"><span class="header-section-number">6.2.1.1</span> R Packages</h4>
<p>In addition to base R, several packages enhance its performances and offer more tools to users. The packages are distributed by the official <a href="https://cran.r-project.org/web/packages/">CRAN repository</a>, which counts more than 20,248 packages<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. This section details some of the packages that have been most useful for this research.</p>
<section id="tidyverse" class="level5" data-number="6.2.1.1.1">
<h5 data-number="6.2.1.1.1" class="anchored" data-anchor-id="tidyverse"><span class="header-section-number">6.2.1.1.1</span> tidyverse</h5>
<p>The <strong>tidyverse</strong> ecosystem <span class="citation" data-cites="tidyverse">(<a href="references.html#ref-tidyverse" role="doc-biblioref">Wickham et al., 2019</a>)</span> is a core set of packages for R, maintained by Hadley Wickham for importing, tidying, transforming and visualising data which includes packages such as—ggplot2, dplyr, tidyr, stringr, tibble, forcats, purr, readr.</p>
</section>
<section id="ggplot2" class="level5" data-number="6.2.1.1.2">
<h5 data-number="6.2.1.1.2" class="anchored" data-anchor-id="ggplot2"><span class="header-section-number">6.2.1.1.2</span> ggplot2</h5>
<p><strong>ggplot2</strong> is the most common data visualisation package for R, included in the tidyverse environment. The package substitutes the R base graphics and allows visualisation of single and multiple components <span class="citation" data-cites="wickhamProgrammingGgplot22016">(<a href="references.html#ref-wickhamProgrammingGgplot22016" role="doc-biblioref">Wickham, 2016</a>)</span>.</p>
</section>
<section id="knitr" class="level5" data-number="6.2.1.1.3">
<h5 data-number="6.2.1.1.3" class="anchored" data-anchor-id="knitr"><span class="header-section-number">6.2.1.1.3</span> knitr</h5>
<p>The <strong>knitr</strong> engine enables the integration of R with HTML, Markdown and LaTeX. The package allows reproducible research <span class="citation" data-cites="knitr">(<a href="references.html#ref-knitr" role="doc-biblioref">Xie, 2021</a>)</span> and was used for generating dynamic reports and documentation for this thesis.</p>
</section>
<section id="vegan" class="level5" data-number="6.2.1.1.4">
<h5 data-number="6.2.1.1.4" class="anchored" data-anchor-id="vegan"><span class="header-section-number">6.2.1.1.4</span> vegan</h5>
<p>The <strong>vegan</strong> package <span class="citation" data-cites="oksanenVeganCommunityEcology2022">(<a href="references.html#ref-oksanenVeganCommunityEcology2022" role="doc-biblioref">Oksanen et al., 2022</a>)</span> is designed for ordination methods, diversity analysis and multivariate analysis in ecology.</p>
</section>
<section id="rethinking" class="level5" data-number="6.2.1.1.5">
<h5 data-number="6.2.1.1.5" class="anchored" data-anchor-id="rethinking"><span class="header-section-number">6.2.1.1.5</span> rethinking</h5>
<p>The <strong>rethinking</strong> package <span class="citation" data-cites="rethinking">(<a href="references.html#ref-rethinking" role="doc-biblioref">McElreath, 2023</a>)</span> provides tools and resources for statistical modeling and data analysis in a Bayesian framework. Developed by Richard McElreath, it is specifically designed to support the concepts and techniques described in his book “Statistical Rethinking: A Bayesian Course with Examples in R and Stan” <span class="citation" data-cites="mcelreath2016">(<a href="references.html#ref-mcelreath2016" role="doc-biblioref">McElreath, 2016</a>)</span>. This package also uses the <strong>rstan</strong> package <span class="citation" data-cites="rstan">(<a href="references.html#ref-rstan" role="doc-biblioref">2023</a>)</span> for certain functions. <strong>rstan</strong> allows the implementation of Stan in R, and was also used to model zooarchaeological NISP data.</p>
</section>
</section>
</section>
</section>
<section id="issues-and-approaches-in-the-quantification-of-archaeobotanical-data" class="level2" style="text-align:justify;" data-number="6.3">
<h2 style="text-align:justify;" data-number="6.3" class="anchored" data-anchor-id="issues-and-approaches-in-the-quantification-of-archaeobotanical-data"><span class="header-section-number">6.3</span> Issues and approaches in the quantification of archaeobotanical data</h2>
<p>Quantitative analysis of the archaeobotanical remains collected proved difficult due to several biases in the dataset which, if not controlled, could lead to erroneous results. In fact, the majority of published archaeobotanical material can be attributed to judgemental/feature-based sampling, which introduces biases as outlined in <a href="materials_archaeobotany.html"><span>Chapter&nbsp;3</span></a>. Given the paucity of Italian archaeobotanical samples available for the period compared to other European countries, and given that many samples contained outliers, it was not possible to adopt a purely quantitative strategy using the raw counts, but the data had to be processed in other ways. Before going any further, let us consider three sites to give a practical example of the outliers that were so common in the dataset: Parma (Piazza Garibaldi/via Cavestro), Miranduolo, Brescia (via Alberto Mario). The sample from the Parma excavation, Piazza Garibaldi/via Cavestro, comes from an urban cesspit and the seeds have been preserved by waterlogging <span class="citation" data-cites="bosiSeedsFruitsPollen2011 bosiIndaginiArcheobotanicheSul2012">(<a href="references.html#ref-bosiIndaginiArcheobotanicheSul2012" role="doc-biblioref">Bosi et al., 2012</a>, <a href="references.html#ref-bosiSeedsFruitsPollen2011" role="doc-biblioref">2011</a>)</span>. In this sample, certain taxa skew the distribution and under-represent other plant remains. In the case of the mid 8<sup>th</sup> to mid 9<sup>th</sup> century samples from the rural village of Miranduolo, charred samples were taken from layers of a storehouse and storage pits. The outlier here is represented by <em>Triticum aestivum/durum</em> (4,037 seeds) and cereals in general, which have much higher counts compared to legumes or fruits <span class="citation" data-cites="buonincontriFarmingRuralSettlement2014">(<a href="references.html#ref-buonincontriFarmingRuralSettlement2014" role="doc-biblioref">Buonincontri et al., 2014</a>)</span>. In other cases, excavators may have taken samples from layers where a large conglomerate of seeds was visible to the naked eye. For example, in Brescia, via Alberto Mario, a small food store contained a large number of charred seeds of <em>Panicum miliaceum</em> (more than 21,000, after which the researchers stopped counting) and <em>Triticum monococcum</em> (750 seeds). Apart from these taxa, other plant remains were found in much smaller quantities <span class="citation" data-cites="castiglioniBrescianArchaeobotanicalStudies2019">(<a href="references.html#ref-castiglioniBrescianArchaeobotanicalStudies2019" role="doc-biblioref">Castiglioni and Rottoli, 2019</a>)</span>. It is clear here how the sampling location affects the type of taxa we might expect to find: cereals are much more common than other taxa in food storage areas, whereas other seeds ingested by humans (figs, strawberries, grapes, etc.) might be expected to be found in cesspits <span class="citation" data-cites="smithDefiningIndicatorPackage2013">(<a href="references.html#ref-smithDefiningIndicatorPackage2013" role="doc-biblioref">Smith, 2013</a>)</span>. In addition to the biases that may be introduced by the choice of sampling strategies, as discussed in <a href="materials_archaeobotany.html"><span>Chapter&nbsp;3</span></a>, other problems may arise, for example, from the way in which plant remains are preserved. Once again, <a href="materials_archaeobotany.html#fig-pres-mode-species-livarda">Figure&nbsp;<span>3.2</span></a> and <a href="materials_archaeobotany.html#fig-vanderveen2013-preservation-mode">Figure&nbsp;<span>3.3</span></a> give a breakdown of the way in which seeds are preserved under different conditions.</p>
<p>In order to ignore these sources of bias, we would need a very large dataset so that outliers would have less effect on the calculations. Since this is not the case, we need to take precautions to avoid jumping to false conclusions. The first is to transform the data and the second, discussed later, is to use a statistical modelling approach. When it comes to numerical transformations for statistical analysis, there are several examples and approaches in the scientific literature <span class="citation" data-cites="jamesIntroductionStatisticalLearning2021 bishopPatternRecognitionMachine2006a">(<a href="references.html#ref-bishopPatternRecognitionMachine2006a" role="doc-biblioref">Bishop, 2006</a>; <a href="references.html#ref-jamesIntroductionStatisticalLearning2021" role="doc-biblioref">James et al., 2021</a>)</span>. Unfortunately, none of them are helpful for outliers of this nature; each site presents its own unique problems. Although <span class="citation" data-cites="heinrichModellingCropSelectionRoman2017">Heinrich (<a href="references.html#ref-heinrichModellingCropSelectionRoman2017" role="doc-biblioref">2017</a>)</span> argues for the need for quantitative archaeobotanical analyses that go beyond presence/absence categories, with the current state of information available for the 1<sup>st</sup> millennium CE Italian peninsula, this is simply not yet possible. For this reason, most of the analyses of the palaeobotanical dataset presented in this study are based on the presence of particular species in each context <span class="citation" data-cites="bastowwilsonSpeciesPresenceAbsence2012">(<a href="references.html#ref-bastowwilsonSpeciesPresenceAbsence2012" role="doc-biblioref">Bastow Wilson, 2012</a>)</span>. Numerically, this means that raw counts are converted to 1 to indicate that a taxon is present, and to 0 to indicate that it is absent from a sample. Although much safer than other types of data transformation, this transformation has a strong effect on the data and inevitably changes the range of questions that can be asked of our dataset. Within each sample, the data is flattened and the importance of a taxon relative to other taxa in the same context is lost. Instead of asking questions such as “What was the most abundant plant in Roman rural sites?”, we can only ask “Which plant was most frequently found in Roman rural sites?”.</p>
<p>In one case, for demonstration purposes, the samples were transformed in a different way in order to preserve the quantitative information. In <a href="archaeobotany.html"><span>Chapter&nbsp;7</span></a> it is possible to see how different strategies affect the quantification of cereals at different stages. This short case study was chosen because cereals are present in most samples (unlike legumes, for example) and because the chronological division is the one that creates the least imbalance in the data. Other groupings, for example based on site type, would have distorted the results as smaller group sizes are unreliable, especially when frequentist approaches to statistics are used. The purpose of the transformations was to see how the proportions of cereals changed over time. In the first example (<a href="archaeobotany.html#tbl-Cereals-Ratios-Means">Table&nbsp;<span>7.10</span></a>), simple means were calculated based on the total number of cereals. Whenever a cereal taxon was not present in a sample, its proportion was considered to be 0. In addition, the means are also affected by any other cereal outliers present in the samples. The second example (<a href="archaeobotany.html#tbl-Cereals-Ratios-Means-Pres-Only">Table&nbsp;<span>7.11</span></a>) shows instead the means calculated on the basis of true presences, excluding missing values (<em>NAs</em>). This type of calculation deals well with zero-inflated columns (<em>i.e.</em> cereal taxa that are rarely present in a sample), but runs the risk of over-representing rare species. Moreover, the results are still biased by the outliers present in the sample. The third example (<a href="archaeobotany.html#tbl-Cereals-Ranks-ratios-means">Table&nbsp;<span>7.12</span></a>) uses a different approach. This method involves converting the data into relative ranks using the <code>decostand()</code> function found in the <em>vegan</em> package <span class="citation" data-cites="vegan">(<a href="references.html#ref-vegan" role="doc-biblioref">Oksanen et al., 2020</a>)</span>. This transformation replaces the original count data with their corresponding increasing ranks, while leaving zeros unaffected. The result is that the taxon with the highest abundance is ranked as 1. This process has the effect of mitigating the effects of pronounced variations within the data, effectively smoothing out extreme values. Crucially, however, it preserves valuable information about the relative abundance of taxa. The values in these tables will be commented on later, but what is important to note here is how different strategies yield different figures, and how important it is to be careful when working with biased datasets. The optimal choice, although very limiting, is to work on presence/absence.</p>
<section id="ubiquity" class="level3" style="text-align:justify;" data-number="6.3.1">
<h3 style="text-align:justify;" data-number="6.3.1" class="anchored" data-anchor-id="ubiquity"><span class="header-section-number">6.3.1</span> Ubiquity</h3>
<p>Ubiquity, or presence analysis, is a popular approach in archaeobotanical quantitative analysis. The method is straightforward—the number of sites/contexts where a plant is present is divided by the total number of sites/contexts under examination. If, for instance, an olive pit is present in 3 sites out of 10, the ubiquity for the olive will be 0.30. The formula for the calculation is at follows:</p>
<p><span class="math display">\[
U_x = (\frac{N_p}{N_{tot}})
\]</span> where <span class="math inline">\(N_p\)</span> is the number of presences, and <span class="math inline">\(N_{tot}\)</span> is the total number of contexts.</p>
<p>This approach has both advantages and drawbacks. Presence analysis minimizes the impact of outliers (overrepresented plant species) on calculations <span class="citation" data-cites="wrightMethodologicalIssuesPaleoethnobotany2010">(<a href="references.html#ref-wrightMethodologicalIssuesPaleoethnobotany2010" role="doc-biblioref">Wright, 2010, pp. 51–52</a>)</span>, but the relative importance of a plant in a particular context is lost. It is also important to keep in mind that taxa richness is influenced by factors including sample size, deposition and preservation modes, and sampling strategies (e.g.&nbsp;sieving methodologies) <span class="citation" data-cites="pearsallPaleoethnobotanyHandbookProcedures2015a banningAnalysingPlantRemains2000">(<a href="references.html#ref-banningAnalysingPlantRemains2000" role="doc-biblioref">Banning et al., 2000</a>; <a href="references.html#ref-pearsallPaleoethnobotanyHandbookProcedures2015a" role="doc-biblioref">Pearsall, 2015, pp. 161–2</a>)</span>. In general, larger sample sizes tend to produce more diverse assemblages, while smaller assemblages under-represent rarer species <span class="citation" data-cites="plogSampleSizeRichnessRelation1993 kadanePossibleStatisticalContributions1988">(<a href="references.html#ref-kadanePossibleStatisticalContributions1988" role="doc-biblioref">Kadane, 1988</a>; <a href="references.html#ref-plogSampleSizeRichnessRelation1993" role="doc-biblioref">Plog and Hegmon, 1993</a>)</span>. Despite these limits, ubiquity is the best option for immediate reading of the botanical dataset of the Italian peninsula. The variability of the seed/fruit assemblages is too high, with different species being outliers in different sites. As mentioned earlier, the probable reason for this is probably the poor quality of sampling, which usually occurs after an agglomerate of seeds is found during excavation. Typically, agglomerates are found in specific storage or processing areas (e.g.&nbsp;wine/olive processing quarters), skewing the distribution of the curve. Ubiquity overcomes this problem by providing a score based on the percentage presence of a plant species in the samples considered.</p>
<p>In addition to the general calculation of the diachronic ubiquity across the entire peninsula, it is also important to look for regional differences in the archaeobotanical dataset. To do so, I created an <code>R</code> function to subset data related to northern, central and southern Italian regions. For a clearer reading of the plot, I divided the plants into–<code>Cereals</code>, <code>Pulses</code> and <code>Fruits/Nuts</code>. The results are presented in <a href="archaeobotany.html"><span>Chapter&nbsp;7</span></a>.</p>
</section>
<section id="richness-and-diversity-indices" class="level3" style="text-align:justify;" data-number="6.3.2">
<h3 style="text-align:justify;" data-number="6.3.2" class="anchored" data-anchor-id="richness-and-diversity-indices"><span class="header-section-number">6.3.2</span> Richness and diversity indices</h3>
<p>Species richness (<span class="math inline">\(S\)</span>) is the number of species found within a community or ecosystem. The boundaries of the region are defined by the researcher. While ecologists use sampling or censuses to obtain the richness value, archaeobotanists can only rely on sampling, counting the presence of species in the area under investigation <span class="citation" data-cites="mooreDiversityTaxonomicFunctional2013">(<a href="references.html#ref-mooreDiversityTaxonomicFunctional2013" role="doc-biblioref">Moore, 2013</a>)</span>. Species diversity is a measurement of species richness combined with species evenness, meaning that it takes into account not only how many species are present, but also how evenly distributed the numbers of each species are. There are several diversity indices used in ecology, all of which include abundance in the calculation. Given the biases in the dataset discussed earlier, it is safer to calculate diversity by grouping the assemblages only chronologically, so that the imbalance in the groups is not too high.</p>
<p>Species diversity can be a useful indicator of the centralisation of agricultural practices towards specialised production or the specialised storage/import of specific products. Two diversity indices are commonly used in archaeobotany: the Shannon Equitability Index (<span class="math inline">\(E_{H}\)</span>) and the Simpson Index (D). Both of these measures range from 0 to 1, where a value of 0 indicates an uneven assemblage or low diversity, while a value of 1 indicates maximum diversity. The Shannon Equitability Index (<span class="math inline">\(E_{H}\)</span>) assesses evenness by considering both species diversity and their distribution. In simpler terms, a higher <span class="math inline">\(E_{H}\)</span> score indicates a more balanced spread of individuals among species. Also referred to as the Pielou index, this measure is a variant of the Shannon index <span class="citation" data-cites="hillDiversityEvennessUnifying1973 pielouMeasurementDiversityDifferent1966">(<a href="references.html#ref-hillDiversityEvennessUnifying1973" role="doc-biblioref">Hill, 1973</a>; <a href="references.html#ref-pielouMeasurementDiversityDifferent1966" role="doc-biblioref">Pielou, 1966</a>)</span>. Its calculation follows the formula: <span class="math display">\[E_{H} = \frac{ - \sum\limits_{i=1}^{S} p_{i} \cdot \ln p_{i}}{\ln S}\]</span></p>
<p>Here, <span class="math inline">\(\sum\limits_{i=1}^{S}\)</span> indicates the sum across all species, with <span class="math inline">\(i\)</span> ranging from 1 to <span class="math inline">\(S\)</span>, representing the total number of species. <span class="math inline">\(p_{i}\)</span> stands for the proportion (relative abundance) of the <span class="math inline">\(i\)</span>th species, and <span class="math inline">\(ln\)</span> signifies the natural logarithm. The term <span class="math inline">\(S\)</span> denotes the total number of species in the ecological community.</p>
<p>The Simpson index, on the other hand, is a different measure of species diversity that emphasises dominance within a community. It quantifies the probability that two randomly selected individuals belong to the same species. Higher values of the Simpson Index indicate lower diversity, with greater dominance of a few species <span class="citation" data-cites="simpsonMeasurementDiversity1949">(<a href="references.html#ref-simpsonMeasurementDiversity1949" role="doc-biblioref">Simpson, 1949</a>)</span>. The calculation of the Simpson Index is given by the formula: <span class="math display">\[D = 1 - \sum\limits_{i=1}^{S} p_{i}^2\]</span> The terms of this formula are equivalent to the previous ones, with <span class="math inline">\(\sum\limits_{i=1}^{S}\)</span> representing the sum across all species, with <span class="math inline">\(i\)</span> ranging from 1 to <span class="math inline">\(S\)</span>. Again, <span class="math inline">\(p_{i}\)</span> represents the proportion of the <span class="math inline">\(i\)</span>th species. This formula subtracts a calculated integer sum from 1, so that <span class="math inline">\(D\)</span> ranges from 0 to 1, where a value of 0 indicates maximum diversity (each species is equally abundant), and a value of 1 indicates minimum diversity (one species dominates the community).</p>
<p>Examining both measures together provides a more holistic view of the ecological characteristics of a community. The Shannon Equitability Index emphasises evenness, showing the balance of species distribution, while the Simpson Index highlights dominance and the prevalence of abundant species. The two indices presented above are not the only diversity and equitability indices available in scientific literature. Ecological diversity indices have indeed undergone several stages of critiques, with those advocating for better and more mathematically sound indices and those advocating that ecologists should stop using such indices and move on to other methods, such as multivariate analysis <span class="citation" data-cites="barrantesConceptualStatisticalProblems2009 dalyEcologicalDiversityMeasuring2018 morrisChoosingUsingDiversity2014 heipComparingSpeciesDiversity1974">(<a href="references.html#ref-barrantesConceptualStatisticalProblems2009" role="doc-biblioref">Barrantes and Sandoval, 2009</a>; <a href="references.html#ref-dalyEcologicalDiversityMeasuring2018" role="doc-biblioref">Daly et al., 2018</a>; <a href="references.html#ref-heipComparingSpeciesDiversity1974" role="doc-biblioref">Heip and Engels, 1974</a>; <a href="references.html#ref-morrisChoosingUsingDiversity2014" role="doc-biblioref">Morris et al., 2014</a>)</span>. In summary, although diversity indices can help to read the distribution of species within archaeobotanical assemblages, caution is required in their interpretation.</p>
<p>In this study, both diversity indices were applied to each assemblages in the dataset to produce a score. The diversity scores for each site were later modelled using a Bayesian approach, which is explained in more detail in the following sections of this chapter. The mathematical breakdown of the models specific to plant richness and diversity is presented in <a href="archaeobotany.html#sec-archaeobot-results-richness-diversity"><span>Section&nbsp;7.2</span></a>.</p>
</section>
<section id="sec-met-multivariate-statistics" class="level3" style="text-align:justify;" data-number="6.3.3">
<h3 style="text-align:justify;" data-number="6.3.3" class="anchored" data-anchor-id="sec-met-multivariate-statistics"><span class="header-section-number">6.3.3</span> Multivariate analysis</h3>
<p>This research uses multivariate analysis to explore possible relationships within the archaeobotanical dataset under investigation. Univariate analyses can be easily plotted and visualised using bar charts, histograms and density curves. A scatterplot (or scattergram) shows the relationship between two variables by plotting their values on the axes of a graph using Cartesian coordinates. This relationship can also be measured mathematically by calculating a distance between two points on the graph. However, the relationship between more than two variables is much harder to read on a scatterplot, as it would require as many axes as there are variables. If our analysis is exploratory, we may not yet know where to look for correlations. One possible solution is to analyse every combination of two variables in the data set and measure their correlation. This would take too much computing time if the dataset had a large number of variables, i.e.&nbsp;if we were dealing with big data. In addition, we would only be gathering information about the relationship between two variables when there may be another factor influencing a trend or phenomenon. Multivariate statistics has a wide range of applications, including grouping and multidimensional scaling, as well as in machine learning and predictive analysis <span class="citation" data-cites="fletcherDiggingNumbersElementary2005">(<a href="references.html#ref-fletcherDiggingNumbersElementary2005" role="doc-biblioref">Fletcher and Lock, 2005</a>)</span>. In this research, multivariate methods have been applied to the botanical dataset, mainly with the aim of <em>(i)</em> testing hypotheses between multiple variables, and <em>(ii)</em> reducing the dimensionality of the data, to assess which variables are the main drivers of change in the datasets, and to examine relationships between these variables. In particular, these methods have been used to test the hypothesis that different cereal farming strategies were adopted between southern and northern Italy in the early Middle Ages.</p>
<section id="hypothesis-testing-permanova" class="level4" data-number="6.3.3.1">
<h4 data-number="6.3.3.1" class="anchored" data-anchor-id="hypothesis-testing-permanova"><span class="header-section-number">6.3.3.1</span> Hypothesis testing: PERMANOVA</h4>
<p>The importance of statistical significance testing in archaeological applications was discussed in <a href="literature_review.html"><span>Chapter&nbsp;2</span></a>. In this context, concepts such as null hypothesis formulation and p-values were introduced. Within the framework of null hypothesis significance testing (NHST), parametric and non-parametric statistics are two different approaches used to analyse data and make inferences about population parameters. These approaches have different assumptions and are suitable for different types of data and situations. While parametric statistics are more powerful, they assume that data follow certain distributions (i.e.&nbsp;the normal distribution) and are based on parameters such as means and variances. Non-parametric statistics are less strict because they make no assumptions about the underlying distribution of the data. Rather than being based on numerical values, most of these methods are based on the rank or order of the data. Non-parametric statistics are more robust and appropriate in the case of ordinal, nominal, skewed data where the normality condition is not met <span class="citation" data-cites="hollanderNonparametricStatisticalMethods2015 wuNonparametricStatistics2017 kraska-millerNonparametricStatisticsSocial2014 wassermanAllNonparametricStatistics2006 andersonScalesStatisticsParametric1961">(<a href="references.html#ref-andersonScalesStatisticsParametric1961" role="doc-biblioref">Anderson, 1961</a>; <a href="references.html#ref-hollanderNonparametricStatisticalMethods2015" role="doc-biblioref">Hollander et al., 2015</a>; <a href="references.html#ref-kraska-millerNonparametricStatisticsSocial2014" role="doc-biblioref">Kraska-Miller, 2014</a>; <a href="references.html#ref-wassermanAllNonparametricStatistics2006" role="doc-biblioref">Wasserman, 2006</a>; <a href="references.html#ref-wuNonparametricStatistics2017" role="doc-biblioref">Wu et al., 2017</a>)</span>. As the cereal data set, transformed into presence/absence values, does not follow a normal distribution, non-parametric statistics are the more appropriate choice for hypothesis testing. In archaeology, significance tests are commonly used on the means of a group of assemblages to assess whether the assemblages come from the same distribution. In this specific case we will use a non-parametric test, permutational analysis of variance (PERMANOVA).</p>
<p>Permutational multivariate analysis of variance (PERMANOVA) is a versatile multivariate statistical test based on permutations. As a semiparametric test, it makes no assumptions regarding homogeneity of variances or normality of data distributions. The test was developed by Marti J. Anderson <span class="citation" data-cites="andersonPermutationalMultivariateAnalysis2017">(<a href="references.html#ref-andersonPermutationalMultivariateAnalysis2017" role="doc-biblioref">2017</a>)</span> as a flexible method for comparing groups of objects in a multivariate context. The primary focus of PERMANOVA is to determine whether there are statistically significant differences in centroids (location) and dispersion (spread) between the different groups being compared. This is achieved by examining measure space, a mathematical representation of the relationships between objects in the dataset. The test operates under a null hypothesis that there are no meaningful differences in centroids and dispersion between the groups. A permutation-based procedure rearranges the observed data in a variety of ways, generating a distribution of possible outcomes under the assumption that the null hypothesis is true <span class="citation" data-cites="gollandPermutationTestsClassification2005">(<a href="references.html#ref-gollandPermutationTestsClassification2005" role="doc-biblioref">Golland et al., 2005</a>)</span>. By comparing the observed test statistic with this permutation-derived distribution, PERMANOVA determines whether the observed differences in centroids and dispersion are statistically significant or could have occurred by chance. Before performing the analysis, it is necessary to calculate the distances between all pairs of objects within the dataset. These distances serve as a basis for assessing the dissimilarities between the objects and can be based on various metrics such as Euclidean distance, Jaccard dissimilarity, Manhattan distance, Bray-Curtis dissimilarity or other measures depending on the data <span class="citation" data-cites="bakkerPERMANOVA2023 andersonNewMethodNonparametric2001">(<a href="references.html#ref-andersonNewMethodNonparametric2001" role="doc-biblioref">Anderson, 2001</a>; <a href="references.html#ref-bakkerPERMANOVA2023" role="doc-biblioref">Bakker, 2023</a>)</span>. As the archaeobotanical dataset is examined using a presence/absence approach rather than raw counts, the most appropriate dissimilarity index is Jaccard. This index calculates the dissimilarity between sets of archaeobotanical assemblages and assigns a score to each pair of assemblages so that, given <span class="math inline">\(J(Sample_A, Sample_B)\)</span>, a value of 0 means that two assemblages have identical species compositions (all species present or all species absent), while a value of 1 means that the two assemblages have no species in common.</p>
</section>
<section id="dimensionality-reduction-and-ordination" class="level4" style="text-align:justify;" data-number="6.3.3.2">
<h4 style="text-align:justify;" data-number="6.3.3.2" class="anchored" data-anchor-id="dimensionality-reduction-and-ordination"><span class="header-section-number">6.3.3.2</span> Dimensionality reduction and ordination</h4>
<p>Dimensionality reduction techniques transform high-dimension datasets into a low-dimension ordination space, with the intention of maintaining the geometry and data structure as close as possible to the original dataset. The <strong>dimension</strong> of a dataset is given by the number of variables (<em>i.e.</em> the columns in the table). As anticipated in <a href="#sec-met-multivariate-statistics"><span>Section&nbsp;6.3.3</span></a>, as each variable is graphically represented by an axis, it would be virtually impossible to represent more than three axes in a graph. Ordination allows to reduce data dimensionality to usually one to three (at most) dimensions. Moreover, focusing on a reduced number of dimensions reduces the amount of “noise” that can mislead the interpretation <span class="citation" data-cites="gauchMultivariateAnalysisCommunity1982">(<a href="references.html#ref-gauchMultivariateAnalysisCommunity1982" role="doc-biblioref">Gauch, 1982</a>)</span>. The points generated through ordination techniques (the objects in our dataset) can eventually be plotted in a scatterplot. In most of the ordination methods, points plotting closer together in graph are more similar, whereas points far apart from each other are more dissimilar <span class="citation" data-cites="shennanQuantifyingArchaeology1997">(<a href="references.html#ref-shennanQuantifyingArchaeology1997" role="doc-biblioref">Shennan, 1997, p. 197</a>)</span>. For instance, one could perform an ordination on a group of burials in a cemetery where each point represents a single burial assemblage. After the ordination it is also possible to group the new reduced set of variables, to observe differences between groups and facilitate the interpretation. In the previous example, a group might be represented by burials of the same ethnic group, status, etc.</p>
<p>Many of the ordination techniques described in this chapter developed in fields outside archaeology, and are thus borrowed from disciplines as community ecology. Ecologists regularly apply ordination methods for the study of environmental gradients, so that the term “gradient analysis” is often used interchangeably with “ordination”. An environmental gradient refers to variations in site characteristics (e.g.&nbsp;time, elevation, temperature, vegetation, etc.), which in turn can affect biotic factors (e.g.&nbsp;species abundance, diversity, etc.) <span class="citation" data-cites="grebnerForestDynamics2013">(<a href="references.html#ref-grebnerForestDynamics2013" role="doc-biblioref">Grebner et al., 2013</a>)</span>. The purpose of ordination is then to identify the cause of ecological processes in the dataset. Generally, it is possible to apply ordination on datasets in which the variables have a cause-and-effect (e.g.&nbsp;climate vs.&nbsp;plant species) or mutual influences on each other. There are two main types of ordination, or gradient analysis, techniques (see <a href="#tbl-gradient-analysis">Table&nbsp;<span>6.1</span></a>): <strong>direct</strong> (constrained) or <strong>indirect</strong> (unconstrained). The objective of indirect (unconstrained) gradient analysis is to identify patterns between samples of ‘dependent variables’ (e.g.&nbsp;which sites are more similar according to their species composition). Conversely, direct gradient (or constrained) analysis includes more information (or tables) in a single analysis—the dependent variables are now constrained to be a function of other sets of ‘independent variables’ (usually environmental proxies). In short, a constrained analysis uses both datasets to find the best possible mathematical relationship between the dependent and independent variables. In this sense, direct gradient analysis can be considered as an extension of unconstrained analysis <span class="citation" data-cites="symsOrdination2008">(<a href="references.html#ref-symsOrdination2008" role="doc-biblioref">Syms, 2008</a>)</span>. The choice between using constrained or unconstrained methods for ordination depends on the research questions and on the dataset.</p>
<div id="tbl-gradient-analysis" class="anchored">
<table class="table">
<caption>Table&nbsp;6.1: Ordination methods used in gradient analysis. Table after <span class="citation" data-cites="cuffneyAquaticEcosystemsIndicators2014">Cuffney et al. (<a href="references.html#ref-cuffneyAquaticEcosystemsIndicators2014" role="doc-biblioref">2014, p. 149</a>)</span></caption>
<colgroup>
<col style="width: 16%">
<col style="width: 42%">
<col style="width: 39%">
</colgroup>
<thead>
<tr class="header">
<th>Response model</th>
<th>Indirect gradient analysis</th>
<th>Direct gradient analysis</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong><em>Linear</em></strong></td>
<td>Principal component analysis (PCA)</td>
<td>Redundancy analysis (RDA)</td>
</tr>
<tr class="even">
<td><strong><em>Unimodal</em></strong></td>
<td><p>Correspondence analysis (CA)</p>
<p>Detrended CA (DCA)</p></td>
<td><p>Canonical correspondence analysis (CCA)</p>
<p>Detrended CCA</p></td>
</tr>
<tr class="odd">
<td><strong><em>Monotonic</em></strong></td>
<td>non-metric multidimensional scaling (nMDS)</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<section id="sec-met-nmds" class="level5" data-number="6.3.3.2.1">
<h5 data-number="6.3.3.2.1" class="anchored" data-anchor-id="sec-met-nmds"><span class="header-section-number">6.3.3.2.1</span> nMDS</h5>
<p>Multidimensional scaling (MDS) is a technique to visualise the level of similarity of individual observations (e.g.&nbsp;sites/cases) in a dataset. MDS works with matrices containing Euclidean distances between each pair of observations. Conversely, <strong>non-metric multidimensional scaling</strong> (nMDS) is a rank-based approach that finds both:</p>
<ul>
<li><p>A non-parametric monotonic relationship between the items in the dissimilarity matrix and the Euclidean distances.</p></li>
<li><p>The location of items in the low-dimensional space.</p></li>
</ul>
<p>The goal of nMDS is to represent the pairwise dissimilarity between items in the matrix as closely as possible. For this reason, it is considered as a good technique for multivariate data visualisation. nMDS can be used on quantitative, qualitative and mixed data. The <code>R</code> function <code>metaMDS()</code> from the package <code>vegan</code> allows users to select the distance metric most appropriate to their data (e.g.&nbsp;Bray-Curtis, Jaccard, etc.). As nMDS is an iterative approach, meaning that the the computations are run until the best solution is found, it can be quite computationally demanding for larger datasets. Although the nMDS algorithm tries to minimize the ordination stress, it is a good practice to compute the <strong>ordination stress</strong> value to judge the reliability of the solution found (goodness-of-fit). Ordination stress indicates how much distorted are the fitted data when compared to the original observed samples. Stress values can also be visualised with the function <code>stressplot()</code> (<code>vegan</code> package), which produces a Shepard stressplot (<a href="#fig-shepard-plot-nmds">Figure&nbsp;<span>6.2</span></a>).</p>
<div id="fig-shepard-plot-nmds" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/ShepardPlot.png" class="img-fluid figure-img" style="width:90.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;6.2: A Shepard plot, from <a href="https://rpubs.com/CPEL/NMDS">R Studio Pubs</a>.</figcaption>
</figure>
</div>
<p>The Shepard plot displays the ordination distance against the observed distance. Ideally, the higher the points should fall on a monotonic line, where an increased observed distance is related to an increased ordination distance. Moreover, the higher the number of dimensions, the lower the stress value. If interested in choosing the appropriate number of dimensions, it is possible to use a scree plot which shows the number of dimensions against the stress level. Generally, it is possible to interpret stress values following these guidelines <span class="citation" data-cites="dexterTroubleStressFlexible2018">(<a href="references.html#ref-dexterTroubleStressFlexible2018" role="doc-biblioref">Dexter et al., 2018</a>)</span>:</p>
<div id="tbl-stress-nmds" class="anchored">
<table class="table">
<caption>Table&nbsp;6.2: Ordination stress for the interpretation of nMDS</caption>
<thead>
<tr class="header">
<th>Interpretation</th>
<th>Stress level</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Excellent</td>
<td>&lt; 0.05</td>
</tr>
<tr class="even">
<td>Good</td>
<td>&lt; 0.1</td>
</tr>
<tr class="odd">
<td>Usable (but caution is required)</td>
<td>&gt; 0.2</td>
</tr>
<tr class="even">
<td>Random</td>
<td>&gt; 0.3</td>
</tr>
</tbody>
</table>
</div>
<p>If the solution has produced a good stress level for the number of dimensions required, it is possible to plot the nMDS and interpret the results. Points that plot closer together are more similar, while points that are distant one to each other are more different. The nMDS plot can also be useful in recognising groups (points grouping together and plotting further from other points). An example is provided in <a href="#fig-nmds-rpubs">Figure&nbsp;<span>6.3</span></a>.</p>
<div id="fig-nmds-rpubs" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/NMDS_RPub.png" class="img-fluid figure-img" style="width:90.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;6.3: A nMDS plot with clusters, from <a href="https://rpubs.com/CPEL/NMDS">R Studio Pubs</a>.</figcaption>
</figure>
</div>
</section>
</section>
</section>
<section id="sec-case-study-richness-cereals-macroreg" class="level3" data-number="6.3.4">
<h3 data-number="6.3.4" class="anchored" data-anchor-id="sec-case-study-richness-cereals-macroreg"><span class="header-section-number">6.3.4</span> Case study: Cereal richness across the Italian subregions</h3>
<p>Both qualitative and quantitative methods were used to reconstruct the regional differences in cereal farming practices in Italy during the first millennium. In addition to the Bayesian approach, which is described later in this chapter and which is the core of this research, a frequentist approach was also used as a case study to test the validity of the conclusions drawn from the Bayesian models. Before carrying out these statistical analyses, it was necessary to carry out some pre-processing of the data. This involved:</p>
<ul>
<li><p>Selecting all the cereals columns from the <code>plant_remains</code> table, keeping the <code>Macroregion</code> column as a categorical variable.</p></li>
<li><p>Removing rows with no cereals (assemblages reporting only fruits, nuts and legumes but no cereals).</p></li>
<li><p>Selecting assemblages where the total of seeds was greater than 10. The total includes fruits, nuts and legumes in such a way that assemblages poor in grains but rich in other seeds were not of minor importance in the calculations, and were in essence considered reliable. This process resulted in a more limited number of assemblages available for analysis. The assemblage sizes after pre-processing can be viewed in <a href="archaeobotany.html#sec-richness-macroregions"><span>Section&nbsp;7.4.1.3</span></a>. Although the lower limit of the allowable assemblage size may appear small (which may affect species richness), some sites reported low numbers of seeds.</p></li>
<li><p>Transforming the raw counts into presence/absence, using the function <code>decostand()</code> (<code>method=pa</code>) in the <code>R</code> package <code>vegan</code> <span class="citation" data-cites="vegan">(<a href="references.html#ref-vegan" role="doc-biblioref">Oksanen et al., 2020</a>)</span>.</p></li>
</ul>
<p>Multivariate statistics are used in this research to test the hypothesis of a shift in Italian cereal farming practices and to visualise the separation between macroregions. Due to the small size of the data sets, the statistical methods used in this research are non-parametric or distribution-free, as the data do not follow a normal distribution. As non-parametric statistics make no assumptions about the distribution of the data, they are less powerful than parametric methods, but are flexible and particularly useful when dealing with small datasets <span class="citation" data-cites="kraska-millerNonparametricStatisticsSocial2014">(<a href="references.html#ref-kraska-millerNonparametricStatisticsSocial2014" role="doc-biblioref">Kraska-Miller, 2014</a>)</span>. Two main methods were used: PERMANOVA and nMDS, as described above. After preprocessing, PERMANOVA could be run using the <code>adonis2()</code> function in the <code>vegan</code> package. This function computes a distance matrix using the Jaccard distance and performs an analysis of variance on the matrix. The Jaccard distance is often used in presence/absence analyses because it is not based on Euclidean distances <span class="citation" data-cites="kosubNoteTriangleInequality2019">(<a href="references.html#ref-kosubNoteTriangleInequality2019" role="doc-biblioref">Kosub, 2019</a>)</span>. If the PERMANOVA reports a significant p-value for the selected response variable (in this case <code>Macroregion</code>), it is important to check that the assumptions of the test are met. One of these assumptions is that the variances are homogeneous. To this end, the <code>betadisper()</code> function (also in the <code>vegan</code> package) checks the homogeneity of the variances by calculating the multivariate analogue of Levene’s test for homogeneity of variances, which measures the distances of the group samples from the centroids. The most common test for whether the distances from the centroids are significantly different is to perform an ANOVA on the <code>betadisper()</code> object. If the ANOVA returns a p-value that is not significant (i.e.&nbsp;the p-value is greater than 0.05), it means that the variances of the distances from the centroids are similar between the groups and the assumption of homogeneity of variances is met for the PERMANOVA analysis.</p>
<p>PERMANOVA was used to test the hypothesis of a separation between northern and southern Italy in two chronological phases. However, this test does not indicate the extent of this separation. For this purpose, nMDS, a non-parametric technique for reducing the dimensionality of a dataset, is useful. Although it is commonly applied by reducing a dataset to two dimensions, following a procedure similar to <span class="citation" data-cites="cardarelliDeepVariationalConvolutional2022">Cardarelli (<a href="references.html#ref-cardarelliDeepVariationalConvolutional2022" role="doc-biblioref">2022</a>)</span>, the dataset will be reduced to one dimension so that the distance between two density curves can be calculated. nMDS can be computed using the <code>metaMDS()</code> function in <code>vegan</code>, which allows for several dissimilarity measures. The most appropriate measure for this dataset is again the Jaccard distance. In addition to reducing the dimensionality of the dataset, the aim was also to measure the degree of separation between regions using the Wasserstein distance, also known as the Earth Mover’s distance. This measure quantifies the distance between two probability distributions, taking into account the cost of moving mass from one distribution to the other. In order to avoid potentially biased estimates in the calculations, the macroregion of central Italy and the phases LR (late Roman) and Ma (11<sup>th</sup> century onwards) were excluded from the scaling due to the very uneven sample sizes. These phases are analysed separately using ubiquity only. The nMDS was run with the reduction set to one dimension only, and KDE plots were used to visualise the results. Reducing the dimension to one allows for easier distance calculations using the Wasserstein distance. Finally, the distance was calculated using the <code>wasserstein1d()</code> function in the <code>transport</code> library <span class="citation" data-cites="schuhmacherTransportComputationOptimal2022">(<a href="references.html#ref-schuhmacherTransportComputationOptimal2022" role="doc-biblioref">Schuhmacher et al., 2022</a>)</span>.</p>
</section>
</section>
<section id="sec-issues-zoo-quant" class="level2" style="text-align:justify;" data-number="6.4">
<h2 style="text-align:justify;" data-number="6.4" class="anchored" data-anchor-id="sec-issues-zoo-quant"><span class="header-section-number">6.4</span> Issues and approaches in the quantification of zooarchaeological data</h2>
<p>When compared to the archaeobotanical dataset, the collection of zooarchaeological assemblages allowed for a genuinely quantitative approach, albeit with some challenges. Similar to archaeobotany, most excavations lacked a sampling strategy and instead used feature-based sampling. However, biases are less prevalent in the zooarchaeological dataset. In fact, the bones of primary domesticates such as sheep, goats, cattle and pigs are readily identifiable during excavation, leading to less bias in their representation in the dataset. Nevertheless, small bones, notably those of fish and birds, pose a challenge as they are often underrepresented owing to difficulties in visual identification. Additionally, not all excavations utilised or declared the use of flotation, making it difficult to compare the abundance of these species. The zooarchaeological dataset presents a limited number of outliers. Although a few cases may be cited, these outliers do not have a significant impact on the analysis. This is partly attributable to the dataset’s much larger size compared to the archaeobotanical dataset. Additionally, the inclusion of these outliers may indicate real conditions at the archaeological sites, providing additional reinforcement. For example, let us examine the case of the faunal remains uncovered in Calvatone-<em>Bedriacum</em> from the 4<sup>th</sup>-5<sup>th</sup> century CE. The remains demonstrate a significant imbalance between the species present. While the total NISP count for pigs and <em>caprinae</em> amounts to 63, the amount of identified cattle specimens is 919 <span class="citation" data-cites="wilkensRestiFaunisticiDi1990">(<a href="references.html#ref-wilkensRestiFaunisticiDi1990" role="doc-biblioref">Wilkens, 1990</a>)</span>. The over-representation of cattle remains in this instance is most likely a result of economic specialisation, possibly due to the slaughter of animals in close proximity to the site.</p>
<p>Given that the dataset is generally less biased than the archaeobotanical one and contains fewer outliers, opting to work with counts rather than performing a presence/absence analysis for animals was possible. This choice was also driven by the fact that the major domesticates were consistently present at each site, making presence/absence analysis less informative. Such an analysis might be preferable for examining rare species, assuming that comparable assemblages are used and the process of flotation is consistently applied throughout each excavation. In this regard, the dataset concerning fauna provides more informative data. Unlike archaeobotany, it is feasible to inquire about topics like “Which variety of animal was most abundant on a Roman farm?” or “Is it more likely to find sheep and goats on a medieval mountain site?”</p>
<p>Despite the greater quantity of assemblages and reduced amount of outliers, the zooarchaeological dataset also presented some problems for quantitative analysis. Because NISP counts must be comparable, it is possible to convert the count data for each assemblages into proportions between 0 and 1. Nonetheless, when dividing the proportions into groups (e.g.&nbsp;by chronology, site type), it becomes clear that each animal’s distribution across sites is overly dispersed, with the curves for each animal being right-tailed (positively skewed). Simply put, the distribution is asymmetric and does not adhere to a normal curve, rendering the interpretation of common measures of central tendency (i.e.&nbsp;mean, median, mode) problematic. Although these measures provide informative insights for normally distributed data, they may mislead the interpretation of right-tailed distributions. In such situations, the mean usually tends to be skewed towards the long tail, resulting in an inaccurate representation of the typical proportion. Similarly, the median may not precisely express the middle value, particularly in circumstances where extreme values dominate the right tail of the distribution. These concerns are addressed through the use of Bayesian statistical modelling, which is introduced later in this chapter.</p>
</section>
<section id="building-a-statistical-model" class="level2" style="text-align:justify;" data-number="6.5">
<h2 style="text-align:justify;" data-number="6.5" class="anchored" data-anchor-id="building-a-statistical-model"><span class="header-section-number">6.5</span> Building a statistical model</h2>
<p>Whenever dealing with non-normal or skewed distributions, it may be wise to move away from measures of central tendency and model data instead. Creating a statistical model to trace past human activities is a challenging undertaking. Choosing the most suitable predictor (or set of predictors) and response variable to answer our question requires careful consideration of several factors. In archaeology, there is an additional complication because we often cannot select our data and have to work with what is available. The majority of our data is a proxy, or representation, of what we are genuinely interested in. For example, the number of identified specimens of pigs at a particular site is a proxy for how many pigs would actually have been at the site at a particular time. Building statistical models additionally requires taking into account causal inference, particularly when attempting to establish causal relationships between variables. In this study, the use of causal diagrams, also known as directed acyclic graphs (DAGs), is used to represent statistical models, showing how “when we draw an arrow from <span class="math inline">\(X\)</span> to <span class="math inline">\(Y\)</span>, we are implicitly saying some probability rule or function specifies how <span class="math inline">\(Y\)</span> would change if <span class="math inline">\(X\)</span> were to change” <span class="citation" data-cites="pearlBookWhyNew2019">(<a href="references.html#ref-pearlBookWhyNew2019" role="doc-biblioref">Pearl and Mackenzie, 2019, p. 45</a>)</span>. Understanding the causal pathways and potential confounding factors<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> is crucial for precise model formulation and result interpretation. Whenever we have additional predictors available, it is not always advisable to include them all in our mathematical model. Including many variables in a regression may yield “significant” results, but the scientific justification for the incorporation of certain variables may instead be flawed. Furthermore, caution must be exercised as the production of archaeological data involves various intricate processes and is frequently impacted by numerous biases, some of which have already been addressed in this research. Thus, statistical modelling is not only a computational activity but also a meticulous process that amalgamates data, theory, and domain knowledge to yield meaningful insights into intricate phenomena.</p>
<p><span class="citation" data-cites="levinsStrategyModelBuilding1966">Levins (<a href="references.html#ref-levinsStrategyModelBuilding1966" role="doc-biblioref">1966</a>)</span> proposed that a model has three interdependent properties: generality, precision, and reality. Generality denotes the capability of a model to describe a broad range of phenomena. Precision relates to the model’s accuracy in predicting the behaviour of a specific system. Realism, however, concerns the extent to which a model mirrors the actual processes at work in the system being investigated. However, there is a trade-off, as the author suggests that only two of these properties can be improved simultaneously. <a href="#fig-levins-model-classification">Figure&nbsp;<span>6.4</span></a> illustrates how various combinations of these properties produce empirical (precision and reality), analytical (generality and precision), and mechanistic (reality and generality) models. Nevertheless, <span class="citation" data-cites="guisanPredictiveHabitatDistribution2000">Guisan and Zimmermann (<a href="references.html#ref-guisanPredictiveHabitatDistribution2000" role="doc-biblioref">2000</a>)</span> noted that the distinctions between the three model types are frequently not as sharp and that it is possible to achieve a combination of the desired properties with some compromise.</p>
<div id="fig-levins-model-classification" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/Guisan_et_al_2000_p150_Levins_models.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;6.4: Illustration of Levins’ models classification. Image after Guisan and Zimmerman <span class="citation" data-cites="guisanPredictiveHabitatDistribution2000">(<a href="references.html#ref-guisanPredictiveHabitatDistribution2000" role="doc-biblioref">2000, p. 150</a>)</span>.</figcaption>
</figure>
</div>
<p>Among the statistical models most frequently used are Generalised Linear Models (GLMs). GLMs should be employed because of their ability to handle a wide range of response variables, including non-normal and categorical variables, and to allow modelling of other distributions. Furthermore, GLMs permit the modelling of non-constant variance functions, particularly valuable in addressing heteroscedasticity, a common issue in many datasets. Once the predictor (<span class="math inline">\(X\)</span>, the factor used to make the prediction) and the response variable (<span class="math inline">\(Y\)</span>, the factor being explained or predicted) are identified, the subsequent step is to analyse the relationship between the two by correctly formulating the statistical model. The statistical method used for modelling data must be appropriate to the type of data being analysed. When modelling counts of data, a probability density function (PDF) such as Poisson, negative-binomial, and others should be specified. For presence-absence data, various PDFs such as binomial, beta-binomial, and others are necessary <span class="citation" data-cites="guisanPredictiveHabitatDistribution2000 guisanHabitatSuitabilityDistribution2017">(<a href="references.html#ref-guisanHabitatSuitabilityDistribution2017" role="doc-biblioref">Guisan et al., 2017, pp. 55–56</a>; <a href="references.html#ref-guisanPredictiveHabitatDistribution2000" role="doc-biblioref">Guisan and Zimmermann, 2000, pp. 159–160</a>)</span>. Each of these distributions possesses distinctive properties and traits that are suitable for modelling certain kinds of data. For example, the Poisson distribution is commonly employed when operating with count data, such as the amount of events of a particular kind taking place within a fixed interval. It presupposes that events happen at a consistent rate and are mutually independent. On the other hand, the binomial distribution is appropriate for modelling binary data, in which outcomes are either success or failure, such as presence or absence.</p>
<p>Along with selecting the appropriate probability distribution, choosing a link function is also crucial in statistical modelling. The link function determines the relationship between the predictors and the expected value of the response variable. Commonly used link functions include the logit link for logistic regression (which constrains the outcome variable between 0 and 1), the log link for several types of regression (Gaussian, Poisson, Gamma, etc.), and the identity link for linear regression. Selecting a suitable link function depends on the data type and the specific research question being addressed.</p>
</section>
<section id="sec-bayesian-modeling" class="level2" style="text-align:justify;" data-number="6.6">
<h2 style="text-align:justify;" data-number="6.6" class="anchored" data-anchor-id="sec-bayesian-modeling"><span class="header-section-number">6.6</span> Modeling, the Bayesian way</h2>
<blockquote class="blockquote">
<p>“Bayesian data analysis takes a question in the form of a model and uses logic to produce an answer in the form of probability distributions” <span class="citation" data-cites="mcelreath2016">(<a href="references.html#ref-mcelreath2016" role="doc-biblioref">McElreath, 2016</a>)</span>.</p>
</blockquote>
<p>In the literature review section we already discussed the rationale behind Bayesian inference, introducing the concept of prior probabilities. The construction of a Bayesian statistical model initially resembles that of its frequentist counterpart, as we begin with a sampling model for observed data (<span class="math inline">\(B\)</span>) given a vector of unknown parameters (<span class="math inline">\(A\)</span>). However, a unique aspect of the Bayesian model is that the unknown parameters are not fixed, but instead are regarded as random. We create a probability distribution for A that summarises any relevant information. This distribution is known as the <em>prior</em> distribution. Prior distributions may have other random parameters which can be assigned other probability distributions, and these parameters are referred to as hyperparameters. Bayes’ Theorem is then used to derive the posterior distribution, which can be viewed as a compromise between our prior knowledge and the data we have gathered (<a href="#fig-bayesian-compromise">Figure&nbsp;<span>6.5</span></a>). In short, if we have <em>prior</em> knowledge or belief about an event, we can use Bayes’ rule to update our belief in light of new data:</p>
<p><span class="math display">\[
P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}
\]</span></p>
<p>The probability <span class="math inline">\(P (A|B)\)</span> of a hypothesis <span class="math inline">\(A\)</span> being true, given the observed evidence <span class="math inline">\(B\)</span>, is proportional to the likelihood of the evidence given the hypothesis <span class="math inline">\(P (B|A)\)</span>, multiplied by the prior probability of the hypothesis <span class="math inline">\(P (A)\)</span>. This is divided by the probability of the evidence <span class="math inline">\(P (B)\)</span> itself, which normalizes the result so that the probabilities sum to one. The resulting probability distribution is called the <em>posterior</em> probability distribution, which quantifies our updated belief in the hypothesis given the observed evidence. More than one hypothesis is plausible, and Bayesian probability theory allows to quantify uncertainty and compare different hypotheses (rather than comparing our hypothesis against a null hypothesis) based on their posterior probability distributions <span class="citation" data-cites="gelmanBayesianDataAnalysis2013a">(<a href="references.html#ref-gelmanBayesianDataAnalysis2013a" role="doc-biblioref">Gelman et al., 2013, pp. 6–8</a>)</span>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-bayesian-compromise" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="methods_files/figure-html/fig-bayesian-compromise-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;6.5: Bayesian updating: The posterior distribution is a compromise between our prior knowledge and the likelihood (observed data).</figcaption>
</figure>
</div>
</div>
</div>
<p>There is a catch, however, especially for complex models: the posterior distribution cannot be expressed in closed form and can only be explored by working with samples. These samples in turn can help us to estimate properties of the posterior (e.g.&nbsp;mean, variance, etc.). The challenge is that drawing samples directly from the posterior can be computationally infeasible, especially when dealing with high-dimensional parameter spaces or complex models. The mathematics behind this process is prohibitively difficult (if not sometimes impossible), which is one of the reasons why Bayesian statistics has only taken off in recent years, with increasingly powerful computers. Bayesians have devised several ways of sampling from a posterior distribution, although the method most commonly used in recent years is Markov chain Monte Carlo (MCMC). While it is not possible to give a detailed mathematical explanation of the method here, the logic behind it is relatively straightforward. Imagine walking into a room blindfolded and trying to avoid tripping over furniture. Most people would take small steps in each direction, but if they accidentally tripped over something, they would remember the location of the obstacle. By repeating this process many times, you eventually learn the layout of the room. In a Markov chain, you can take a very large number of steps from a given location, with the next step depending only on where you are. The chain will then be the path you have taken. The ‘Monte Carlo’ part of MCMC refers to the randomness of your path. MCMC allows you to get a general idea of the shape of a distribution, in this case the posterior distribution, to explore its properties <span class="citation" data-cites="carlinBayesianMethodsData2008 albertBayesianComputation2009 marinBayesianEssentials2014 robertIntroducingMonteCarlo2010 robertMonteCarloStatistical2004 hartigStatisticalInferenceStochastic2011 tierneyMarkovChainsExploring1994">(<a href="references.html#ref-albertBayesianComputation2009" role="doc-biblioref">Albert, 2009</a>; <a href="references.html#ref-carlinBayesianMethodsData2008" role="doc-biblioref">Carlin and Louis, 2008, pp. 120–140</a>; <a href="references.html#ref-hartigStatisticalInferenceStochastic2011" role="doc-biblioref">Hartig et al., 2011</a>; <a href="references.html#ref-marinBayesianEssentials2014" role="doc-biblioref">Marin and Robert, 2014</a>; <a href="references.html#ref-robertIntroducingMonteCarlo2010" role="doc-biblioref">Robert and Casella, 2010</a>, <a href="references.html#ref-robertMonteCarloStatistical2004" role="doc-biblioref">2004</a>; <a href="references.html#ref-tierneyMarkovChainsExploring1994" role="doc-biblioref">Tierney, 1994</a>)</span>.</p>
<p>Now that we have covered the basics of Bayesian inference, let us take a closer look at building a model. As we have seen, once we have collected data and built a DAG, it is necessary to think about any prior beliefs we may have about the phenomenon we are trying to predict. Particularly in archaeology, we may not have a history of previous surveys or strong beliefs about our data. If we cannot feel confident about our prior knowledge, does this mean that we cannot do Bayesian inference? Or should we switch to frequentist statistics if we do not fully accept the subjectivity of the Bayesian approach, but still value its logic? It turns out that certain priors have a weaker influence on the posterior distribution than others. These priors are referred to in various ways: flat, weakly informative, uninformative, diffuse, among others. For the purposes of this study, we label them as ‘weakly informative priors’ as virtually any prior has some impact, albeit minimal, on the posterior distribution. A weakly informative prior does not favour any particular interval of a distribution, and the observed data have a much greater weight on the posterior distribution than the prior. A canonical example of a weakly informative prior in the context of a binomial distribution (constrained between 0 and 1) is the uniform distribution (<a href="#fig-uniform-prior-example">Figure&nbsp;<span>6.6</span></a>). If there is no prior belief regarding the likelihood of an event occurring, using the uniform distribution implicitly says that we believe that the mean occurrence could be anywhere between 0 and 1. It is worth noting that even stronger priors have a minimal effect on the posterior distribution when the sample size is large enough (see <a href="#fig-bayesian-updating-example">Figure&nbsp;<span>6.7</span></a>) <span class="citation" data-cites="johnsonBayesRulesIntroduction2022 albertProbabilityBayesianModeling2020 mcelreath2016 bannerUseBayesianPriors2020">(<a href="references.html#ref-albertProbabilityBayesianModeling2020" role="doc-biblioref">Albert and Hu, 2020, p. 344</a>; <a href="references.html#ref-bannerUseBayesianPriors2020" role="doc-biblioref">Banner et al., 2020</a>; <a href="references.html#ref-johnsonBayesRulesIntroduction2022" role="doc-biblioref">Johnson et al., 2022, p. 234</a>; <a href="references.html#ref-mcelreath2016" role="doc-biblioref">McElreath, 2016, p. 127</a>)</span>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-uniform-prior-example" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="methods_files/figure-html/fig-uniform-prior-example-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;6.6: When a uniform distribution is applied as a prior belief, the resulting posterior distribution is influenced more by the likelihood than the prior. This example is for illustrative purposes only and is not based on actual data.</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-bayesian-updating-example" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="methods_files/figure-html/fig-bayesian-updating-example-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;6.7: An illustration demonstrating how two distinct prior beliefs (dashed lines) converge towards the same true probability <span class="math inline">\(p\)</span> with an adequate number of samples (<span class="math inline">\(N\)</span> = 100). The initial prior follows a beta distribution with <span class="math inline">\(\alpha\)</span> = 2 and <span class="math inline">\(\beta\)</span> = 10, whereas the subsequent prior is defined by <span class="math inline">\(\alpha\)</span> = 8 and <span class="math inline">\(\beta\)</span> = 3. As the sample size increases, the two distributions converge even more closely.</figcaption>
</figure>
</div>
</div>
</div>
<p>This study has exclusively sought to use weakly informative priors in its models for several reasons. Firstly, the sample size of some of the sample groups under examination (e.g., archaeobotanical remains from Roman central Italy) is insufficient for informative priors to be used. When observations are scarce, informative priors pose the risk of outweighing the posterior. On the contrary, a prior that is weakly informative will result in a posterior distribution that more closely resembles the actual data, even with only one observation. Secondly, as the study aims to encompass sites from diverse contexts, which may include varying site types and geographical features, and in light of the dearth of previous statistical studies on the subject, excluding localised studies discussed in the literature review, the adoption of weakly informative priors is deemed more suitable. It is worth noting that although the terms are often used interchangeably, there is a distinction between flat priors (i.e.&nbsp;the uniform distribution) and weakly informative priors <span class="citation" data-cites="mcelreath2016">(<a href="references.html#ref-mcelreath2016" role="doc-biblioref">McElreath, 2016, p. 36</a>)</span>. The priors used in the models in this research have been carefully constructed so that they do not contain any bias towards any particular interval in the distribution of the data, but at the same time are sceptical of extreme values. We will explore the practical implications of these types of priors when constructing a Bayesian model. For now, let us examine an example. Let us suppose we are developing a model that anticipates the occurrence of cattle in Roman Italy. Cattle were a frequently occurring farm animal during the Roman era, serving as both a source of food and as labour. This information is derived from various literary sources and spans a wide timeframe. Most zooarchaeological studies also confirm widespread presence of this animal in Italy. Although it is possible to find extreme cases, it may be more plausible to assume that, in an archaeological dig, a portion of identified specimens will include cattle, rather than no cattle or only cattle.</p>
<p>For this study, we opted for a Bayesian approach as it provides us with a good degree of flexibility and the ease of interpretation. In the Bayesian set of tools there is another valuable resource that goes by multiple names in scholarly literature, namely multilevel models, hierarchical, mixed-effects models, and random-effect models <span class="citation" data-cites="johnsonBayesRulesIntroduction2022 kruschkeDoingBayesianData2015 albertProbabilityBayesianModeling2020">(<a href="references.html#ref-albertProbabilityBayesianModeling2020" role="doc-biblioref">Albert and Hu, 2020, p. 438</a>; <a href="references.html#ref-johnsonBayesRulesIntroduction2022" role="doc-biblioref">Johnson et al., 2022, p. 375</a>; <a href="references.html#ref-kruschkeDoingBayesianData2015" role="doc-biblioref">Kruschke, 2015, p. 557</a>)</span>. Among these definitions, Richard McElreath’s term of “models with memory” is particularly compelling <span class="citation" data-cites="mcelreath2016">(<a href="references.html#ref-mcelreath2016" role="doc-biblioref">McElreath, 2016, pp. 399–400</a>)</span>. However, for clarity purposes we will refer to these as “multilevel models” to avoid any confusion. Before jumping into the multilevel territory, it is necessary to introduce the concept of “pooling” data <span class="citation" data-cites="johnsonBayesRulesIntroduction2022">(<a href="references.html#ref-johnsonBayesRulesIntroduction2022" role="doc-biblioref">Johnson et al., 2022, pp. 377–375</a>)</span>. The term simply refers to the grouping of data from various observations, datasets, experiments, and the like. However, the manner in which we pool data can significantly impact the range of questions we can pose to our dataset, and ultimately influence the interpretation of results.</p>
<p>Consider a data set of <span class="math inline">\(N\)</span> independent samples containing NISP data from cattle that were found in a particular area and that date back to a particular period of time in centuries. If we disregard any attributes that these samples may carry (such as their origin from a rural or urban context, chronology, location, etc.) and pool all the observations together, we are using a “complete pooling” technique. Any outcome of our modelling will depend on the entire dataset, which restricts the range of questions that can be asked but may also lead to misinterpretation. If we study the correlation between a certain altitude and a particular animal and attempt to anticipate the presence of this type of animal at a particular elevation, our inference may be distorted if this correlation varies amongst different time periods. On the other hand, the use of a “no pooling” technique considers each group as independent. This is especially informative for evaluating variability within a group. For example, it allows us to determine how much elevation affects the presence of the animal being examined during specific time periods. However, not pooling the data has a downside: it prevents generalisation. This limitation is particularly significant when dealing with smaller groups, as the utilised method presupposes non-sharing of critical information amongst groups. “Partial pooling” may be the solution to these problems. Bayesian multilevel models possess “memory” as they exchange information among groups. By comprehensively studying each data cluster, the estimates for every cluster are in turn refined and improved. According to McElreath <span class="citation" data-cites="mcelreath2016">(<a href="references.html#ref-mcelreath2016" role="doc-biblioref">2016, p. 400</a>)</span>, multilevel modelling has four primary advantages:</p>
<ol type="1">
<li>The availability of new samples improves the estimates.</li>
<li>Estimates are improved whenever the group sizes are imbalanced. This prevents groups with more samples available to dominate over smaller groups.</li>
<li>Variation is explicitly modelled. Multilevel models provide both within-group and between-group variability. Within-group variability tells us how consistent the observations are within a single group. On the other hand, between-group variability provides information on how much observations differ from group to group.</li>
<li>It does not require data transformation (i.e.&nbsp;averaging) and preserves the uncertainty in the dataset.</li>
</ol>
<p>The rationale for partial pooling and sharing information between groups is straightforward. Our knowledge about a group is not null even when it only comprises a few samples. Imagine entering an unfamiliar café and ordering a coffee. Although the price is unknown, we make an assumption based on previous coffee shop experiences, the cost of living in the city, the appearance of the café, etc. Similarly, it is logical for the model to anticipate specific estimations on the basis of all other groups. However, this does not imply that the model is generating estimates with a high degree of confidence: if the prior we have previously set is weak enough, with a small set of data the expected values will fall within a sufficiently large range, also intuitively known as the “credible interval”.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Salakpi_et_al_2022_elaboration.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Example of various pooling techniques when evaluating the impact of site elevation on the total NISP of a certain species. Initially, every observation is considered independently. In the complete pooling illustration, the overall altitude effect on the total NISP can be seen. Lastly, the effect of site elevation on NISP is stratified by chronology, preserving the variability within each group. Elaboration after <span class="citation" data-cites="salakpiDynamicHierarchicalBayesian2022">Salakpi et al. (<a href="references.html#ref-salakpiDynamicHierarchicalBayesian2022" role="doc-biblioref">2022</a>)</span>.</figcaption>
</figure>
</div>
<section id="sec-building-bayesian-models" class="level3" data-number="6.6.1">
<h3 data-number="6.6.1" class="anchored" data-anchor-id="sec-building-bayesian-models"><span class="header-section-number">6.6.1</span> Building Bayesian models</h3>
<p>With an understanding of the core principles of Bayesian modelling, let us now explore the process of model building in greater detail while focusing on the dataset employed in this research. Different models have been utilised to analyse archaeobotanical and zooarchaeological data, due to the constraints of the former. After detailing the approaches and distributions utilised in each dataset, this section will also provide guidance on how the models were built, from drawing the causal diagrams to the diagnostics required to check that our models worked.</p>
<section id="archaeobotany" class="level4" data-number="6.6.1.1">
<h4 data-number="6.6.1.1" class="anchored" data-anchor-id="archaeobotany"><span class="header-section-number">6.6.1.1</span> Archaeobotany</h4>
<p>Archaeobotanical data has been exclusively used for presence/absence analysis instead of pure quantitative analysis due to previously explained inherent dataset issues. The most frequently used distribution for modelling presence/absence data is the binomial distribution <span class="citation" data-cites="wypijBinomialDistribution2014 garcia-garciaBinomialDistributionHistorical2022">(<a href="references.html#ref-garcia-garciaBinomialDistributionHistorical2022" role="doc-biblioref">García-García et al., 2022</a>; <a href="references.html#ref-wypijBinomialDistribution2014" role="doc-biblioref">Wypij, 2014</a>)</span>, which includes two parameters: N, the number of trials, and p, the probability of success:</p>
<p><span class="math display">\[
Y∼Binomial(N,p)
\]</span></p>
<p>In its simplest form, a distribution for a single success/failure experiment (N=1) is referred to as a Bernoulli trial <span class="citation" data-cites="gelmanBayesianDataAnalysis2013a">(<a href="references.html#ref-gelmanBayesianDataAnalysis2013a" role="doc-biblioref">Gelman et al., 2013, p. 39</a>)</span>. One of the most common ways to illustrate the binomial distribution is by tossing a coin. Suppose you want to find the probability of getting exactly 3 heads if you flip a fair coin 5 times. In this scenario, <span class="math inline">\(N\)</span> is 5, representing the number of coin flips, and p is 0.5 since each coin flip has an equal likelihood of landing on either heads or tails. Using the binomial distribution formula, you can calculate the probability in the following way:</p>
<p><span class="math display">\[P(X = 3) = C(5, 3) \cdot (0.5)^3 \cdot (1 - 0.5)^{(5 - 3)} = 0.31\]</span></p>
<p>Where:</p>
<ul>
<li><p><span class="math inline">\(C(5, 3)\)</span> is the binomial coefficient, which is 10 (because there are 10 ways to get 3 heads in 5 coin flips).</p></li>
<li><p><span class="math inline">\((0.5)^3\)</span> is the probability of getting 3 heads.</p></li>
<li><p>The probability of obtaining 2 tails when flipping a coin 5 times is <span class="math inline">\((1 - 0.5)^{(5 - 3)}\)</span> since the complementary event to obtaining a head is obtaining a tail.</p></li>
<li><p>The probability of getting exactly 3 heads on 5 tosses of a fair coin is 0.31, or 31%.</p></li>
</ul>
<p>In Bayesian data analysis, it is essential to present models using mathematical notation. Typically, statisticians list variables and define each one as a function of other variables, whether deterministic or distributional. For instance, consider a Bayesian binomial model constructed to evaluate the extent of “minor” (or more rustic) grains adoption in our dataset’s entire sample. Examining the presence of every cereal grain type is an essential research question. However, one of the aims of this research is to understand the extent to which polyculture was adopted by farmers and other grains besides naked wheats and barley were grown and consumed. Therefore, to achieve this objective, the number of trials, <span class="math inline">\(N\)</span>, is limited to seven, which is the maximum number of cereal types stored in the database. Whilst the measurement of cereal richness at a site can be biased by sample size and the use of techniques such as flotation, it remains a valuable proxy for polyculture.</p>
<p><span class="math display">\[
Y_{i} \sim Binomial(N=7, \bar{p}_{i} )
\]</span></p>
<p><span class="math display">\[
\bar{p}_{i} \sim Normal(0,1.5)
\]</span></p>
<p>In this model, new parameters are specified in the following line, adhering to the traditional approach of formulating Bayesian statistics. The first line presents the expression Y on the left side, signifying the observed value, and the likelihood function on the right side specifying the probability of the observed data <span class="math inline">\(Y\)</span>. If a sample contains three different cereal grain types, for instance, the corresponding formula is <span class="math inline">\(3 \sim Binomial(7, p)\)</span>. Here, the number of cereal types adopted in the specific sample is denoted by “3”, while <span class="math inline">\(p\)</span> represents the probability of each respective minor cereal type being adopted. The Binomial distribution is used to calculate the probability of observing this specific adoption count, given the parameter <span class="math inline">\(p\)</span>. To complete the model, a prior distribution for <span class="math inline">\(p\)</span> is assigned to represent our initial understanding of the probability of adopting any “rustic” cereal before any data is observed. Modelling <span class="math inline">\(p\)</span> captures the generative aspect of Bayesian statistics. Bayesian modelling is not solely concerned with describing observed data but also with understanding the underlying process that generates it. To exemplify, the uniform distribution ranging from 0 to 1 is used here to model <span class="math inline">\(p\)</span>, but in this study we mostly use other weakly informative priors. Employing Bayes’ theorem enables us to combine the prior and the likelihood to compute the posterior distribution of <span class="math inline">\(p\)</span> based on the observed data. The resulting posterior distribution reflects our updated beliefs about <span class="math inline">\(p\)</span> after taking into account the observed patterns of adoption.</p>
<p>In the example given, a “complete pooling” strategy is employed, although as noted earlier, this is only rarely a good idea. In practice, it is important to consider other variables, or predictors, that may affect the occurrence of multiple cereal types. We can construct a causal diagram to display the potential predictors, namely the type of site where the sample was discovered and the chronology of the sample. To adjust for both predictors in the regression at the same time, we implement a trick of developing an interaction index. The index has been constructed to ensure that every site type interacts with every chronology. For example, the interaction between Rural and Roman will be indexed as 1, while the interaction between Rural and Late Roman will be indexed as 2, and so forth. There are several contexts that have been recorded in the database (see <a href="database.html#tbl-site-type-db">Table&nbsp;<span>5.1</span></a> for a full list), but the model required some simplifications in order to avoid extremely small categories. For instance, religious monasteries have been grouped with other <code>Religious</code> sites, or Roman <em>mansiones</em> have been classified as <code>Rural</code> for these models. Categorical simplifications can obscure the nuances of data, but tiny sample sizes produce very uninformative posterior distributions. In essence, we are transitioning to a “partial pooling” approach, where the models incorporate additional levels and provide an intercept for each interaction index (which is why they are also referred to as “varying intercepts” models). We can modify the formula to incorporate a varying intercept:</p>
<p><span class="math display">\[
Y_{i} \sim Binomial(N=7, \bar{p}_{i} )
\]</span></p>
<p><span class="math display">\[
logit(\bar{p}_{i}) = \alpha_{[TCid]}
\]</span></p>
<p><span class="math display">\[
\alpha_{[TCid]} \sim Normal(0,1.5)
\]</span></p>
<p>We define the varying intercept as <span class="math inline">\(\alpha\)</span> and note that <span class="math inline">\([TCid]\)</span> represents the numerical interaction index. We then assign a weak prior to the intercept <span class="math inline">\(\alpha\)</span>, using a normal distribution with a mean of 0 and a standard deviation of 1.5. In <a href="#fig-met-prior-pred-sim-binom">Figure&nbsp;<span>6.8</span></a> you can see how the prior is weakly informative as it assigns similar probabilities from 0 to 7. Note that the probabilities are randomly assigned as they are generated in the normal distribution. With such a diffuse prior, even one observation will change the posterior density to better reflect the shape of the data:</p>
<blockquote class="blockquote">
<p>[… ] with a weakly informed prior that spreads credibility over a wide range of parameter values, it takes relatively little data to shift the peak of the posterior distribution toward the data (although the posterior will be relatively wide and uncertain) <span class="citation" data-cites="kruschkeDoingBayesianData2015">(<a href="references.html#ref-kruschkeDoingBayesianData2015" role="doc-biblioref">Kruschke, 2015, p. 114</a>)</span>.</p>
</blockquote>
<div class="cell">
<div class="cell-output-display">
<div id="fig-met-prior-pred-sim-binom" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="methods_files/figure-html/fig-met-prior-pred-sim-binom-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;6.8: In this prior predictive simulation, it is evident that a weakly informative prior does not result in any fabricated trends. The x-axis displays counts ranging from 0 to 7, representing the highest number of ‘minor’ grains specified in the binomial model. It is advisable to simulate the potential impact of a chosen prior on a hypothetical posterior distribution.</figcaption>
</figure>
</div>
</div>
</div>
<p>Comparing the complete pooling model to the one with the varying intercept, we observe a difference. In order to include more levels, we are practically constructing a Bayesian GLM, necessitating a logit link function. The logit link is the most common when working with binomial GLMs, mapping a parameter that is defined as a probability mass and effectively constraining it between 0 and 1. When employing the logit link function, it is crucial to note that the intercept estimates obtained from the posterior distribution represent log-odds, which are on a transformed scale <span class="citation" data-cites="mcelreath2016">(<a href="references.html#ref-mcelreath2016" role="doc-biblioref">McElreath, 2016, pp. 315–7</a>)</span>. To interpret these estimates in terms of probabilities, they must be transformed back to the original probability scale using the inverse logit transformation.</p>
<p>After building the model, we can sample from the posterior distribution and obtain useful information such as group means, within and between group variability, and credible intervals<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. A posterior credible interval (CI) quantifies the uncertainty in an estimated parameter obtained from Bayesian inference. Unlike frequentist confidence intervals, which rely on the concept of repeated sampling, Bayesian credible intervals offer a direct statement about the plausible range of the parameter given the observed data and the prior distribution chosen. CIs are selected to encompass specific high-density regions of the posterior distribution, which is why they are also called highest density intervals (HDIs). Common options for credible intervals may include the 95% and 90% credible intervals. However, this study presents several CIs to improve the clarity: 99%, 95%, 80%, and 50%. The objective is to capture the most plausible values of the posterior, excluding the extremes or unlikely scenarios <span class="citation" data-cites="johnsonBayesRulesIntroduction2022">(<a href="references.html#ref-johnsonBayesRulesIntroduction2022" role="doc-biblioref">Johnson et al., 2022, pp. pp-185-186</a>)</span>. By representing the likelihood of a parameter falling within a specific range, CIs are more intuitive than confidence intervals<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>.</p>
</section>
<section id="zooarchaeology" class="level4" data-number="6.6.1.2">
<h4 data-number="6.6.1.2" class="anchored" data-anchor-id="zooarchaeology"><span class="header-section-number">6.6.1.2</span> Zooarchaeology</h4>
<p>The zooarchaeological dataset permitted a more quantitative approach compared to the archaeobotanical dataset, as previously described in <a href="#sec-issues-zoo-quant"><span>Section&nbsp;6.4</span></a>. Instead of modelling the occurrence of specific species, it was feasible to directly model counts to evaluate quantitative distinctions between species based on selected stratifying factors, such as chronology, type of context, macroregion, and others. Counts are frequently modelled with a Poisson distribution <span class="citation" data-cites="hilbeModelingCountData2014">(<a href="references.html#ref-hilbeModelingCountData2014" role="doc-biblioref">Hilbe, 2014, pp. 35–73</a>)</span>, which has been used, for example, to model species diversity and richness in the archaeobotanical dataset. However, while it is feasible to use Poisson regression to model comparable counts, it is not advisable to do so when comparing NISP data. The amount of NISP data collected in each sample can vary depending on various factors, including excavation size, number of samples, and richness of the stratigraphic layer. When exploring a single excavation, researchers may ask specific questions such as: “Which area or chronology provided the most bone fragments?”. However, our focus is on understanding the relative occurrence of specific species, which requires investigating different questions: “What is the probability of finding pig remains in a sample from the Roman period?”. This can only be determined through modelling comparable counts. Fortunately, the binomial distribution can be used to simulate relative proportions among species in a different strategy.</p>
<p>Assuming that <span class="math inline">\(Y\)</span> represents the NISP count for a specific species such as pigs and <span class="math inline">\(N\)</span> (i.e.&nbsp;the number of trials) represents the total NISP from a sample, we can utilise the <span class="math inline">\(Y \sim Binomial(N, p)\)</span> formula. This approach provides each probability for each sample within the range of 0 and 1 as each sample will be capped at its own total NISP count. We will not elaborate on the construction of a Bayesian binomial regression again, as it has been previously explained, and we can improve on this. In <a href="#sec-issues-zoo-quant"><span>Section&nbsp;6.4</span></a>, we explored overdispersion as a major challenge in quantifying zooarchaeological data. This issue arises because several factors can contribute to a particular species dominating in a sample, and the proportions between species and samples are never precise. One immediate approach to address this issue would be to implement ranking (e.g.&nbsp;Assemblage #1, Pigs = 1, Sheep/Goats = 2, Cattle = 3), although at the expense of losing some of the finer details. It is worth noting that whether an assemblage comprises of 300 pig bones, 20 sheep or goats bones, or 10 cattle bones, the rankings would remain the same at 300, 290 and 280 bones respectively.</p>
<p>There is an alternative method that considers overdispersion while still allowing us to model our counts with a binomial distribution. To introduce this, we need to take a step back and talk about conjugate priors. As defined by <span class="citation" data-cites="johnsonBayesRulesIntroduction2022">Johnson et al. (<a href="references.html#ref-johnsonBayesRulesIntroduction2022" role="doc-biblioref">2022, p. 62</a>)</span>:</p>
<blockquote class="blockquote">
<p>“We say that <span class="math inline">\(f (π)\)</span> is a conjugate prior for <span class="math inline">\(L(π∣y)\)</span> if the posterior, <span class="math inline">\(f (π∣y) ∝ f (π)L(π∣y)\)</span>, is from the same model family as the prior”.</p>
</blockquote>
<p>Conjugate priors for the likelihood are an algebraic convenience, as they facilitate otherwise difficult (or impossible) computations. By creating a closed-form expression for the posterior distribution within the same family as the prior, it becomes more straightforward to observe the impact of the likelihood in revising our prior evidence. One of the most frequently utilised continuous probability distributions that are conjugate to the binomial distribution is the Beta distribution. It is defined on the <span class="math inline">\([0,1]\)</span> interval and characterised by two positive parameters, <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, which can be adjusted to express strong, weak, or neutral prior beliefs. The distribution’s shape may vary as we modify its parameters:</p>
<ul>
<li><p>With <span class="math inline">\(\alpha = \beta = 1\)</span>, the Beta pdf is uniform.</p></li>
<li><p>With <span class="math inline">\(\alpha &lt; \beta\)</span>, the Beta pdf is right-skewed.</p></li>
<li><p>With <span class="math inline">\(\alpha &gt; \beta\)</span>, the Beta pdf is left-skewed.</p></li>
<li><p>With <span class="math inline">\(\alpha = \beta\)</span>, the Beta pdf is symmetric with mean and mode equal to 0.5.</p></li>
</ul>
<p>The <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> values also provide information on the variability of the probability density function. As these values increase, the pdf becomes narrower, more concentrated around the mean, and less dispersed. It is clear that these qualities are desirable as they provide significant flexibility when selecting a prior belief. How can we benefit from these properties? The solution is to use a beta-binomial model, a mixture model in which each binomial count observation has its unique probability of success, allowing a distribution of probabilities of success to be estimated rather than a singular probability <span class="citation" data-cites="mcelreath2016 leeBayesianEstimationPrediction1987 leeNoteBayesianEstimation1999 kimValidationBetaBinomialModel2017">(<a href="references.html#ref-kimValidationBetaBinomialModel2017" role="doc-biblioref">Kim and Lee, 2017</a>; <a href="references.html#ref-leeBayesianEstimationPrediction1987" role="doc-biblioref">Lee and Sabavala, 1987</a>; <a href="references.html#ref-leeNoteBayesianEstimation1999" role="doc-biblioref">Lee and Lio, 1999</a>; <a href="references.html#ref-mcelreath2016" role="doc-biblioref">McElreath, 2016, pp. 370–371</a>)</span>. Instead of utilising the conventional formulation of the beta-binomial distribution, the reparameterization provided in McElreath was adopted for this study. In this reparameterization, Beta takes on two parameters: a mean probability of <span class="math inline">\(p\)</span> and a scale or precision parameter of <span class="math inline">\(\phi\)</span><a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. The value of <span class="math inline">\(\phi\)</span> can be determined based on the relationship between <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, which is such that: <span class="math display">\[\alpha = p \cdot \phi; \beta = (1-p) \cdot \phi\]</span> Additionally, the Beta-Binomial model, in which <span class="math inline">\(p\)</span> is assumed to follow a Beta distribution:</p>
<p><span class="math display">\[
Y \sim Binomial(N,p)
\]</span></p>
<p><span class="math display">\[
p \sim Beta(\alpha, \beta)
\]</span></p>
<p>Can be reparametrised as:</p>
<p><span class="math display">\[
Y \sim Betabinomial(N, p, \phi)
\]</span></p>
<p>This formulation (which already includes the Beta distribution) is simpler for modelling and interpreting the results since the exploration of a single parameter <span class="math inline">\(\phi\)</span> provides a clearer understanding of the variability in the posterior distribution. Specifically:</p>
<ul>
<li><p>When <span class="math inline">\(\phi &lt; 2\)</span>, the distribution is greatly overdispersed, leading to a possible concentration of probabilities around 0 and 1.</p></li>
<li><p>When <span class="math inline">\(\phi = 2\)</span>, the distribution is uniform (flat).</p></li>
<li><p>When <span class="math inline">\(\phi &gt; 2\)</span>, the distribution becomes increasingly narrow and the probabilities are more concentrated.</p></li>
</ul>
<p>With these concepts in mind, we can begin constructing a beta-binomial model to evaluate its practicality. Let us examine a case in this study. Extending the binomial model previously used to calculate pig occurrence, we shift our focus back to the multilevel realm. As a recap, a multilevel model allows us to model counts while retaining information about variation between and within groups, and about group sizes (through credible intervals). Furthermore, multilevel models improve estimate accuracy for small groups by gathering information from other groups through partial pooling. Having constructed a DAG, we are interested in knowing the predicted occurrence of pig remains on different site types, stratified by chronology. Just as in the previous binomial archaeobotanical example, we introduce a trick to map the interaction between each of the site types and each of the chronologies: an interaction index. We define the variable intercept as <span class="math inline">\(\alpha\)</span> and clarify that <span class="math inline">\([TCid]\)</span> signifies the numerical interaction index. Consistent with our earlier example, we also assign <span class="math inline">\(\alpha\)</span> a weakly informative prior of <span class="math inline">\(Normal(0,1.5)\)</span>. To establish a prior for the shape parameter <span class="math inline">\(\phi\)</span> assuming that any <span class="math inline">\(\phi\)</span> value below 2 would result in excessive dispersion, we aim to establish a flat beta distribution as a baseline <span class="citation" data-cites="kermanNeutralNoninformativeInformative2011">(<a href="references.html#ref-kermanNeutralNoninformativeInformative2011" role="doc-biblioref">Kerman, 2011</a>)</span>. In order to proceed, a prior distribution with a minimum of 2 is required. McElreath <span class="citation" data-cites="mcelreath2016">(<a href="references.html#ref-mcelreath2016" role="doc-biblioref">2016, p. 371</a>)</span> recommends the use of an exponential distribution, which has a minimum of 0. Therefore, two is added to the <span class="math inline">\(Exp(1)\)</span> generative model (compare <a href="#fig-beta-zoo-prior-sim-methods">Figure&nbsp;<span>6.9</span></a> and <a href="#fig-betabin-zoo-prior-sim-methods">Figure&nbsp;<span>6.10</span></a>). The interaction index <span class="math inline">\({[TCid]}\)</span> is also added to the prior <span class="math inline">\(\phi\)</span> in order to get varying estimates for each site type and chronology.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-beta-zoo-prior-sim-methods" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="methods_files/figure-html/fig-beta-zoo-prior-sim-methods-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;6.9: Example of a beta distribution using a precision parameter generated randomly from an exponential distribution with a rate of 1 and then adding a constant of 2. This type of prior is considered weakly informative.</figcaption>
</figure>
</div>
</div>
</div>
<div id="fig-betabin-zoo-prior-sim-methods" class="cell quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-betabin-zoo-prior-sim-methods-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="methods_files/figure-html/fig-betabin-zoo-prior-sim-methods-1.png" class="img-fluid figure-img" data-ref-parent="fig-betabin-zoo-prior-sim-methods" width="672"></p>
<figcaption class="figure-caption">(a) Φ + 2; The simulation shows how when no data is available values on the limits are likely. New observations however rapidly affect the posterior distribution.</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-betabin-zoo-prior-sim-methods-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="methods_files/figure-html/fig-betabin-zoo-prior-sim-methods-2.png" class="img-fluid figure-img" data-ref-parent="fig-betabin-zoo-prior-sim-methods" width="672"></p>
<figcaption class="figure-caption">(b) Φ; The simulation shows how when no data is available the probabilities pile up on the extremes.</figcaption>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;6.10: Prior predictive simulation for the betabinomial distribution with and without the addition of the constant 2.</figcaption><p></p>
</figure>
</div>
<p>After constructing the hierarchical model and sampling from the posterior distribution, we obtain valuable information about two key parameters for each group (e.g., Roman: Rural, Roman: Urban, etc.). These parameters are the varying intercept <span class="math inline">\(\alpha\)</span> and the precision parameter <span class="math inline">\(\phi\)</span>. Analysing the distribution of <span class="math inline">\(\phi\)</span> within each chronology and site type enables us to assess the model’s performance and accuracy. The distribution of <span class="math inline">\(\alpha\)</span> offers insights into the central tendency of probabilities of occurrence, helping us identify where these probabilities are most concentrated. Additionally, it provides us with credible intervals that can vary in width based on the available data and the degree of variability within each group. A wider credible interval for <span class="math inline">\(\alpha\)</span> suggests more uncertainty about where the group’s probability is centred. On the other hand, the parameter <span class="math inline">\(\phi\)</span> is complementary as it informs us about the dispersion or variability within each group. A flat and wide distribution of <span class="math inline">\(\phi\)</span> values suggests higher uncertainty or variability in estimating the precision parameter across different groups. This variability can arise due to factors such as limited data, inherent heterogeneity, or weak prior information. Conversely, a narrow distribution of <span class="math inline">\(\phi\)</span> values indicates lower uncertainty or variability in estimating the precision parameter across different groups. This suggests that the groups are more consistent in terms of their data dispersion, and the precision parameter is estimated with greater confidence. As we anticipated, low <span class="math inline">\(\phi\)</span> values suggest that the data within a group are highly dispersed or variable, with observations deviating significantly from each other. High <span class="math inline">\(\phi\)</span> values (far from zero) imply that the data within a group are less dispersed or variable, with observations clustering closely together (<a href="#fig-phi-values-example">Figure&nbsp;<span>6.11</span></a>). To clarify, while both credible intervals and <span class="math inline">\(\phi\)</span> values provide insights into dispersion, credible intervals focus on the central tendency of probabilities, while <span class="math inline">\(\phi\)</span> measures the dispersion of the data points themselves within a group. They offer complementary information to understand how groups behave and how variable their probabilities are.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-phi-values-example" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="methods_files/figure-html/fig-phi-values-example-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;6.11: The plots illustrate the behaviour of Φ across various probability levels for different values.</figcaption>
</figure>
</div>
</div>
</div>
<p>The beta-binomial multilevel model presented in this section has enabled us to offer reliable estimates for the abundance of a selected species in each site type and chronology. This example has laid the foundations for understanding the logic behind Bayesian model building, although the results section will provide estimates using multiple other predictors. These models address over-dispersion through several methods. Firstly, they introduce an observation-level varying effect <span class="citation" data-cites="harrisonComparisonObservationlevelRandom2015">(<a href="references.html#ref-harrisonComparisonObservationlevelRandom2015" role="doc-biblioref">Harrison, 2015</a>)</span> while also permitting each combination of predictors to have an unobserved intercept <span class="citation" data-cites="mcelreath2016">(<a href="references.html#ref-mcelreath2016" role="doc-biblioref">McElreath, 2016, p. 372</a>)</span>. We can then obtain estimates of these intercepts via posterior predictive. Nonetheless, it would be prudent to verify that our model has operated accurately before doing so. The following section will explore the necessary diagnostics that must be conducted to ascertain the model’s ability to generate precise estimates. It will also explain the methodology for interpreting posterior predictive simulations and comparing various models to determine the most fitting one.</p>
</section>
</section>
<section id="sec-sampling-posterior-diagnostics" class="level3" data-number="6.6.2">
<h3 data-number="6.6.2" class="anchored" data-anchor-id="sec-sampling-posterior-diagnostics"><span class="header-section-number">6.6.2</span> Sampling from the posterior and model diagnostics</h3>
<p>In <a href="#sec-bayesian-modeling"><span>Section&nbsp;6.6</span></a>, we looked at a stochastic process based on MCMC. This process can be used to estimate posterior probability distributions. Following a mathematical notation outline of the Bayesian model, the model must be translated into code. Ideally, prior (or priors) simulations should be conducted at this stage to ensure that the models behave appropriately and that incorrect prior specifications do not bias the results. There are various probabilistic programming languages and R packages that can be used to create Bayesian models. These R packages often act as compilers for the Bayesian engines. The two most prevalent languages are BUGS/JAGS <span class="citation" data-cites="lunnBUGSProjectEvolution2009 plummerJAGSProgramAnalysis2003">(<a href="references.html#ref-lunnBUGSProjectEvolution2009" role="doc-biblioref">Lunn et al., 2009</a>; <a href="references.html#ref-plummerJAGSProgramAnalysis2003" role="doc-biblioref">Plummer, 2003</a>)</span>, which can be incorporated into R with nimble <span class="citation" data-cites="nimble nimbleEcology">(<a href="references.html#ref-nimbleEcology" role="doc-biblioref">Goldstein et al., 2021</a>; <a href="references.html#ref-nimble" role="doc-biblioref">Valpine et al., 2017</a>)</span>, rjags <span class="citation" data-cites="plummerRjagsBayesianGraphical2023">(<a href="references.html#ref-plummerRjagsBayesianGraphical2023" role="doc-biblioref">Plummer et al., 2023</a>)</span>, and bayesmix <span class="citation" data-cites="gruenBayesmixBayesianMixture2023">(<a href="references.html#ref-gruenBayesmixBayesianMixture2023" role="doc-biblioref">Gruen and Plummer, 2023</a>)</span> packages, and Stan <span class="citation" data-cites="gelmanStanProbabilisticProgramming2015">(<a href="references.html#ref-gelmanStanProbabilisticProgramming2015" role="doc-biblioref">Gelman et al., 2015</a>)</span>, which can be utilised through rstan <span class="citation" data-cites="rstan">(<a href="references.html#ref-rstan" role="doc-biblioref">2023</a>)</span>, rstanarm <span class="citation" data-cites="rstanarm">(<a href="references.html#ref-rstanarm" role="doc-biblioref">Goodrich et al., 2023</a>)</span>, and brms <span class="citation" data-cites="brms">(<a href="references.html#ref-brms" role="doc-biblioref">Bürkner, 2017</a>)</span>. This study utilises the STAN-based package, rethinking <span class="citation" data-cites="rethinking">(<a href="references.html#ref-rethinking" role="doc-biblioref">McElreath, 2023</a>)</span>, which is dependent on rstan for fitting basic models. Other more advanced models, such as the multilevel beta-binomial described above, are instead written directly in STAN and fitted using rstan. To demonstrate the difference between writing a model in R and in Stan, two examples are provided. The following example uses the <code>ulam()</code> function in the rethinking package to fit a multilevel poisson model. This package has the benefit of making it relatively easy to translate a mathematical model into code, as the model specification follows the same structure.</p>
<div class="cell">
<div class="sourceCode cell-code" id="annotated-cell-1"><pre class="sourceCode r code-annotation-code code-with-copy code-annotated"><code class="sourceCode r"><span id="annotated-cell-1-1"><a href="#annotated-cell-1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rethinking)</span>
<span id="annotated-cell-1-2"><a href="#annotated-cell-1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-1-3"><a href="#annotated-cell-1-3" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> </span>
<span id="annotated-cell-1-4"><a href="#annotated-cell-1-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ulam</span>(</span>
<span id="annotated-cell-1-5"><a href="#annotated-cell-1-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-1" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-1-6" class="code-annotation-target"><a href="#annotated-cell-1-6" aria-hidden="true" tabindex="-1"></a>        Richness <span class="sc">~</span> <span class="fu">dpois</span>( p ),</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-1" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-1-7" class="code-annotation-target"><a href="#annotated-cell-1-7" aria-hidden="true" tabindex="-1"></a>        <span class="fu">log</span>(p) <span class="ot">&lt;-</span> a[Chronology] <span class="sc">+</span> b[Observations],</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-1" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-1-8" class="code-annotation-target"><a href="#annotated-cell-1-8" aria-hidden="true" tabindex="-1"></a>        a[Chronology] <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">3</span>,<span class="fl">0.5</span>),</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-1" data-target-annotation="4" onclick="event.preventDefault();">4</a><span id="annotated-cell-1-9" class="code-annotation-target"><a href="#annotated-cell-1-9" aria-hidden="true" tabindex="-1"></a>        b[Observations] <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>,<span class="fl">0.2</span>)</span>
<span id="annotated-cell-1-10"><a href="#annotated-cell-1-10" aria-hidden="true" tabindex="-1"></a>    ), </span>
<span id="annotated-cell-1-11"><a href="#annotated-cell-1-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span>dat.Plants_Richness, </span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-1" data-target-annotation="5" onclick="event.preventDefault();">5</a><span id="annotated-cell-1-12" class="code-annotation-target"><a href="#annotated-cell-1-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">chains=</span><span class="dv">4</span>,</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-1" data-target-annotation="6" onclick="event.preventDefault();">6</a><span id="annotated-cell-1-13" class="code-annotation-target"><a href="#annotated-cell-1-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">log_lik=</span><span class="cn">TRUE</span></span>
<span id="annotated-cell-1-14"><a href="#annotated-cell-1-14" aria-hidden="true" tabindex="-1"></a>    )</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-1" data-target-annotation="1">1</dt>
<dd>
<span data-code-lines="6" data-code-cell="annotated-cell-1" data-code-annotation="1">Defining the model formula.</span>
</dd>
<dt data-target-cell="annotated-cell-1" data-target-annotation="2">2</dt>
<dd>
<span data-code-lines="7" data-code-cell="annotated-cell-1" data-code-annotation="2">Modelling <code>p</code> (using the log-link function) in terms of chronology and adding an observation-level varying effect.</span>
</dd>
<dt data-target-cell="annotated-cell-1" data-target-annotation="3">3</dt>
<dd>
<span data-code-lines="8" data-code-cell="annotated-cell-1" data-code-annotation="3">Setting a prior for the chronology intercept.</span>
</dd>
<dt data-target-cell="annotated-cell-1" data-target-annotation="4">4</dt>
<dd>
<span data-code-lines="9" data-code-cell="annotated-cell-1" data-code-annotation="4">Setting a prior for the observation level slope.</span>
</dd>
<dt data-target-cell="annotated-cell-1" data-target-annotation="5">5</dt>
<dd>
<span data-code-lines="12" data-code-cell="annotated-cell-1" data-code-annotation="5">Defining the number of Markov chains.</span>
</dd>
<dt data-target-cell="annotated-cell-1" data-target-annotation="6">6</dt>
<dd>
<span data-code-lines="13" data-code-cell="annotated-cell-1" data-code-annotation="6">Setting <code>log_lik = T</code> to enable model comparisons (with WAIC).</span>
</dd>
</dl>
</div>
</div>
<p>When compared to other modelling techniques, designing a model in Stan necessitates meticulous outlining of all data variables and parameters. Moreover, the varying effects cannot be implicitly inferred but need to be defined through for loops and suitable indices. The code snippet below provides the code used to build a beta-binomial model in Stan.</p>
<div class="cell">
<div class="sourceCode cell-code" id="annotated-cell-2"><pre class="sourceCode r code-annotation-code code-with-copy code-annotated"><code class="sourceCode r"><a class="code-annotation-anchor" data-target-cell="annotated-cell-2" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-2-1" class="code-annotation-target"><a href="#annotated-cell-2-1" aria-hidden="true" tabindex="-1"></a>data{</span>
<span id="annotated-cell-2-2"><a href="#annotated-cell-2-2" aria-hidden="true" tabindex="-1"></a>  int<span class="sc">&lt;</span>lower<span class="ot">=</span><span class="dv">0</span><span class="sc">&gt;</span> J;</span>
<span id="annotated-cell-2-3"><a href="#annotated-cell-2-3" aria-hidden="true" tabindex="-1"></a>  array[J] int N;</span>
<span id="annotated-cell-2-4"><a href="#annotated-cell-2-4" aria-hidden="true" tabindex="-1"></a>  array[J] int A;</span>
<span id="annotated-cell-2-5"><a href="#annotated-cell-2-5" aria-hidden="true" tabindex="-1"></a>  array[J] int Chronology;</span>
<span id="annotated-cell-2-6"><a href="#annotated-cell-2-6" aria-hidden="true" tabindex="-1"></a>}</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-2" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-2-7" class="code-annotation-target"><a href="#annotated-cell-2-7" aria-hidden="true" tabindex="-1"></a>parameters{</span>
<span id="annotated-cell-2-8"><a href="#annotated-cell-2-8" aria-hidden="true" tabindex="-1"></a>  vector[<span class="dv">4</span>] a;</span>
<span id="annotated-cell-2-9"><a href="#annotated-cell-2-9" aria-hidden="true" tabindex="-1"></a>  array[<span class="dv">4</span>] real<span class="sc">&lt;</span>lower<span class="ot">=</span><span class="dv">2</span><span class="sc">&gt;</span> phi;</span>
<span id="annotated-cell-2-10"><a href="#annotated-cell-2-10" aria-hidden="true" tabindex="-1"></a>}</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-2" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-2-11" class="code-annotation-target"><a href="#annotated-cell-2-11" aria-hidden="true" tabindex="-1"></a>model{</span>
<span id="annotated-cell-2-12"><a href="#annotated-cell-2-12" aria-hidden="true" tabindex="-1"></a>  vector[J] pbar;</span>
<span id="annotated-cell-2-13"><a href="#annotated-cell-2-13" aria-hidden="true" tabindex="-1"></a>  a <span class="sc">~</span> <span class="fu">normal</span>(<span class="dv">0</span>, <span class="fl">1.5</span>);</span>
<span id="annotated-cell-2-14"><a href="#annotated-cell-2-14" aria-hidden="true" tabindex="-1"></a>  phi <span class="sc">~</span> <span class="fu">exponential</span>(<span class="dv">1</span>);</span>
<span id="annotated-cell-2-15"><a href="#annotated-cell-2-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> ( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>J ) {</span>
<span id="annotated-cell-2-16"><a href="#annotated-cell-2-16" aria-hidden="true" tabindex="-1"></a>    pbar[i] <span class="ot">=</span> a[Chronology[i]];</span>
<span id="annotated-cell-2-17"><a href="#annotated-cell-2-17" aria-hidden="true" tabindex="-1"></a>    pbar[i] <span class="ot">=</span> <span class="fu">inv_logit</span>(pbar[i]);</span>
<span id="annotated-cell-2-18"><a href="#annotated-cell-2-18" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="annotated-cell-2-19"><a href="#annotated-cell-2-19" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="annotated-cell-2-20"><a href="#annotated-cell-2-20" aria-hidden="true" tabindex="-1"></a>  vector[J] phi_l;</span>
<span id="annotated-cell-2-21"><a href="#annotated-cell-2-21" aria-hidden="true" tabindex="-1"></a>  vector[J] pbar_l;</span>
<span id="annotated-cell-2-22"><a href="#annotated-cell-2-22" aria-hidden="true" tabindex="-1"></a>  vector[J] beta_c;</span>
<span id="annotated-cell-2-23"><a href="#annotated-cell-2-23" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> ( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>J ) {</span>
<span id="annotated-cell-2-24"><a href="#annotated-cell-2-24" aria-hidden="true" tabindex="-1"></a>    phi_l[i] <span class="ot">=</span> phi[Chronology[i]];</span>
<span id="annotated-cell-2-25"><a href="#annotated-cell-2-25" aria-hidden="true" tabindex="-1"></a>    pbar_l[i] <span class="ot">=</span> pbar[i]<span class="sc">*</span>phi_l[i];</span>
<span id="annotated-cell-2-26"><a href="#annotated-cell-2-26" aria-hidden="true" tabindex="-1"></a>    beta_c[i] <span class="ot">=</span> (<span class="dv">1</span> <span class="sc">-</span> pbar[i]) <span class="sc">*</span> phi_l[i];</span>
<span id="annotated-cell-2-27"><a href="#annotated-cell-2-27" aria-hidden="true" tabindex="-1"></a>  }</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-2" data-target-annotation="4" onclick="event.preventDefault();">4</a><span id="annotated-cell-2-28" class="code-annotation-target"><a href="#annotated-cell-2-28" aria-hidden="true" tabindex="-1"></a>  target <span class="sc">+</span><span class="er">=</span> <span class="fu">beta_binomial_lupmf</span>(A <span class="sc">|</span> N, pbar_l, beta_c);</span>
<span id="annotated-cell-2-29"><a href="#annotated-cell-2-29" aria-hidden="true" tabindex="-1"></a>}</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-2" data-target-annotation="1">1</dt>
<dd>
<span data-code-lines="1" data-code-cell="annotated-cell-2" data-code-annotation="1">Defining input data variables.</span>
</dd>
<dt data-target-cell="annotated-cell-2" data-target-annotation="2">2</dt>
<dd>
<span data-code-lines="7" data-code-cell="annotated-cell-2" data-code-annotation="2">Defining model parameters. Note that <span class="math inline">\(\phi\)</span> has a lower boundary of 2, for the reasons detailed before.</span>
</dd>
<dt data-target-cell="annotated-cell-2" data-target-annotation="3">3</dt>
<dd>
<span data-code-lines="11" data-code-cell="annotated-cell-2" data-code-annotation="3">Defining model formula and priors.</span>
</dd>
<dt data-target-cell="annotated-cell-2" data-target-annotation="4">4</dt>
<dd>
<span data-code-lines="28" data-code-cell="annotated-cell-2" data-code-annotation="4">Defining target function.</span>
</dd>
</dl>
</div>
</div>
<p>The Stan code must be implemented and compiled in R using the rstan package, as shown in the code snippet provided.</p>
<div class="cell">
<div class="sourceCode cell-code" id="annotated-cell-3"><pre class="sourceCode r code-annotation-code code-with-copy code-annotated"><code class="sourceCode r"><span id="annotated-cell-3-1"><a href="#annotated-cell-3-1" aria-hidden="true" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">stan</span>(</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-3" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-3-2" class="code-annotation-target"><a href="#annotated-cell-3-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">file =</span> <span class="st">"model.stan"</span>,</span>
<span id="annotated-cell-3-3"><a href="#annotated-cell-3-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> dataset,    </span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-3" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-3-4" class="code-annotation-target"><a href="#annotated-cell-3-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> <span class="dv">4</span>,</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-3" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-3-5" class="code-annotation-target"><a href="#annotated-cell-3-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">warmup =</span> <span class="dv">1000</span>,</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-3" data-target-annotation="4" onclick="event.preventDefault();">4</a><span id="annotated-cell-3-6" class="code-annotation-target"><a href="#annotated-cell-3-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter =</span> <span class="dv">4000</span>,</span>
<span id="annotated-cell-3-7"><a href="#annotated-cell-3-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">cores =</span> <span class="dv">4</span>,              </span>
<span id="annotated-cell-3-8"><a href="#annotated-cell-3-8" aria-hidden="true" tabindex="-1"></a>)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-3" data-target-annotation="1">1</dt>
<dd>
<span data-code-lines="2" data-code-cell="annotated-cell-3" data-code-annotation="1">Path of Stan file “model.stan”.</span>
</dd>
<dt data-target-cell="annotated-cell-3" data-target-annotation="2">2</dt>
<dd>
<span data-code-lines="4" data-code-cell="annotated-cell-3" data-code-annotation="2">Number of Markov chains.</span>
</dd>
<dt data-target-cell="annotated-cell-3" data-target-annotation="3">3</dt>
<dd>
<span data-code-lines="5" data-code-cell="annotated-cell-3" data-code-annotation="3">Warmup iterations per chain.</span>
</dd>
<dt data-target-cell="annotated-cell-3" data-target-annotation="4">4</dt>
<dd>
<span data-code-lines="6" data-code-cell="annotated-cell-3" data-code-annotation="4">Total number of iterations per chain.</span>
</dd>
</dl>
</div>
</div>
<p>In both cases, the MCMC method is used for posterior sampling, with diagnostic information on the model’s fit available through the <code>rstan</code> and <code>rethinking</code> packages. The convergence tells us if the model has worked and most R packages terminate when convergence cannot be reached or the Markov chains appear poorly mixed. In addition, these packages offer instruments to evaluate the effective sample size, which is an estimate of the number of independent samples obtained from the MCMC run. A low effective sample size may indicate poor mixing or autocorrelation in the Markov chains, suggesting that more samples are needed for reliable inference. Furthermore, both packages provide trace plots and density plots of the posterior samples, enabling users to visually inspect the behaviour of the chain and the posterior distributions.</p>
<p>These diagnostic tools are necessary to ensure that the Bayesian models have converged and yielded dependable outcomes. Good convergence is generally reached with an Rhat (<span class="math inline">\(\widehat{R}\)</span>) value near to 1. Rhat measures the convergence of multiple chains <span class="citation" data-cites="vehtariRanknormalizationFoldingLocalization2021">(<a href="references.html#ref-vehtariRanknormalizationFoldingLocalization2021" role="doc-biblioref">Vehtari et al., 2021</a>)</span>. <a href="#tbl-precis-example-methods">Table&nbsp;<span>6.3</span></a> shows the output of the example model <code>m2</code> using the rethinking function <code>precis()</code>. For diagnostic purposes, the columns <code>n_eff</code> (representing the effective sample size) and <code>Rhat</code> are of particular significance. In this instance, we can observe how the chains were sampled efficiently, and achieved convergence at 1. It is also helpful to visually inspect the chains to see if there has been good mixing (<a href="#fig-traceplot-methods-example">Figure&nbsp;<span>6.12</span></a>). A ‘healthy’ chain should be fuzzy and ideally look like a caterpillar (for this reason traceplots are sometimes referred to as caterpillar plots). The posterior distributions in the results section were sampled only when the models had converged (<span class="math inline">\(\widehat{R} = 1\)</span>), the chains mixed efficiently, and the effective sample size (<code>n_eff</code>) was sufficient. Consequently, traceplots were not included in the results to prevent cluttering the text.</p>
<div id="tbl-precis-example-methods" class="anchored">
<table class="table">
<caption>Table&nbsp;6.3: Output of <code>precis(m2)</code>. Some rows have been excluded for ease of reading.</caption>
<colgroup>
<col style="width: 13%">
<col style="width: 8%">
<col style="width: 11%">
<col style="width: 7%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 7%">
</colgroup>
<thead>
<tr class="header">
<th>Value</th>
<th>Mean</th>
<th>SE_Mean</th>
<th>SD</th>
<th>2.5%</th>
<th>25%</th>
<th>50%</th>
<th>75%</th>
<th>97.5%</th>
<th>n_eff</th>
<th>Rhat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>a[1]</td>
<td>-0.48</td>
<td>0</td>
<td>0.12</td>
<td>-0.72</td>
<td>-0.56</td>
<td>-0.48</td>
<td>-0.39</td>
<td>-0.23</td>
<td>23305</td>
<td>1</td>
</tr>
<tr class="even">
<td>a[2]</td>
<td>-0.40</td>
<td>0</td>
<td>0.08</td>
<td>-0.55</td>
<td>-0.45</td>
<td>-0.40</td>
<td>-0.34</td>
<td>-0.24</td>
<td>21928</td>
<td>1</td>
</tr>
<tr class="odd">
<td>…</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>a[12]</td>
<td>-0.54</td>
<td>0</td>
<td>0.09</td>
<td>-0.70</td>
<td>-0.59</td>
<td>-0.54</td>
<td>-0.48</td>
<td>-0.37</td>
<td>19914</td>
<td>1</td>
</tr>
<tr class="odd">
<td>phi[1]</td>
<td>4.29</td>
<td>0.01</td>
<td>0.79</td>
<td>2.90</td>
<td>3.74</td>
<td>4.24</td>
<td>4.77</td>
<td>5.99</td>
<td>18383</td>
<td>1</td>
</tr>
<tr class="even">
<td>phi[2]</td>
<td>4.12</td>
<td>0</td>
<td>0.49</td>
<td>3.22</td>
<td>3.78</td>
<td>4.09</td>
<td>4.43</td>
<td>5.14</td>
<td>20359</td>
<td>1</td>
</tr>
<tr class="odd">
<td>…</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>phi[12]</td>
<td>9.63</td>
<td>0.01</td>
<td>1.72</td>
<td>6.59</td>
<td>8.43</td>
<td>9.52</td>
<td>10.73</td>
<td>13.38</td>
<td>21478</td>
<td>1</td>
</tr>
</tbody>
</table>
</div>
<div id="fig-traceplot-methods-example" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/traceplot_example.png" class="img-fluid figure-img" width="500"></p>
<figcaption class="figure-caption">Figure&nbsp;6.12: Example of a traceplot for parameter <code>a[1]</code>. All parameters require inspection. The shaded region illustrates warm-up iterations, with 4000 iterations per chain in total. Overall, this plot indicates a good mixing.</figcaption>
</figure>
</div>
<p>Once the model is ready and the traceplots indicate a good mixing of the chains for the posterior sampling, it is possible to visually inspect the estimates produced. For this purpose, we employ two packages, which enable the extraction of posterior draws with ease. The first package, tidybayes <span class="citation" data-cites="tidybayes">(<a href="references.html#ref-tidybayes" role="doc-biblioref">Kay, 2023</a>)</span>, presents a range of graphics options and functions to plot estimates that are categorised by the chosen parameter. The second package is an extension of tidybayes, called tidybayes.rethinking, which is tailored to models that rely on the rethinking package. These packages provide a variety of visualisation options. We have chosen to display interval bars showing four credible interval ranges (.99, .90, .80, .50) and a mean probability represented by a circle specifically in the context of intercept estimation. This is to facilitate understanding for those who are not accustomed to reading density graphs or to considering estimate intervals rather than means. An illustration of the graph is given in <a href="#fig-poisson-example-methods">Figure&nbsp;<span>6.13</span></a> below as an example. The highest density intervals, or 0.50 credible intervals, indicate the range of values where the probability density is relatively high, focusing on the areas where the data and prior information offer the greatest support.</p>
<div id="fig-poisson-example-methods" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/plant_richness_poisson_example.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;6.13: Example poisson regression output from <code>m1</code>. The graph displays the predicted richness of plant species per varying intercept (chronology), represented on an inverse log scale as a result of the use of a link function to return it to the original scale. It is evident that the Roman (R) credible interval is shorter due to a higher number of samples with less variation. The Ma chronology (11<sup>th</sup> century onwards) has a broader credible interval due to a smaller sample size. If a stronger prior were selected, the credible intervals would be shorter. The red line indicates the overall mean.</figcaption>
</figure>
</div>
<p>Regarding beta-binomial models that involve estimating the <span class="math inline">\(\phi\)</span> parameter, we selected an alternative visualisation to prevent any confusion for the reader. The precision parameter estimate graphs are presented similarly to the intercept graphs, with density distributions showing the shape of the distribution. Each line is also plotted with two probability intervals — 0.65 (represented by a shorter, thicker line) and 0.99 (represented by a longer, thinner line). In relation regression models with numerical predictors (such as elevation, temperature, and precipitation), we plotted estimates using credible intervals at .95, .80, and .50, avoiding intervals that were excessively large (i.e.&nbsp;.99) and could have made interpretation of any specific trend difficult. The plots display either a positive or negative correlation as indicated by the slope, and the width of the interval changes according to the sample size and variability.</p>
<p>Finally, for some models, an attempt was made to produce community plots, combining the estimates of several models to provide information on particular temporal trends or interactions between species, to answer questions such as “Which species were similarly abundant? What is the degree of separation between two species? Which species has the largest or smallest variability in its estimates?”. As noted in the results section, combining estimates from different models is not a precise procedure and a multivariate modelling approach would be more suitable. However, since the models were generated using the same formula and parameters, it is nonetheless informative to look at these graphs to get a broader view of the general trends. Such plots can be interpreted by displaying the predicted probability of occurrence (restricted between 0 and 1) on the x-axis, while on the y-axis, the slope coefficient indicates whether there is a positive or negative correlation in numerical regressions (e.g. <a href="zooarchaeology.html#fig-domestic-alt">Figure&nbsp;<span>8.38</span></a>). Alternatively, in other instances (e.g. <a href="zooarchaeology.html#fig-animals-by-chrono-comm-plot">Figure&nbsp;<span>8.4</span></a>), probabilities can be plotted against the precision factor <span class="math inline">\(\phi\)</span>.</p>
<p>In Bayesian modelling, it is essential to make model comparisons. Various methods exist for model comparison, such as AIC, BIC, DIC, and PSIS, each serving a different purpose <span class="citation" data-cites="albertProbabilityBayesianModeling2020 kruschkeDoingBayesianData2015">(<a href="references.html#ref-albertProbabilityBayesianModeling2020" role="doc-biblioref">Albert and Hu, 2020, pp. 314–316, 530–533</a>; <a href="references.html#ref-kruschkeDoingBayesianData2015" role="doc-biblioref">Kruschke, 2015, pp. 266–295</a>)</span>. We will introduce the Widely Applicable Information Criterion (WAIC) for simplicity. The WAIC is the logarithm of the predictive posterior density (lppd) with a penalty term proportional to the variance in the posterior predictions. We will not elaborate on the mathematical details, but it is important to note that it provides a more robust approach that takes into account model flexibility and predictive accuracy. To additionally handle overfitting due to an increased number of parameters, the results also present pWAIC alongside WAIC <span class="citation" data-cites="mcelreath2016 vehtariPracticalBayesianModel2017 gelmanUnderstandingPredictiveInformation2014">(<a href="references.html#ref-gelmanUnderstandingPredictiveInformation2014" role="doc-biblioref">Gelman et al., 2014</a>; <a href="references.html#ref-mcelreath2016" role="doc-biblioref">McElreath, 2016, pp. 220–221</a>; <a href="references.html#ref-vehtariPracticalBayesianModel2017" role="doc-biblioref">Vehtari et al., 2017</a>)</span>. It is worth considering that WAIC (and other equivalent measures) are exclusively designed to compare models to help determine which model is preferable when we have models that are equally plausible (assuming our causal inference is correct). This is accomplished by assessing the models out-of-sample, meaning how well they perform with data that was not seen during their fitting process (i.e.&nbsp;how well they generalise to new data). To comprehend the results, the specific WAIC value alone is not significant, but rather used to evaluate the model with the lowest value. The model with the lowest value indicates a better model performance. In addition to WAIC, other graphical tools such as posterior predictive checks and visual comparisons of model predictions to observed data, can provide useful feedback on model performance.</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-albertBayesianComputation2009" class="csl-entry" role="listitem">
Albert, J., 2009. Bayesian computation with <span>R</span>, 2. Aufl. ed, Use <span>R</span>! <span>Springer</span>, <span>Dordrecht Heidelberg</span>.
</div>
<div id="ref-albertProbabilityBayesianModeling2020" class="csl-entry" role="listitem">
Albert, J., Hu, J., 2020. <a href="https://doi.org/10.1201/9781351030144">Probability and <span>Bayesian Modeling</span></a>, 1st ed. <span>Chapman and Hall/CRC</span>.
</div>
<div id="ref-andersonNewMethodNonparametric2001" class="csl-entry" role="listitem">
Anderson, M.J., 2001. <a href="https://doi.org/10.1111/j.1442-9993.2001.01070.pp.x">A new method for non-parametric multivariate analysis of variance</a>. Austral Ecology 26, 32–46.
</div>
<div id="ref-andersonPermutationalMultivariateAnalysis2017" class="csl-entry" role="listitem">
Anderson, M.J., 2017. <a href="https://doi.org/10.1002/9781118445112.stat07841">Permutational <span>Multivariate Analysis</span> of <span>Variance</span> (<span>PERMANOVA</span>)</a>. In: Wiley <span>StatsRef</span>: <span>Statistics Reference Online</span>. <span>John Wiley &amp; Sons, Ltd</span>, pp. 1–15.
</div>
<div id="ref-andersonScalesStatisticsParametric1961" class="csl-entry" role="listitem">
Anderson, N.H., 1961. <a href="https://doi.org/10.1037/h0042576">Scales and statistics: <span>Parametric</span> and nonparametric.</a> Psychological Bulletin 58, 305–316.
</div>
<div id="ref-bakkerPERMANOVA2023" class="csl-entry" role="listitem">
Bakker, J.D., 2023. <span>PERMANOVA</span>. Applied Multivariate Statistics in R.
</div>
<div id="ref-bannerUseBayesianPriors2020" class="csl-entry" role="listitem">
Banner, K.M., Irvine, K.M., Rodhouse, T.J., 2020. <a href="https://doi.org/10.1111/2041-210X.13407">The use of <span>Bayesian</span> priors in <span>Ecology</span>: <span>The</span> good, the bad and the not great</a>. Methods in Ecology and Evolution 11, 882–889.
</div>
<div id="ref-banningAnalysingPlantRemains2000" class="csl-entry" role="listitem">
Banning, E.B., Jochim, M.A., Dickens, R.S. (Eds.), 2000. <a href="https://doi.org/10.1007/0-306-47654-1_11">Analysing <span>Plant Remains</span></a>. In: The <span>Archaeologist</span>’s <span>Laboratory</span>: <span>The Analysis</span> of <span>Archaeological Data</span>, Interdisciplinary <span>Contributions</span> to <span>Archaeology</span>. <span>Springer US</span>, <span>Boston, MA</span>, pp. 213–233.
</div>
<div id="ref-barrantesConceptualStatisticalProblems2009" class="csl-entry" role="listitem">
Barrantes, G., Sandoval, L., 2009. <a href="https://doi.org/10.15517/rbt.v57i3.5467"><span>Conceptual and statistical problems associated with the use of diversity indices in ecology</span></a>. Revista de Biología Tropical 57, 451-460-451-460.
</div>
<div id="ref-bastowwilsonSpeciesPresenceAbsence2012" class="csl-entry" role="listitem">
Bastow Wilson, J., 2012. <a href="https://doi.org/10.1111/j.1654-1103.2012.01430.x">Species presence/absence sometimes represents a plant community as well as species abundances do, or better</a>. Journal of Vegetation Science 23, 1013–1023.
</div>
<div id="ref-bishopPatternRecognitionMachine2006a" class="csl-entry" role="listitem">
Bishop, C.M., 2006. Pattern recognition and machine learning, Information science and statistics. <span>Springer</span>, <span>New York</span>.
</div>
<div id="ref-bosiSeedsFruitsPollen2011" class="csl-entry" role="listitem">
Bosi, G., Mazzanti, M.B., Florenzano, A., N’siala, I.M., Pederzoli, A., Rinaldi, R., Torri, P., Mercuri, A.M., 2011. <a href="https://doi.org/10.1016/j.jas.2011.02.027">Seeds/fruits, pollen and parasite remains as evidence of site function: Piazza <span>Garibaldi</span> <span>Parma</span> (<span>N Italy</span>) in <span>Roman</span> and <span>Mediaeval</span> times</a>. Journal of Archaeological Science 38, 1621–1633.
</div>
<div id="ref-bosiIndaginiArcheobotanicheSul2012" class="csl-entry" role="listitem">
Bosi, G., Mercuri, A.M., Pederzoli, A., Florenzano, A., Rinaldi, R., Bandini Mazzanti, M., 2012. Indagini archeobotaniche sul riempimento delle buche da rifiuti e del pozzo nero di via <span>Cavestro</span> a <span>Parma</span> (<span>X-XI</span> sec d.<span>C</span>.). In: Marini Calvani, M. (Ed.), Ventidue Secoli a <span>Parma</span>: Lo Scavo Sotto La Sede Centrale Della <span>Cassa</span> Di <span>Risparmio</span> in Piazza <span>Garibaldi</span>, <span>BAR</span> International Series. <span>Archaeopress</span>, <span>Oxford, England</span>, pp. 269–283.
</div>
<div id="ref-bowesRomanPeasantProject2020" class="csl-entry" role="listitem">
Bowes, K. (Ed.), 2020. <a href="https://www.jstor.org/stable/j.ctv18dvvqq">The <span>Roman Peasant Project</span> 2009-2014: <span>Excavating</span> the <span>Roman Rural Poor</span></a>. <span>University of Pennsylvania Press</span>.
</div>
<div id="ref-buonincontriFarmingRuralSettlement2014" class="csl-entry" role="listitem">
Buonincontri, M., Moser, D., Allevato, E., Basile, B., Di Pasquale, G., 2014. <a href="https://doi.org/10.1007/s00334-013-0429-8">Farming in a rural settlement in central <span>Italy</span>: Cultural and environmental implications of crop production through the transition from <span>Lombard</span> to <span>Frankish</span> influence (8th11th centuries a.d.)</a>. Vegetation History and Archaeobotany 23, 775–788.
</div>
<div id="ref-brms" class="csl-entry" role="listitem">
Bürkner, P.-C., 2017. <a href="https://doi.org/10.18637/jss.v080.i01"><span></span>Brms<span></span>: An <span></span>r<span></span> package for <span></span>bayesian<span></span> multilevel models using <span></span>stan<span></span></a> 80.
</div>
<div id="ref-burknerOrdinalRegressionModels2019" class="csl-entry" role="listitem">
Bürkner, P.-C., Vuorre, M., 2019. <a href="https://doi.org/10.1177/2515245918823199">Ordinal <span>Regression Models</span> in <span>Psychology</span>: <span>A Tutorial</span></a>. Advances in Methods and Practices in Psychological Science 2, 77–101.
</div>
<div id="ref-cardarelliDeepVariationalConvolutional2022" class="csl-entry" role="listitem">
Cardarelli, L., 2022. <a href="https://doi.org/10.1016/j.jas.2022.105640">A deep variational convolutional <span>Autoencoder</span> for unsupervised features extraction of ceramic profiles. <span>A</span> case study from central <span>Italy</span></a>. Journal of Archaeological Science 144, 105640.
</div>
<div id="ref-carlinBayesianMethodsData2008" class="csl-entry" role="listitem">
Carlin, B.P., Louis, T.A., 2008. <a href="https://doi.org/10.1201/b14884">Bayesian <span>Methods</span> for <span>Data Analysis</span></a>, 3rd ed. <span>Chapman and Hall/CRC</span>, <span>New York</span>.
</div>
<div id="ref-castiglioniBrescianArchaeobotanicalStudies2019" class="csl-entry" role="listitem">
Castiglioni, E., Rottoli, M., 2019. Brescian archaeobotanical studies, <span>Romanization</span> to <span>Early Medieval</span> periods. European Journal of PostClassical Archaeologies 8, 91–116.
</div>
<div id="ref-cuffneyAquaticEcosystemsIndicators2014" class="csl-entry" role="listitem">
Cuffney, T.F., Kennen, J.G., Waite, I.R., 2014. <a href="https://doi.org/10.1016/B978-0-12-382182-9.00008-6">Aquatic <span>Ecosystems</span> as <span>Indicators</span> of <span>Status</span> and <span>Trends</span> in <span>Water Quality</span></a>. In: Comprehensive <span>Water Quality</span> and <span>Purification</span>. <span>Elsevier</span>, pp. 122–156.
</div>
<div id="ref-dalyEcologicalDiversityMeasuring2018" class="csl-entry" role="listitem">
Daly, A.J., Baetens, J.M., De Baets, B., 2018. <a href="https://doi.org/10.3390/math6070119">Ecological <span>Diversity</span>: <span>Measuring</span> the <span>Unmeasurable</span></a>. Mathematics 6, 119.
</div>
<div id="ref-davisDefiningWhatWe2020" class="csl-entry" role="listitem">
Davis, D.S., 2020. <a href="https://doi.org/10.1016/j.daach.2020.e00152">Defining what we study: <span>The</span> contribution of machine automation in archaeological research</a>. Digital Applications in Archaeology and Cultural Heritage 18, e00152.
</div>
<div id="ref-dexterTroubleStressFlexible2018" class="csl-entry" role="listitem">
Dexter, E., Rollwagen-Bollens, G., Bollens, S.M., 2018. <a href="https://doi.org/10.1002/lom3.10257">The trouble with stress: <span>A</span> flexible method for the evaluation of nonmetric multidimensional scaling: <span><em>The</em></span><span> <em>Trouble with Stress</em></span></a>. Limnology and Oceanography: Methods 16, 434–443.
</div>
<div id="ref-dunnellNotionSite1992" class="csl-entry" role="listitem">
Dunnell, R.C., 1992. <a href="https://doi.org/10.1007/978-1-4899-2450-6_2">The <span>Notion Site</span></a>. In: Rossignol, J., Wandsnider, L. (Eds.), Space, <span>Time</span>, and <span>Archaeological Landscapes</span>, Interdisciplinary <span>Contributions</span> to <span>Archaeology</span>. <span>Springer US</span>, <span>Boston, MA</span>, pp. 21–41.
</div>
<div id="ref-fletcherDiggingNumbersElementary2005" class="csl-entry" role="listitem">
Fletcher, M., Lock, G.R., 2005. Digging numbers: Elementary statistics for archaeologists, 2nd ed. ed, Monograph (<span>Oxford University School</span> of <span>Archaeology</span>). <span>Oxford University Committee for Archaeology</span>, <span>Oxford : Oakville, CT</span>.
</div>
<div id="ref-garcia-garciaBinomialDistributionHistorical2022" class="csl-entry" role="listitem">
García-García, J.I., Fernández Coronado, N.A., Arredondo, E.H., Imilpán Rivera, I.A., 2022. <a href="https://doi.org/10.3390/math10152680">The <span>Binomial Distribution</span>: <span>Historical Origin</span> and <span>Evolution</span> of <span>Its Problem Situations</span></a>. Mathematics 10, 2680.
</div>
<div id="ref-gauchMultivariateAnalysisCommunity1982" class="csl-entry" role="listitem">
Gauch, H.G., 1982. <a href="https://doi.org/10.1017/CBO9780511623332">Multivariate <span>Analysis</span> in <span>Community Ecology</span></a>, First. ed. <span>Cambridge University Press</span>.
</div>
<div id="ref-gelmanBayesianDataAnalysis2013a" class="csl-entry" role="listitem">
Gelman, A., Carlin, J.B., Stern, H.S., Dunson, D.B., Vehtari, A., Rubin, D.B., 2013. <a href="https://doi.org/10.1201/b16018">Bayesian <span>Data Analysis</span></a>, 3rd ed. <span>Chapman and Hall/CRC</span>, <span>New York</span>.
</div>
<div id="ref-gelmanUnderstandingPredictiveInformation2014" class="csl-entry" role="listitem">
Gelman, A., Hwang, J., Vehtari, A., 2014. <a href="https://doi.org/10.1007/s11222-013-9416-2">Understanding predictive information criteria for <span>Bayesian</span> models</a>. Statistics and Computing 24, 997–1016.
</div>
<div id="ref-gelmanStanProbabilisticProgramming2015" class="csl-entry" role="listitem">
Gelman, A., Lee, D., Guo, J., 2015. <a href="https://doi.org/10.3102/1076998615606113">Stan: <span>A Probabilistic Programming Language</span> for <span>Bayesian Inference</span> and <span>Optimization</span></a>. Journal of Educational and Behavioral Statistics 40, 530–543.
</div>
<div id="ref-nimbleEcology" class="csl-entry" role="listitem">
Goldstein, B.R., Turek, D., Ponisio, L., Valpine, P. de, 2021. <a href="https://cran.r-project.org/package=nimbleEcology"><span></span>nimbleEcology<span></span>: Distributions for ecological models in <span></span>nimble<span></span></a>.
</div>
<div id="ref-gollandPermutationTestsClassification2005" class="csl-entry" role="listitem">
Golland, P., Liang, F., Mukherjee, S., Panchenko, D., 2005. <a href="https://doi.org/10.1007/11503415_34">Permutation <span>Tests</span> for <span>Classification</span></a>. In: Auer, P., Meir, R. (Eds.), Learning <span>Theory</span>, Lecture <span>Notes</span> in <span>Computer Science</span>. <span>Springer</span>, <span>Berlin, Heidelberg</span>, pp. 501–515.
</div>
<div id="ref-rstanarm" class="csl-entry" role="listitem">
Goodrich, B., Gabry, J., Ali, I., Brilleman, S., 2023. <a href="https://mc-stan.org/rstanarm/">Rstanarm: <span></span>Bayesian<span></span> applied regression modeling via <span></span>stan<span></span>.</a>
</div>
<div id="ref-grebnerForestDynamics2013" class="csl-entry" role="listitem">
Grebner, D.L., Bettinger, P., Siry, J.P., 2013. <a href="https://doi.org/10.1016/B978-0-12-386901-2.00010-5">Forest <span>Dynamics</span></a>. In: Introduction to <span>Forestry</span> and <span>Natural Resources</span>. <span>Elsevier</span>, pp. 243–254.
</div>
<div id="ref-grosStoriaUrbanisticaMondo2014" class="csl-entry" role="listitem">
Gros, P., Torelli, M., 2014. <span>Storia dell’urbanistica: Il mondo romano</span>, Edizione 3. ed, <span>Grandi Opere</span>. <span>Editori Laterza</span>, <span>Roma</span>.
</div>
<div id="ref-gruenBayesmixBayesianMixture2023" class="csl-entry" role="listitem">
Gruen, B., Plummer, M., 2023. Bayesmix: <span>Bayesian Mixture Models</span> with <span>JAGS</span>.
</div>
<div id="ref-guisanHabitatSuitabilityDistribution2017" class="csl-entry" role="listitem">
Guisan, A., Thuiller, W., Zimmermann, N.E., 2017. <a href="https://doi.org/10.1017/9781139028271">Habitat suitability and distribution models: With applications in <span>R</span></a>, Ecology, biodiversity and conservation. <span>Cambridge University Press</span>, <span>Cambridge New York, NY Port Melbourne Delhi Singapore</span>.
</div>
<div id="ref-guisanPredictiveHabitatDistribution2000" class="csl-entry" role="listitem">
Guisan, A., Zimmermann, N.E., 2000. <a href="https://doi.org/10.1016/S0304-3800(00)00354-9">Predictive habitat distribution models in ecology</a>. Ecological Modelling 135, 147–186.
</div>
<div id="ref-harrisonComparisonObservationlevelRandom2015" class="csl-entry" role="listitem">
Harrison, X.A., 2015. <a href="https://doi.org/10.7717/peerj.1114">A comparison of observation-level random effect and <span>Beta-Binomial</span> models for modelling overdispersion in <span>Binomial</span> data in ecology &amp; evolution</a>. PeerJ 3, e1114.
</div>
<div id="ref-hartigStatisticalInferenceStochastic2011" class="csl-entry" role="listitem">
Hartig, F., Calabrese, J.M., Reineking, B., Wiegand, T., Huth, A., 2011. <a href="https://doi.org/10.1111/j.1461-0248.2011.01640.x">Statistical inference for stochastic simulation models - theory and application: <span>Inference</span> for stochastic simulation models</a>. Ecology Letters 14, 816–827.
</div>
<div id="ref-heersCittaNelMedioevo1995" class="csl-entry" role="listitem">
Heers, J., 1995. <span>La città nel medioevo in occidente: paesaggi, poteri e conflitti</span>. <span>Editoriale Jaca Book</span>.
</div>
<div id="ref-heinrichModellingCropSelectionRoman2017" class="csl-entry" role="listitem">
Heinrich, F., 2017. <a href="https://doi.org/10.1163/9789004345027_008">Modelling <span>Crop-Selection</span> in <span>Roman Italy</span>. <span>The Economics</span> of <span>Agricultural Decision Making</span> in a <span>Globalizing Economy</span></a>. In: de Haas, T., Tol, G. (Eds.), The <span>Economic Integration</span> of <span>Roman Italy</span>. <span>BRILL</span>, pp. 141–169.
</div>
<div id="ref-heipComparingSpeciesDiversity1974" class="csl-entry" role="listitem">
Heip, C., Engels, P., 1974. <a href="https://doi.org/10.1017/S0025315400022748">Comparing <span>Species Diversity</span> and <span>Evenness Indices</span></a>. Journal of the Marine Biological Association of the United Kingdom 54, 559–563.
</div>
<div id="ref-hilbeModelingCountData2014" class="csl-entry" role="listitem">
Hilbe, J.M., 2014. Modeling <span>Count Data</span>. <span>Cambridge University Press</span>.
</div>
<div id="ref-hillDiversityEvennessUnifying1973" class="csl-entry" role="listitem">
Hill, M.O., 1973. <a href="https://doi.org/10.2307/1934352">Diversity and <span>Evenness</span>: <span>A Unifying Notation</span> and <span>Its Consequences</span></a>. Ecology 54, 427–432.
</div>
<div id="ref-hollanderNonparametricStatisticalMethods2015" class="csl-entry" role="listitem">
Hollander, M., Wolfe, D.A., Chicken, E., 2015. Nonparametric <span>Statistical Methods</span>, 2nd ed, Wiley <span>Series</span> in <span>Probability</span> and <span>Statistics</span>. <span>John Wiley &amp; Sons</span>, <span>Hoboken, New Jersey</span>.
</div>
<div id="ref-jamesIntroductionStatisticalLearning2021" class="csl-entry" role="listitem">
James, G., Witten, D., Hastie, T., Tibshirani, R., 2021. <a href="https://doi.org/10.1007/978-1-0716-1418-1">An <span>Introduction</span> to <span>Statistical Learning</span>: With <span>Applications</span> in <span>R</span></a>, Springer <span>Texts</span> in <span>Statistics</span>. <span>Springer US</span>, <span>New York, NY</span>.
</div>
<div id="ref-johnsonBayesRulesIntroduction2022" class="csl-entry" role="listitem">
Johnson, A.A., Ott, M.Q., Dogucu, M., 2022. Bayes rules! An introduction to <span>Bayesian</span> modeling with <span>R</span>, Chapman &amp; <span>Hall</span>/<span>CRC</span> texts in statistical science. <span>CRC Press</span>, <span>Boca Raton</span>.
</div>
<div id="ref-kadanePossibleStatisticalContributions1988" class="csl-entry" role="listitem">
Kadane, J.B., 1988. Possible statistical contributions to paleoethnobotany. In: Hastorf, C.A., Popper, V.S. (Eds.), Current Paleoethnobotany: Analytical Methods and Cultural Interpretations. <span>University of Chicago Press</span>, <span>Chicago</span>, pp. 206–214.
</div>
<div id="ref-tidybayes" class="csl-entry" role="listitem">
Kay, M., 2023. <a href="https://doi.org/10.5281/zenodo.1308151"><span></span>Tidybayes<span></span>: Tidy data and geoms for <span></span>bayesian<span></span> models</a>.
</div>
<div id="ref-kermanNeutralNoninformativeInformative2011" class="csl-entry" role="listitem">
Kerman, J., 2011. <a href="https://doi.org/10.1214/11-EJS648">Neutral noninformative and informative conjugate beta and gamma prior distributions</a>. Electronic Journal of Statistics 5, 1450–1470.
</div>
<div id="ref-kimValidationBetaBinomialModel2017" class="csl-entry" role="listitem">
Kim, J., Lee, J.-H., 2017. <a href="https://doi.org/10.1080/03610918.2014.960091">The <span>Validation</span> of a <span>Beta-Binomial Model</span> for <span>Overdispersed Binomial Data</span></a>. Communications in statistics: Simulation and computation 46, 807–814.
</div>
<div id="ref-kosubNoteTriangleInequality2019" class="csl-entry" role="listitem">
Kosub, S., 2019. <a href="https://doi.org/10.1016/j.patrec.2018.12.007">A note on the triangle inequality for the <span>Jaccard</span> distance</a>. Pattern Recognition Letters 120, 36–38.
</div>
<div id="ref-kraska-millerNonparametricStatisticsSocial2014" class="csl-entry" role="listitem">
Kraska-Miller, M., 2014. Nonparametric statistics for social and behavioral sciences. <span>CRC Press</span>, <span>Boca Raton London New York</span>.
</div>
<div id="ref-kruschkeDoingBayesianData2015" class="csl-entry" role="listitem">
Kruschke, J.K., 2015. Doing <span>Bayesian</span> data analysis: A tutorial with <span>R</span>, <span>JAGS</span>, and <span>Stan</span>, 2nd edition. ed. <span>Academic Press</span>, <span>Amsterdam</span>.
</div>
<div id="ref-lauroComputationalStatisticsStatistical1996" class="csl-entry" role="listitem">
Lauro, C., 1996. <a href="https://doi.org/10.1016/0167-9473(96)88920-1">Computational statistics or statistical computing, is that the question?</a> Computational Statistics &amp; Data Analysis, Classification 23, 191–193.
</div>
<div id="ref-leeBayesianEstimationPrediction1987" class="csl-entry" role="listitem">
Lee, J.C., Sabavala, D.J., 1987. <a href="https://doi.org/10.1080/07350015.1987.10509600">Bayesian <span>Estimation</span> and <span>Prediction</span> for the <span>Beta-Binomial Model</span></a>. Journal of Business &amp; Economic Statistics 5, 357–367.
</div>
<div id="ref-leeNoteBayesianEstimation1999" class="csl-entry" role="listitem">
Lee, J., Lio, Y.L., 1999. <a href="https://doi.org/10.1080/00949659908811950">A note on bayesian estimation and prediction for the beta-binomial model</a>. Journal of Statistical Computation and Simulation 63, 73–91.
</div>
<div id="ref-levinsStrategyModelBuilding1966" class="csl-entry" role="listitem">
Levins, R., 1966. <a href="https://www.jstor.org/stable/27836590">The <span>Strategy</span> of <span>Model Building</span> in <span>Population Biology</span></a>. American Scientist 54, 421–431.
</div>
<div id="ref-lunnBUGSProjectEvolution2009" class="csl-entry" role="listitem">
Lunn, D., Spiegelhalter, D., Thomas, A., Best, N., 2009. <a href="https://doi.org/10.1002/sim.3680">The <span>BUGS</span> project: <span>Evolution</span>, critique and future directions</a>. Statistics in Medicine 28, 3049–3067.
</div>
<div id="ref-marinBayesianEssentials2014" class="csl-entry" role="listitem">
Marin, J.-M., Robert, C.P., 2014. Bayesian essentials with <span>R</span>, Second edition. ed, Springer <span>Texts</span> in <span>Statistics</span>. <span>Springer</span>, <span>New York</span>.
</div>
<div id="ref-mcelreath2016" class="csl-entry" role="listitem">
McElreath, R., 2016. Statistical rethinking: A bayesian course with examples in r and stan, Chapman &amp; hall/CRC texts in statistical science series. CRC Press/Taylor &amp; Francis Group, Boca Raton.
</div>
<div id="ref-rethinking" class="csl-entry" role="listitem">
McElreath, R., 2023. Rethinking: Statistical rethinking book package.
</div>
<div id="ref-mooreDiversityTaxonomicFunctional2013" class="csl-entry" role="listitem">
Moore, J.C., 2013. <a href="https://doi.org/10.1016/B978-0-12-384719-5.00036-8">Diversity, taxonomic versus functional</a>. In: Encyclopedia of Biodiversity. Elsevier, pp. 648–656.
</div>
<div id="ref-morrisChoosingUsingDiversity2014" class="csl-entry" role="listitem">
Morris, E.K., Caruso, T., Buscot, F., Fischer, M., Hancock, C., Maier, T.S., Meiners, T., Müller, C., Obermaier, E., Prati, D., Socher, S.A., Sonnemann, I., Wäschke, N., Wubet, T., Wurst, S., Rillig, M.C., 2014. <a href="https://doi.org/10.1002/ece3.1155">Choosing and using diversity indices: Insights for ecological applications from the <span>German Biodiversity Exploratories</span></a>. Ecology and Evolution 4, 3514–3524.
</div>
<div id="ref-vegan" class="csl-entry" role="listitem">
Oksanen, J., Blanchet, F.G., Friendly, M., Kindt, R., Legendre, P., McGlinn, D., Minchin, P.R., O’Hara, R.B., Simpson, G.L., Solymos, P., Stevens, M.H.H., Szoecs, E., Wagner, H., 2020. <a href="https://CRAN.R-project.org/package=vegan">Vegan: Community ecology package</a>.
</div>
<div id="ref-oksanenVeganCommunityEcology2022" class="csl-entry" role="listitem">
Oksanen, J., Simpson, G.L., Blanchet, F.G., Kindt, R., Legendre, P., Minchin, P.R., O’Hara, R.B., Solymos, P., Stevens, M.H.H., Szoecs, E., Wagner, H., Barbour, M., Bedward, M., Bolker, B., Borcard, D., Carvalho, G., Chirico, M., Caceres, M.D., Durand, S., Evangelista, H.B.A., FitzJohn, R., Friendly, M., Furneaux, B., Hannigan, G., Hill, M.O., Lahti, L., McGlinn, D., Ouellette, M.-H., Cunha, E.R., Smith, T., Stier, A., Braak, C.J.F.T., Weedon, J., 2022. <a href="https://CRAN.R-project.org/package=vegan">Vegan: Community ecology package</a>.
</div>
<div id="ref-palmisanoLongTermDemographicTrends2021" class="csl-entry" role="listitem">
Palmisano, A., Bevan, A., Kabelindde, A., Roberts, N., Shennan, S., 2021. <a href="https://doi.org/10.1007/s10963-021-09159-3">Long-<span>Term Demographic Trends</span> in <span>Prehistoric Italy</span>: <span>Climate Impacts</span> and <span>Regionalised Socio-Ecological Trajectories</span></a>. Journal of World Prehistory 34, 381–432.
</div>
<div id="ref-parkinsonRadiocarbonDatedTrends2021" class="csl-entry" role="listitem">
Parkinson, E.W., McLaughlin, T.R., Esposito, C., Stoddart, S., Malone, C., 2021. <a href="https://doi.org/10.1007/s10963-021-09158-4">Radiocarbon <span>Dated Trends</span> and <span>Central Mediterranean Prehistory</span></a>. Journal of World Prehistory 34, 317–379.
</div>
<div id="ref-parsonsArchaeologicalSettlementPatterns1972" class="csl-entry" role="listitem">
Parsons, J.R., 1972. <a href="https://doi.org/10.1146/annurev.an.01.100172.001015">Archaeological <span>Settlement Patterns</span></a>. Annual Review of Anthropology 1, 127–150.
</div>
<div id="ref-pearlBookWhyNew2019" class="csl-entry" role="listitem">
Pearl, J., Mackenzie, D., 2019. The book of why: The new science of cause and effect, Penguin science. <span>Penguin Books</span>, <span>London</span>.
</div>
<div id="ref-pearsallPaleoethnobotanyHandbookProcedures2015a" class="csl-entry" role="listitem">
Pearsall, D.M., 2015. Paleoethnobotany: A handbook of procedures, Third edition. ed. <span>Left Coast Press Inc</span>, <span>Walnut Creek, California</span>.
</div>
<div id="ref-piccinatoUrbanisticaMedievale1993" class="csl-entry" role="listitem">
Piccinato, L., 1993. <span>Urbanistica medievale</span>, 1. rist. ed, <span>Universale di architettura</span>. <span>Ed. Dedalo</span>, <span>Bari</span>.
</div>
<div id="ref-pielouMeasurementDiversityDifferent1966" class="csl-entry" role="listitem">
Pielou, E.C., 1966. <a href="https://doi.org/10.1016/0022-5193(66)90013-0">The measurement of diversity in different types of biological collections</a>. Journal of Theoretical Biology 13, 131–144.
</div>
<div id="ref-plogSampleSizeRichnessRelation1993" class="csl-entry" role="listitem">
Plog, S., Hegmon, M., 1993. <a href="https://doi.org/10.2307/282108">The <span>Sample Size-Richness Relation</span>: <span>The Relevance</span> of <span>Research Questions</span>, <span>Sampling Strategies</span>, and <span>Behavioral Variation</span></a>. American Antiquity 58, 489–496.
</div>
<div id="ref-plummerJAGSProgramAnalysis2003" class="csl-entry" role="listitem">
Plummer, M., 2003. <span>JAGS</span>: <span>A</span> program for analysis of <span>Bayesian</span> graphical models using <span>Gibbs</span> sampling. In: Hornik, K., Leisch, F., Achim, Z. (Eds.), Proceedings of the 3rd <span>International Workshop</span> on <span>Distributed Statistical Computing</span> (<span>DSC</span> 2003). <span>Technische Universität Wien</span>, <span>Vienna</span>, pp. 1–10.
</div>
<div id="ref-plummerRjagsBayesianGraphical2023" class="csl-entry" role="listitem">
Plummer, M., Stukalov, A., Denwood, M., 2023. Rjags: <span>Bayesian Graphical Models</span> using <span>MCMC</span>.
</div>
<div id="ref-rizzoStatisticalComputing2019" class="csl-entry" role="listitem">
Rizzo, M.L., 2019. <a href="https://doi.org/10.1201/9780429192760">Statistical <span>Computing</span> with <span>R</span></a>, Second. ed. <span>Chapman and Hall/CRC</span>, <span>New York</span>.
</div>
<div id="ref-robertMonteCarloStatistical2004" class="csl-entry" role="listitem">
Robert, C.P., Casella, G., 2004. Monte <span>Carlo</span> statistical methods, 2. ed. ed, Springer texts in statistics. <span>Springer</span>, <span>New York, NY</span>.
</div>
<div id="ref-robertIntroducingMonteCarlo2010" class="csl-entry" role="listitem">
Robert, C.P., Casella, G., 2010. Introducing <span>Monte Carlo</span> methods with <span>R</span>, Use <span>R</span>! <span>Springer</span>, <span>New York, NY Heidelberg</span>.
</div>
<div id="ref-salakpiDynamicHierarchicalBayesian2022" class="csl-entry" role="listitem">
Salakpi, E.E., Hurley, P.D., Muthoka, J.M., Bowell, A., Oliver, S., Rowhani, P., 2022. <a href="https://doi.org/10.5194/nhess-22-2725-2022">A dynamic hierarchical <span>Bayesian</span> approach for forecasting vegetation condition</a>. Natural Hazards and Earth System Sciences 22, 2725–2749.
</div>
<div id="ref-schuhmacherTransportComputationOptimal2022" class="csl-entry" role="listitem">
Schuhmacher, D., diagrams), B.B.(aha. and power, Bonneel (networkflow), N., shortlist), C.G.(simplex. and, Hartmann (semidiscrete1), V., integration), F.H.(transport_track. and networkflow, Schmitzer (shielding), B., Schrieber (subsampling), J., Wilm (wpp), T., 2022. Transport: <span>Computation</span> of <span>Optimal Transport Plans</span> and <span>Wasserstein Distances</span>.
</div>
<div id="ref-shennanQuantifyingArchaeology1997" class="csl-entry" role="listitem">
Shennan, S., 1997. Quantifying archaeology, 2nd ed. ed. <span>Edinburgh University Press</span>, <span>Edinburgh</span>.
</div>
<div id="ref-simpsonMeasurementDiversity1949" class="csl-entry" role="listitem">
Simpson, E.H., 1949. <a href="https://doi.org/10.1038/163688a0">Measurement of <span>Diversity</span></a>. Nature 163, 688–688.
</div>
<div id="ref-smithDefiningIndicatorPackage2013" class="csl-entry" role="listitem">
Smith, D.N., 2013. <a href="https://doi.org/10.1016/j.jas.2012.06.014">Defining an indicator package to allow identification of <span>“cesspits”</span> in the archaeological record</a>. Journal of Archaeological Science 40, 526–543.
</div>
<div id="ref-rstan" class="csl-entry" role="listitem">
Stan Development Team, 2023. <a href="https://mc-stan.org/"><span></span>RStan<span></span>: The <span></span>r<span></span> interface to <span></span>stan<span></span></a>.
</div>
<div id="ref-symsOrdination2008" class="csl-entry" role="listitem">
Syms, C., 2008. <a href="https://doi.org/10.1016/B978-008045405-4.00524-3">Ordination</a>. In: Encyclopedia of <span>Ecology</span>. <span>Elsevier</span>, pp. 2572–2581.
</div>
<div id="ref-tierneyMarkovChainsExploring1994" class="csl-entry" role="listitem">
Tierney, L., 1994. <a href="https://doi.org/10.1214/aos/1176325750">Markov <span>Chains</span> for <span>Exploring Posterior Distributions</span></a>. The Annals of Statistics 22, 1701–1728.
</div>
<div id="ref-triggerSettlementArchaeologyIts1967" class="csl-entry" role="listitem">
Trigger, B.G., 1967. <a href="https://doi.org/10.2307/277900">Settlement <span>Archaeology</span> and <span>Promise</span></a>. American Antiquity 32, 149–160.
</div>
<div id="ref-nimble" class="csl-entry" role="listitem">
Valpine, P. de, Turek, D., Paciorek, C., Anderson-Bergman, C., Temple Lang, D., Bodik, R., 2017. <a href="https://doi.org/10.1080/10618600.2016.1172487">Programming with models: Writing statistical algorithms for general model structures with <span></span>NIMBLE<span></span></a> 26, 403–413.
</div>
<div id="ref-vehtariPracticalBayesianModel2017" class="csl-entry" role="listitem">
Vehtari, A., Gelman, A., Gabry, J., 2017. <a href="https://doi.org/10.1007/s11222-016-9696-4">Practical <span>Bayesian</span> model evaluation using leave-one-out cross-validation and <span>WAIC</span></a>. Statistics and Computing 27, 1413–1432.
</div>
<div id="ref-vehtariRanknormalizationFoldingLocalization2021" class="csl-entry" role="listitem">
Vehtari, A., Gelman, A., Simpson, D., Carpenter, B., Bürkner, P.-C., 2021. <a href="https://doi.org/10.1214/20-BA1221">Rank-normalization, folding, and localization: <span>An</span> improved <span>Rhat</span> for assessing convergence of <span>MCMC</span></a>. Bayesian Analysis 16.
</div>
<div id="ref-wassermanAllNonparametricStatistics2006" class="csl-entry" role="listitem">
Wasserman, L., 2006. All of <span>Nonparametric Statistics</span>. <span>Springer Science &amp; Business Media</span>, <span>New York</span>.
</div>
<div id="ref-wickhamProgrammingGgplot22016" class="csl-entry" role="listitem">
Wickham, H., 2016. <a href="https://doi.org/10.1007/978-3-319-24277-4_12">Programming with Ggplot2</a>. In: Wickham, H. (Ed.), Ggplot2: <span>Elegant Graphics</span> for <span>Data Analysis</span>, Use <span>R</span>! <span>Springer International Publishing</span>, <span>Cham</span>, pp. 241–253.
</div>
<div id="ref-tidyverse" class="csl-entry" role="listitem">
Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L.D., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T.L., Miller, E., Bache, S.M., Müller, K., Ooms, J., Robinson, D., Seidel, D.P., Spinu, V., Takahashi, K., Vaughan, D., Wilke, C., Woo, K., Yutani, H., 2019. <a href="https://doi.org/10.21105/joss.01686">Welcome to the <span></span>tidyverse<span></span></a> 4, 1686.
</div>
<div id="ref-wilkensRestiFaunisticiDi1990" class="csl-entry" role="listitem">
Wilkens, B., 1990. <span>I resti faunistici di Calvatone (CR)</span>. Archeologia Medievale 307–322.
</div>
<div id="ref-wrightMethodologicalIssuesPaleoethnobotany2010" class="csl-entry" role="listitem">
Wright, P.J., 2010. <a href="https://doi.org/10.1007/978-1-4419-0935-0_3">Methodological <span>Issues</span> in <span>Paleoethnobotany</span>: <span>A</span> consideration of <span>Issues</span>, <span>Methods</span>, and <span>Cases</span></a>. In: VanDerwarker, A.M., Peres, T.M. (Eds.), Integrating <span>Zooarchaeology</span> and <span>Paleoethnobotany</span>: <span>A Consideration</span> of <span>Issues</span>, <span>Methods</span>, and <span>Cases</span>. <span>Springer New York</span>, <span>New York, NY</span>, pp. 37–64.
</div>
<div id="ref-wuNonparametricStatistics2017" class="csl-entry" role="listitem">
Wu, X., Geng, Z., Zhao, Q., 2017. Non-parametric statistics. In: Handbook of <span>Medical Statistics</span>. <span>World Scientific Publishing</span>, <span>Singapore</span>, pp. 145–182.
</div>
<div id="ref-wypijBinomialDistribution2014" class="csl-entry" role="listitem">
Wypij, D., 2014. <a href="https://doi.org/10.1002/9781118445112.stat04852">Binomial <span>Distribution</span></a>. In: Balakrishnan, N., Colton, T., Everitt, B., Piegorsch, W., Ruggeri, F., Teugels, J.L. (Eds.), Wiley <span>StatsRef</span>: <span>Statistics Reference Online</span>. <span>Wiley</span>.
</div>
<div id="ref-knitr" class="csl-entry" role="listitem">
Xie, Y., 2021. <a href="https://yihui.org/knitr/">Knitr: A general-purpose package for dynamic report generation in r</a>.
</div>
</div>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Count relative to January 2024.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>A thorough exposition of causal inference concerning confounders, mediators, colliders, and similar concepts is available in <span class="citation" data-cites="pearlBookWhyNew2019">Pearl and Mackenzie (<a href="references.html#ref-pearlBookWhyNew2019" role="doc-biblioref">2019</a>)</span>, while instructive illustrations can be found in <span class="citation" data-cites="mcelreath2016">McElreath (<a href="references.html#ref-mcelreath2016" role="doc-biblioref">2016</a>)</span>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>The resulting posterior distribution from this example can be found <a href="archaeobotany.html#sec-archaeobot-results-context-type"><span>Section&nbsp;7.3</span></a>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>The level of confidence in a frequentist confidence interval instead represents the probability that the interval will contain the true parameter value in repeated sampling. For instance, a 95% confidence interval means that if one were to collect data and construct confidence intervals several times, about 95% of those intervals would contain the true parameter value.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>The precision (or scale/spread) parameter is referred to as <span class="math inline">\(\theta\)</span> by <span class="citation" data-cites="mcelreath2016">McElreath (<a href="references.html#ref-mcelreath2016" role="doc-biblioref">2016</a>)</span>, <span class="math inline">\(\phi\)</span> by <span class="citation" data-cites="burknerOrdinalRegressionModels2019">Bürkner and Vuorre (<a href="references.html#ref-burknerOrdinalRegressionModels2019" role="doc-biblioref">2019</a>)</span> and <span class="math inline">\(\kappa\)</span> by <span class="citation" data-cites="kruschkeDoingBayesianData2015">Kruschke (<a href="references.html#ref-kruschkeDoingBayesianData2015" role="doc-biblioref">2015</a>)</span>. They all mean the same thing. This research will refer to the parameter as <span class="math inline">\(\phi\)</span>, following <span class="citation" data-cites="burknerOrdinalRegressionModels2019">Bürkner and Vuorre (<a href="references.html#ref-burknerOrdinalRegressionModels2019" role="doc-biblioref">2019</a>)</span>.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./database.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">The database</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./archaeobotany.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Archaeobotany</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">Roberto Ragno, PhD Candidate, Dipartimento di Ricerca e Innovazione Umanistica, Università di Bari Aldo Moro</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>



</body></html>